{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8326b62-841c-4f9a-b03b-ad49edf075c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Importing relevant packages - polars for the dataframe manipulation, numpy for series manipulation and time for timing\n",
    "import polars as pl #dataframe manipulation\n",
    "from polars import testing # testing purposes (dataframe comparison)\n",
    "import numpy as np # calculations\n",
    "import time #benchmarking\n",
    "from sklearn.model_selection import train_test_split #Used in training the model that fits the function \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d6f44d3-b90d-484b-b5f5-dfaad88f1497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Timer for benchmarking\n",
    "start = time.perf_counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20b64760-df55-47d2-adf4-93506dab1cf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Input Data\n",
    "Importing all of the input data that the calculations and functions are going to need. This includes the output from the Input Script saved in the form of a \"LazyFrame\", objects only partially evaluated on a \"as needed\" basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91c743e-c567-4901-81aa-d5ba2e487ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Secondary Collision \n",
    "The probability of a secondary collision was originally given via a lookup table. This has been replaced with a Linear Regression Model trained on the values given by the look up table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8754f89a-970e-47e9-8e2e-d8a16e6ce72c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e12e3291f54091bb7ca0483edfb02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading in the original lookup table\n",
    "secondaryCollisionProbability = pl.read_csv(\"path\"\n",
    "                                              ).select(\n",
    "                                                  pl.exclude(\"Index\")\n",
    "                                              ).rename(\n",
    "                                                  {\n",
    "                                                      \"Train speed (Mph)\": \"train_speed_mph\", \n",
    "                                                      \"Braking Rate (%g)\": \"braking_rate\", \n",
    "                                                      \"Trains per hour\": \"frequency\", \n",
    "                                                      \"Probabilty of secondary collision\": \"probability\"\n",
    "                                                    }\n",
    "                                                )\n",
    "\n",
    "# Determining our x and Y variables \n",
    "x = secondaryCollisionProbability.select([\"train_speed_mph\", \"braking_rate\", \"frequency\"]).to_numpy()\n",
    "Y = secondaryCollisionProbability.select(\"probability\").to_numpy()\n",
    "\n",
    "# Splitting the look-up table into training and testing sets\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, random_state=0, test_size = 0.1)\n",
    "\n",
    "# Determining the degree of the polynomial we are going to use\n",
    "degrees = 6\n",
    "poly = PolynomialFeatures(degree = degrees)\n",
    "\n",
    "# Fitting our training data\n",
    "X_train = poly.fit_transform(x_train)\n",
    "X_test = poly.fit_transform(x_test)\n",
    "\n",
    "clf = linear_model.LinearRegression(fit_intercept= False)\n",
    "model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cec893b-f151-4637-a987-b2e291465d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Output DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6f52be2-2bf9-473c-8e7a-e6b5abcec300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Set path (Check that this is pointing to the right location!!!!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6006de4c-6b93-4cbb-b7e1-ad58ee7a08fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setting the input file path \n",
    "path = #insertPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5147e0f6-9806-4da1-938c-e0c66f674072",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Here we lazily scan the csv files that we are going to need for the calculations so that they are available in the form of LazyFrames\n",
    "#This is done individually as 1) not all outputs are necessary for the calculation steps and 2) not all fields are necessary\n",
    "#This way we have more freedom in what we load in, as well as the ability to change data types in the future\n",
    "\n",
    "\n",
    "\n",
    "# Period ID and service section ID are being converted into strings so that they can be converted into categorical data during string caching \n",
    "sectionSegments = pl.read_csv(\n",
    "    path + \"/section\", schema_overrides={\"periodID\":pl.String, \"serviceSectionID\": pl.String}\n",
    ").filter(\n",
    "    (pl.col(\"serviceSectionID\") != \"4\")\n",
    ").with_columns(\n",
    "    (pl.when(pl.col(\"serviceSectionID\") == \"3\"\n",
    "            ).then(pl.lit(\"2\")\n",
    "                   ).otherwise(pl.col(\"serviceSectionID\"))\n",
    "            ).alias(\"serviceSectionID\")\n",
    ").select(\n",
    "    pl.exclude(\"Ref_ID\", \"numOfTracks\", \"right_correction\", \"left_correction\", \"SRS\", \"nextSectionUp\", \"nextSectionDown\")\n",
    ")\n",
    "\n",
    "trainGroup = pl.read_csv(path + \"/train_group\", schema_overrides={\"serviceID\": pl.Categorical, \"operator\": pl.Categorical, \"vehicleClass\": pl.Categorical,\"carshworthiness\":pl.Categorical, \"power\":pl.Categorical, \"serviceSectionID\": pl.String})\n",
    "\n",
    "\n",
    "derailmentType = pl.read_csv(path + \"/derailment_type\")\n",
    "\n",
    "\n",
    "trainType = pl.read_csv(path + \"/train_type\")\n",
    "\n",
    "\n",
    "assetInSection = pl.read_csv(path + \"/asset_in_section\", schema_overrides= {\"assetInSection\": pl.Categorical, \"assetID\": pl.Categorical}\n",
    ").select(pl.exclude(\"Ref_ID\"))\n",
    "\n",
    "\n",
    "assetType = pl.read_csv(path + \"/asset_type\")\n",
    "\n",
    "\n",
    "embankmentHeights = pl.read_csv(path + \"/embankment_heights.csv\").rename(\n",
    "    {\"GIS_ref\": \"sectionID\",\n",
    "        \"Embankment drop off hazard\": \"embankmentDropOffHazard\",\n",
    "        \"Embankment height\" : \"embankmentHeight\", \n",
    "        \"Bridge or viaduct height\": \"bridgeViaductHeight\"}\n",
    ").select(\"sectionID\", \"embankmentDropOffHazard\", \"embankmentHeight\", \"bridgeViaductHeight\"\n",
    ").cast(\n",
    "    {\"embankmentDropOffHazard\" : pl.Categorical,\n",
    "        \"embankmentHeight\" : pl.Categorical,\n",
    "        \"bridgeViaductHeight\": pl.Int32}\n",
    ").fill_null(0\n",
    ").with_columns(\n",
    "    pl.when(pl.col(\"embankmentHeight\") == \"3m to <10m High\"\n",
    "            ).then(5.0\n",
    "                   ).otherwise(\n",
    "                       pl.when(pl.col(\"embankmentHeight\") == \">10m High\"\n",
    "                               ).then(15.0\n",
    "                                      ).otherwise(0.0)\n",
    "                   ).alias(\"embankmentHeight(m)\")\n",
    ")\n",
    "\n",
    "trainSectionDirectionPeriod = pl.read_csv(path + \"/train_in_section_in_direction_per_period\", schema_overrides= {\"trainInSectionInDirectionID\": pl.Categorical, \"periodID\":pl.String})\n",
    "levelCrossings = pl.read_csv(path + \"/level_crossings\", schema_overrides={\"levelCrossingID\" : pl.Categorical})\n",
    "precursorDerailmentMap = pl.read_csv(path + \"/precursor_to_derailment_mapping\", schema_overrides = {\"mappingID\":pl.Categorical})\n",
    "precursor = pl.read_csv(path + \"/precursor\")\n",
    "period = pl.read_csv(path + \"/period\", schema_overrides={\"periodID\": pl.String})\n",
    "lazyMitigationScenarios = pl.scan_csv(path + \"/mitigation_scenarios\", schema_overrides= {\"scenarioID\": pl.Categorical})\n",
    "\n",
    "lazyCutsetMatrixC = pl.scan_csv(path + \"/cutset_matrix_c\").cast({\"1Y\": pl.Boolean, \"2Y\": pl.Boolean, \"3Y\": pl.Boolean, \"4Y\": pl.Boolean, \"5Y\": pl.Boolean, \"6Y\": pl.Boolean, \"7Y\": pl.Boolean, \"8Y\": pl.Boolean, \"9Y\": pl.Boolean, \"10Y\": pl.Boolean, \"11Y\": pl.Boolean, \"12Y\": pl.Boolean, \"13Y\": pl.Boolean, \"14Y\": pl.Boolean, \"1N\": pl.Boolean, \"2N\": pl.Boolean, \"3N\": pl.Boolean, \"4N\": pl.Boolean, \"5N\": pl.Boolean, \"6N\": pl.Boolean, \"7N\": pl.Boolean, \"8N\": pl.Boolean, \"9N\": pl.Boolean, \"10N\": pl.Boolean, \"11N\": pl.Boolean, \"12N\": pl.Boolean, \"13N\": pl.Boolean, \"14N\": pl.Boolean, \"cutsetID\": pl.Categorical})\n",
    "\n",
    "lazyCutsetMatrixC_1_7 = lazyCutsetMatrixC.select([\"cutsetID\", \"1Y\", \"1N\", \"2Y\", \"2N\", \"3Y\", \"3N\", \"4Y\", \"4N\", \"5Y\", \"5N\", \"6Y\", \"6N\", \"7Y\", \"7N\"])\n",
    "lazyCutsetMatrixC_8_14 = lazyCutsetMatrixC.select([\"cutsetID\", \"8Y\", \"8N\", \"9Y\", \"9N\", \"10Y\", \"10N\", \"11Y\", \"11N\", \"12Y\", \"12N\", \"13Y\", \"13N\", \"14Y\", \"14N\"])\n",
    "\n",
    "lazySecondaryCollisionIA = pl.scan_csv(path + \"/IAsecondaryCollision.csv\"\n",
    ").select(\n",
    "    pl.exclude([\"SPAD train\", \"SET train\", \"Passenger FWI\", \"Staff FWI\", \"Driver major injuries (train 1)\", \"Guard major injuries (train 1)\", \"Driver major injuries (train 2)\", \"Guard major injuries (train 2)\"])\n",
    ").filter((pl.col(\"Type of conflict\") != \"Rear-end\") & (pl.col(\"Train 1 type \") != \"-\") & (pl.col(\"Train 2 type \") != \"-\")\n",
    ").rename(\n",
    "{   \"Closing velocity (mph)\" : \"collisionSpeedmph\",\n",
    "    \"Type of conflict\": \"collisionType\",\n",
    "    \"Train 1 type \": \"trainType1\",\n",
    "    \"Train 2 type \": \"trainType2\",\n",
    "    \"Passenger Fatality (train 1)\": \"passengerFatal1\", \n",
    "    \"Passenger Severe Hospital (train 1)\": \"passengerSevHosp1\", \n",
    "    \"Passenger Non-severe (train 1)\": \"passengerNonSevere1\", \n",
    "    \"Driver Fatality (train 1)\": \"driverFatalTrain1\", \n",
    "    \"Driver Specified (train 1)\": \"driverSpecifiedTrain1\",\n",
    "    \"Driver Severe 7 (train 1)\": \"driverSev71\",\n",
    "    \"Driver Non-severe (train 1)\": \"driverNonSevere1\", \n",
    "    \"Guard Fatality (train 1)\": \"guardFatal1\",\n",
    "    \"Guard Specified (train 1)\": \"guardSpecified1\",\n",
    "    \"Guard Severe 7 (train 1)\": \"guardSev71\",\n",
    "    \"Guard Non-severe (train 1)\": \"guardNonSevere1\",\n",
    "    \"Passenger Fatality (train 2)\": \"passengerFatal2\", \n",
    "    \"Passenger Severe Hospital (train 2)\": \"passengerSevHosp2\", \n",
    "    \"Passenger Non-severe (train 2)\": \"passengerNonSevere2\", \n",
    "    \"Driver Fatality (train 2)\": \"driverFatalTrain2\", \n",
    "    \"Driver Specified (train 2)\": \"driverSpecifiedTrain2\",\n",
    "    \"Driver Severe 7 (train 2)\": \"driverSev72\",\n",
    "    \"Driver Non-severe (train 2)\": \"driverNonSevere2\", \n",
    "    \"Guard Fatality (train 2)\": \"guardFatal2\",\n",
    "    \"Guard Specified (train 2)\": \"guardSpecified2\",\n",
    "    \"Guard Severe 7 (train 2)\": \"guardSev72\",\n",
    "    \"Guard Non-severe (train 2)\": \"guardNonSevere2\"\n",
    "}\n",
    ").with_columns(\n",
    "    pl.sum_horizontal(\"driverFatalTrain1\", \"guardFatal1\").alias(\"workforceFatal1\"), \n",
    "    pl.sum_horizontal(\"driverSpecifiedTrain1\", \"guardSpecified1\").alias(\"workforceSpecified1\"),\n",
    "    pl.sum_horizontal(\"driverSev71\", \"guardSev71\").alias(\"workforceSev71\"),\n",
    "    pl.sum_horizontal(\"driverNonSevere1\", \"guardNonSevere1\").alias(\"workforceNonSevere1\"),\n",
    "    pl.sum_horizontal(\"driverFatalTrain2\", \"guardFatal2\").alias(\"workforceFatal2\"), \n",
    "    pl.sum_horizontal(\"driverSpecifiedTrain2\", \"guardSpecified2\").alias(\"workforceSpecified2\"),\n",
    "    pl.sum_horizontal(\"driverSev72\", \"guardSev72\").alias(\"workforceSev72\"),\n",
    "    pl.sum_horizontal(\"driverNonSevere2\", \"guardNonSevere2\").alias(\"workforceNonSevere2\")\n",
    ").with_columns(\n",
    "    passengerShock1 = 0,\n",
    "    passengerShock2 = 0,\n",
    "    workforceShock71 = 0,\n",
    "    workforceShock1 = 0,\n",
    "    workforceShock72 = 0,\n",
    "    workforceShock2 = 0\n",
    ").select(\n",
    "    pl.exclude([\"driverFatalTrain1\", \"guardFatal1\", \"driverSpecifiedTrain1\", \"guardSpecified1\", \"driverSev71\", \"guardSev71\", \"driverNonSevere1\", \"guardNonSevere1\", \"driverFatalTrain2\", \"guardFatal2\", \"driverSpecifiedTrain2\", \"guardSpecified2\", \"driverSev72\", \"guardSev72\", \"driverNonSevere2\", \"guardNonSevere2\"]))\n",
    "\n",
    "lazyCutsetMatrixD = pl.scan_csv(path + \"/cutset_matrix_d\").cast(\n",
    "    {\"1\" : pl.Boolean, \"2\" : pl.Boolean, \"3\" : pl.Boolean, \"4\" : pl.Boolean, \"5\" : pl.Boolean, \"6\" : pl.Boolean, \"7\" : pl.Boolean, \"8\" : pl.Boolean, \"9\" : pl.Boolean, \"10\" : pl.Boolean, \"11\" : pl.Boolean, \"12\" : pl.Boolean, \"13\" : pl.Boolean, \"14\" : pl.Boolean}\n",
    ").rename(\n",
    "    {\"cutsetID\": \"cutset_ID_string\", \"1\" : \"significantStructureCollision\", \"2\" : \"significantStructureCollapse\", \"3\" : \"smallStructureCollision\", \"4\" : \"vehicleFallFromHeight\", \"5\" : \"vehicleFallFromEmbankment\", \"6\" : \"vehicleFallIntoWater\", \"7\" : \"vehicleFallOnSide\", \"8\" : \"secondaryCollision\", \"9\" : \"toxicGoodRelease\", \"10\" : \"toxicGoodRelease(noCollision)\", \"11\" : \"flamGoodRelease\", \"12\" : \"flamGoodRelease(noCollision)\", \"13\" : \"fire(flamGoods)\", \"14\" : \"fire(noFlamGoods)\"}\n",
    ").join(\n",
    "    lazyCutsetMatrixC.select(\"cutsetID\").with_columns(pl.col(\"cutsetID\").cast(pl.String).alias(\"cutset_ID_string\")), on = \"cutset_ID_string\", how = \"inner\"\n",
    ").select(\n",
    "    pl.exclude(\"cutset_ID_string\")\n",
    ")\n",
    "\n",
    "injuryDegree = pl.read_csv(path + \"/injury_degree\")\n",
    "personInjury = pl.read_csv(path + \"/person_injury\", schema_overrides={\"personTypeID\": pl.Categorical, \"personInjuryID\": pl.Categorical})\n",
    "direction = pl.read_csv(path + \"/direction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a45c4e51-35a1-49e7-914a-86508e2b7a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Level crossing normalizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0da13e79-6ea2-4164-bde1-39a16cb7fd42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Annual rate of derailment due to collision with a vehicle at a given level crossing type per year\n",
    "levelCrossingNormalizers = pl.DataFrame(\n",
    "    data = {\n",
    "        \"levelCrossingType\" : pl.Series([\"ABCL\",\"AFBCL\",\"AHB\",\"AOCL\",\"AOCLB\",\"FP\",\"FPMWL\",\"MCB\",\"MCBCCTV\",\"MCBOD\",\"MCG\",\"OC\",\"UWC\",\"UWCMWL\",\"UWCT\"]), \n",
    "        \"totalLevelCrossingDerailmentRisk\": pl.Series([ 0.000382657, 0.000382657, 0.049631002, 0.000077968, 0.000084824, 0.000001033, 0.000000410, 0.003282743, 0.015157379, 0.001134564, 0.000122723, 0.000000554,0.019632537,0.037638675,0.115193576])\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "719b15ef-c3f4-44cb-9e72-59f506e18585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Total train kilometers where assets are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b59d2c7c-8a4b-49f4-a8f1-6a9d11706496",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Total train kms over sections where a given asset presents a risk \n",
    "assetDependentNormalizers = pl.read_csv(path + \"/asset_dependent_normalizers.csv\"\n",
    ").rename(\n",
    "    {\n",
    "        \"asset_type\": \"assetTypeID\",\n",
    "        \"train_type\": \"trainType\",\n",
    "        \"train_km\": \"trainKm\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# The asset type necessary for a precursor to materialize\n",
    "precursorAssetMap = pl.DataFrame(\n",
    "    {\n",
    "        \"precursorGroupID\": pl.Series([\"CATD\",\"DCRW\",\"LNSC\",\"LNSE\", \"RGBD\", \"RBSF\", \"RBSH\", \"ROHL\", \"RSIG\", \"RWAL\", \"SCWS\", \"SHNE\", \"WFLD\", \"OVSP\"]), \n",
    "        \"assetTypeID\": pl.Series([\"switches_crossing\",\"switches_crossing\",\"cutting\",\"embankment\",\"overbridge\",\"underbridge\",\"underbridge\",\"elec_masts\",\"signalling_gantry\",\"lineside\",\"switches_crossing\",\"switches_crossing\",\"water\", \"curve\"])\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae44d5c1-7f60-4eaf-b715-0033e6886bc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Matching Categoricals\n",
    "Having categorical values from the same sources makes joins a lot more efficient computationally. However, because we are loading our data in from .csv files they don't register as having the same encoding, defeating the purpose.\n",
    "\n",
    "To deal with this we use StringCache( ) to tell Polars that these Categorical fields should have the same encoding. We are avoiding a global string cache because that comes with a significant overhead cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f0cd8d2a-23ad-4e8f-89be-7796dec9357d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Numerical columns are first cast into strings as polars cannot convert numerical values to categoricals\n",
    "# Service section ID:\n",
    "with pl.StringCache():\n",
    "    sectionSegments = sectionSegments.sort(\"serviceSectionID\").with_columns(pl.col(\"serviceSectionID\").cast(pl.Categorical))\n",
    "    trainGroup = trainGroup.sort(\"serviceSectionID\").with_columns(pl.col(\"serviceSectionID\").cast(pl.Categorical))\n",
    "\n",
    "# Train type\n",
    "with pl.StringCache():\n",
    "    trainGroup = trainGroup.with_columns(pl.col(\"trainType\").cast(pl.Categorical))\n",
    "    trainType = trainType.with_columns(pl.col(\"trainType\").cast(pl.Categorical))\n",
    "    precursor = precursor.with_columns(pl.col(\"trainType\").cast(pl.Categorical))\n",
    "    assetDependentNormalizers = assetDependentNormalizers.with_columns(pl.col(\"trainType\").cast(pl.Categorical))\n",
    "\n",
    "# Section ID\n",
    "with pl.StringCache():\n",
    "    sectionSegments = sectionSegments.with_columns(pl.col(\"sectionID\").cast(pl.Categorical))\n",
    "    embankmentHeights = embankmentHeights.with_columns(pl.col(\"sectionID\").cast(pl.Categorical))\n",
    "    assetInSection = assetInSection.with_columns(pl.col(\"sectionID\").cast(pl.Categorical))\n",
    "    trainSectionDirectionPeriod = trainSectionDirectionPeriod.with_columns(pl.col(\"sectionID\").cast(pl.Categorical))\n",
    "    levelCrossings = levelCrossings.with_columns(pl.col(\"sectionID\").cast(pl.Categorical))\n",
    "\n",
    "# Asset Type ID\n",
    "with pl.StringCache():\n",
    "    assetInSection = assetInSection.with_columns(pl.col(\"assetTypeID\").cast(pl.Categorical))\n",
    "    assetType = assetType.with_columns(pl.col(\"assetTypeID\").cast(pl.Categorical))\n",
    "    assetDependentNormalizers = assetDependentNormalizers.with_columns(pl.col(\"assetTypeID\").cast(pl.Categorical))\n",
    "    precursorAssetMap = precursorAssetMap.with_columns(pl.col(\"assetTypeID\").cast(pl.Categorical))\n",
    "\n",
    "# Direction \n",
    "with pl.StringCache():\n",
    "    assetInSection = assetInSection.with_columns(pl.col(\"direction\").cast(pl.Categorical))\n",
    "    trainSectionDirectionPeriod = trainSectionDirectionPeriod.with_columns(pl.col(\"direction\").cast(pl.Categorical))\n",
    "    direction = direction.with_columns(pl.col(\"direction\").cast(pl.Categorical))\n",
    "\n",
    "# Period ID\n",
    "with pl.StringCache():\n",
    "    sectionSegments = sectionSegments.with_columns(pl.col(\"periodID\").cast(pl.Categorical))\n",
    "    trainSectionDirectionPeriod = trainSectionDirectionPeriod.with_columns(pl.col(\"periodID\").cast(pl.Categorical))\n",
    "    period = period.with_columns(pl.col(\"periodID\").cast(pl.Categorical))\n",
    "\n",
    "# Train Group ID\n",
    "with pl.StringCache():\n",
    "    trainSectionDirectionPeriod = trainSectionDirectionPeriod.with_columns(pl.col(\"trainGroupID\").cast(pl.Categorical))\n",
    "    trainGroup = trainGroup.with_columns(pl.col(\"trainGroupID\").cast(pl.Categorical))\n",
    "\n",
    "# Derailment Type ID\n",
    "with pl.StringCache():\n",
    "    derailmentType = derailmentType.with_columns(pl.col(\"derailmentTypeID\").cast(pl.Categorical))\n",
    "    derailmentType = derailmentType.with_columns(pl.col(\"derailmentTypeID\").cast(pl.Categorical))\n",
    "    precursorDerailmentMap = precursorDerailmentMap.with_columns(pl.col(\"derailmentTypeID\").cast(pl.Categorical))\n",
    "\n",
    "# Precursor ID\n",
    "with pl.StringCache():\n",
    "    precursorDerailmentMap = precursorDerailmentMap.with_columns(pl.col(\"precursorID\").cast(pl.Categorical))\n",
    "    precursor = precursor.with_columns(pl.col(\"precursorID\").cast(pl.Categorical))\n",
    "\n",
    "# Level Crossing Type\n",
    "with pl.StringCache():\n",
    "    levelCrossings = levelCrossings.with_columns(pl.col(\"levelCrossingType\").cast(pl.Categorical))\n",
    "    precursor = precursor.with_columns(pl.col(\"levelCrossingType\").cast(pl.Categorical))\n",
    "    levelCrossingNormalizers = levelCrossingNormalizers.with_columns(pl.col(\"levelCrossingType\").cast(pl.Categorical))\n",
    "\n",
    "# Injury Degree ID\n",
    "with pl.StringCache():\n",
    "    injuryDegree = injuryDegree.with_columns(pl.col(\"injuryDegreeID\").cast(pl.Categorical))\n",
    "    personInjury = personInjury.with_columns(pl.col(\"injuryDegreeID\").cast(pl.Categorical))\n",
    "\n",
    "# Precursor Group ID\n",
    "with pl.StringCache():\n",
    "    precursorAssetMap = precursorAssetMap.with_columns(pl.col(\"precursorGroupID\").cast(pl.Categorical))\n",
    "    precursor = precursor.with_columns(pl.col(\"precursorGroupID\").cast(pl.Categorical))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607e19fe-94e6-4001-98ed-a1f5df328653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The conversion to dataframes is performed after the string caching to ensure the Categorical fields have the same encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "db862c29-9153-4f05-afad-3ad8c1b2fb0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazySectionSegments = pl.LazyFrame(sectionSegments)\n",
    "lazyTrainGroup = pl.LazyFrame(trainGroup)\n",
    "lazyDerailmentType = pl.LazyFrame(derailmentType)\n",
    "lazyTrainType = pl.LazyFrame(trainType)\n",
    "lazyAssetInSection = pl.LazyFrame(assetInSection)\n",
    "lazyAssetType = pl.LazyFrame(assetType)\n",
    "lazyPrecursor = pl.LazyFrame(precursor)\n",
    "lazyEmbankmentHeights = pl.LazyFrame(embankmentHeights)\n",
    "lazyTrainSectionDirectionPeriod = pl.LazyFrame(trainSectionDirectionPeriod)\n",
    "lazyLevelCrossings = pl.LazyFrame(levelCrossings)\n",
    "lazyDirection = pl.LazyFrame(direction)\n",
    "lazyPeriod = pl.LazyFrame(period)\n",
    "lazyPrecursorDerailmentMap = pl.LazyFrame(precursorDerailmentMap)\n",
    "lazyInjuryDegree = pl.LazyFrame(injuryDegree)\n",
    "lazyPersonInjury = pl.LazyFrame(personInjury) \n",
    "lazyLevelCrossingNormalizers = pl.LazyFrame(levelCrossingNormalizers)\n",
    "lazyPrecursorAssetMap = pl.LazyFrame(precursorAssetMap)\n",
    "lazyAssetDependentNormalizers = pl.LazyFrame(assetDependentNormalizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a1ad05-d430-48f0-9cd5-108f19388a65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Asset Dependent Normalizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f2d4e5f5-665e-4654-a972-41eaa0ac7eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Categorical encoding is decided on materialization - there we create the dataframe first and then convert it to a lazyframe \n",
    "lazyAssetDependentNormalizers = pl.LazyFrame(assetDependentNormalizers.join(assetType.select(\"assetTypeName\", \"assetTypeID\"), \n",
    "       on = \"assetTypeID\", how = \"left\", coalesce = True\n",
    ").join(\n",
    "    precursorAssetMap, on = \"assetTypeID\", how = \"inner\"\n",
    ").with_columns(\n",
    "    pl.concat_str(\n",
    "        [\n",
    "            pl.col(\"precursorGroupID\").cast(pl.String), pl.col(\"trainType\").cast(pl.String)\n",
    "        ], separator = \"_\"\n",
    "    ).alias(\"assetDependentNormalizerID\").cast(pl.Categorical(ordering=\"lexical\"))\n",
    "))\n",
    "# streaming=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "33a14b74-6a2f-4f7e-9c0d-813ce224d538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "55936cb3-7506-4a3a-94df-8a634adc175d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "maxLateralDeviation = 15.0 # the maximum lateral deviation in m for any derailment \n",
    "lateralDisplacementConstant = 0.013178616 # In m laterally per m along the track\n",
    "subsequentPointsInitialLateralDisplacement = 3.0 # the initial lateral displacement of trains with a derailment trajectory going through points\n",
    "speedConversionConstant =  0.44704 # For converting mph to m/s\n",
    "vehicleKmPerYearPassenger = 2864092079.0 # total vehicle km travelled per year for passenger trains\n",
    "vehicleKmPerYearFreight = 700935779.8 # total vehicle km travelled per year for freight trains\n",
    "trainKmPerYearPassenger = 493533456.3 # total train km travelled per year for passenger trains\n",
    "trainKmPerYearFreight = 111835525.7 # total train km travelled per year for freight trains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "821c0ae9-f81c-4860-bf8c-69832994bbd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Escalation Probability Calculation Constants\n",
    "Constants used during the escalation probability calculation step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7bcc19b6-f14c-4cd6-9674-a7e874b32004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Significant structure collision probability \n",
    "probSignStructCollisionP = 0.19 #Given that a significant structure is present\n",
    "probSignStructCollisionN = 0.0 #Given no significant structure is present \n",
    "\n",
    "#Significant structure collapse \n",
    "collisionForce = 4000000\n",
    "timeElapsed = 1 #Reaction time \n",
    "vehicleMass = 40000\n",
    "maxNumberOfVehicles = 4\n",
    "\n",
    "#Small structure collision probability \n",
    "probSmallStructCollisionP = 0.38 #Given that a small structure is present \n",
    "probSmallStructCollisionN = 0.0 #Given that a small structure is not present \n",
    "\n",
    "#Fall from height probability \n",
    "probFallFromHeightP = 1.0 #Given that a fall from height is possible \n",
    "probFallFromHeightN = 0.0 #Given that a fall from height is not possible \n",
    "\n",
    "#Fall from embankment probability \n",
    "probFallFromEmbankmentP = 0.169 #Given that an embankment is present \n",
    "probFallFromEmbankmentN = 0.0 #Given that an embankment is not present\n",
    "\n",
    "#Fall into water probability  \n",
    "probFallInWaterP = 0.085 #Given that a body of water is present\n",
    "probFallInWaterN = 0.0 #Given that a body of water is not present\n",
    "\n",
    "#Fall on side probability \n",
    "probFallOnSideP = 1.0 #Given that the derailment type is T7 or T8\n",
    "constantA = 125\n",
    "P0 = 0.009 #Probability the train will fall on its side at 0 speed \n",
    "P125 = 0.26 #Probability the train will fall on its side at 125mph \n",
    "V50 = 80 #The speed in mph where the probability is between P0 and P125\n",
    "K = 1.5 #The steepness parameter \n",
    "\n",
    "#Probability of flammable goods release\n",
    "probFlamGoodsReleaseP = 0.667 #Given that flam goods are present \n",
    "#In the absence of flam goods diesel release is modelled as P(x) = 1/(1+e^(-(constantA + constantB * speed )))\n",
    "constantB = -4.704 \n",
    "constantC = 0.0609\n",
    "probFlamGoodsReleaseN = 0.0 #Given that no flam goods or diesel is present \n",
    "\n",
    "#Probability of hazardous goods release \n",
    "probHazGoodsReleaseP = 0.667 #Given that haz goods are present \n",
    "probHazGoodsReleaseN = 0.0 #Given that haz goods are not present\n",
    "\n",
    "#Probability of fire\n",
    "probFireP = 0.375 #Given that flam goods are present \n",
    "probFireN = 0.028 #Given that flam goods are not present "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ec0679-572b-4a78-a5b3-ba4979744723",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Calculations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d53a90-254a-49c8-9a8b-c3c146f2f964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Speed\n",
    "Derailment speed is calculated as a function of:\n",
    "- derailmentSpeed(m/s) = lineSpeed(mph) * _derailmentSpeedConstant_ * _trainTypeSpeedConstant_ * _conversionConstant_\n",
    "\n",
    "We need the derailment speed in m/s so that we can calculate the distance the train covers post derailment (_derailmentDistance_) using its develeration which is in m/s^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "21612eab-9e8e-447b-85cb-1387b660553f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentSpeed = lazySectionSegments.select(\n",
    "    pl.exclude(\"Ref_ID\", \"nextSectionUp\", \"NextSectionDown\", \"inTunnel\")\n",
    ").join(lazyTrainGroup.select(\n",
    "    \"trainGroupID\", \"serviceSectionID\", \"trainType\"\n",
    "), on=\"serviceSectionID\", how=\"inner\"\n",
    ").join(lazyTrainType, \n",
    "       on = \"trainType\", how =\"inner\"\n",
    ").join(lazyDerailmentType.select(\n",
    "    pl.exclude(\"description\", \"initialLateralDisplacement\")\n",
    "), how=\"cross\"\n",
    ").join(\n",
    "    lazyDirection.select(\"direction\"), \n",
    "    how=\"cross\"\n",
    ").with_columns(\n",
    "    # These conditionals check the appropriate derailment speed constant to use \n",
    "    pl.when(pl.col(\"useDefaultSpeed\")\n",
    "            ).then(pl.col(\"lineSpeedMPH\") * pl.col(\"defaultSpeed\") * speedConversionConstant\n",
    "                   ).otherwise(pl.col(\"lineSpeedMPH\") * pl.col(\"overspeedingSpeed\") * speedConversionConstant\n",
    "                               ).alias(\"derailment_speed_m/s\") \n",
    ").with_columns(\n",
    "    # Creating a uniqueID for each combination\n",
    "    pl.concat_str(\n",
    "        [\"trainGroupID\", \n",
    "        \"sectionID\", \n",
    "        \"derailmentTypeID\", \n",
    "        \"periodID\",\n",
    "        \"direction\"], separator = \"_\"\n",
    "        ).alias(\"trainSectionDerailmentPeriodDirectionID\").cast(pl.Categorical(ordering=\"lexical\"))\n",
    ")\n",
    "\n",
    "# streaming=True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc184241-83dc-404d-af59-a57c220ea18c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We materialize lazyDerailmentSpeed so that the ID categorical encoding can be set, allowing for accurate joining in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a81a2cb-f273-4c4e-8ebf-2243efb9f72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentSpeed = pl.LazyFrame(lazyDerailmentSpeed.collect(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7509f39d-d7b2-45a0-b63e-9bf6f965fd2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Distance\n",
    "The derailment distance is calculated as the function of: \n",
    "- _derailmentDistance = derailmentSpeed(m/s)^2 / decelerationRate(m/s^2) * 2_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "660727bb-af2c-41c8-805c-415aad0f2b54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentDistance = lazyDerailmentSpeed.with_columns(\n",
    "    # Calculating the derailment Distance\n",
    "    (\n",
    "        (pl.col(\"derailment_speed_m/s\")**2) /\n",
    "        (pl.col(\"decelerationRate(m/s^2)\")*2)\n",
    "        ).alias(\"derailmentDistance\")\n",
    ")\n",
    "\n",
    "# streaming=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5875bbb-c755-4e04-afa4-e8dbfb7175f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Segments Covered\n",
    "The segments covered are calculated by identifying the distance of each segment from the beginning of its respective section. This is used to calculate the distance between two segments like so:\n",
    "- distanceBetweenSegments = D2 - D1, \n",
    "\n",
    "Where: \n",
    "- D2: distance of traversed segments from service section start and \n",
    "- D1: distance of derailment segment from service section start\n",
    "\n",
    "We then compare this to the scenario's derailmentDistance, and if the value is greater than it, then the train cannot have reached this segment, and is excluded. \n",
    "\n",
    "We also exclude segments that are not 100% traversed (i.e. the train covered less than 100% of their length, typically the final segment). This is done to account for the fact that we do not know where the assets are positioned along the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4aa10204-a12f-44f1-942b-bf204967aee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "serviceSectionDistances = pl.LazyFrame(\n",
    "    sectionSegments.join(\n",
    "        # The direction reverses the order in which the segments appear. This essentially swaps the first segment in the service section\n",
    "        # and by extention changes the distance of each segment from the service start.\n",
    "        lazyDirection.collect() # We call .collect() because we need to join two DataFrames\n",
    "        ,how = \"cross\"\n",
    "    ).with_columns(\n",
    "        # Here we calculate the cumulative distance of each segment from the first segment in the serviceSection\n",
    "        pl.cum_sum(\"length(m)\"\n",
    "                   ).over([\"serviceSectionID\", \"direction\"], \n",
    "        # The key in the order_by parameter enforces a conditional ordering, where if the direction is up the distances start at 0 and increase\n",
    "        # and if the direction is down they start at the maximum and decrease.\n",
    "        # The same result could be achieved by creating the DataFrames seperately and stacking them but stacks are computationally more \n",
    "        # expensive. \n",
    "                                     order_by = pl.when(pl.col(\"direction\") == \"up\"\n",
    "                                                        ).then(pl.col(\"sectionID\")\n",
    "                                                               ).otherwise(pl.col(\"sectionID\").reverse())).alias(\"derailmentSegmentDistanceFromServiceSectionStart\")\n",
    "        ).select(\n",
    "            \"sectionID\", \n",
    "            \"serviceSectionID\",\n",
    "            \"hasS&C\", \n",
    "            \"curvature\", \n",
    "            \"direction\",\n",
    "            \"derailmentSegmentDistanceFromServiceSectionStart\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "# streaming=False \n",
    "# We calculate this table as a DataFrame and then convert it into a LazyFrame because cumulative functions are incompatible with streaming\n",
    "# This is unlikely to cause issues though as the DataFrames are small. \n",
    "\n",
    "# For this LazyFrame we gather all of the fields for the derailment cone calculation\n",
    "# We join the serviceSectionDistances twice - the first time we join so that each dearilmentSegment has a distanceFromSectionStart value\n",
    "# and the second time it is an inner join so that all segments within the same service section are joined with one another. \n",
    "segmentsCovered = lazyDerailmentDistance.join(\n",
    "    serviceSectionDistances, \n",
    "    how = \"inner\", on = [\"sectionID\", \"direction\"] \n",
    ").join(serviceSectionDistances.select(\n",
    "    # It is important to note that here the sections in the \"down\" direction are returned the other way around, meaning last first. \n",
    "    # This does NOT affect the calculations but makes it a bit less human-readable. \n",
    "    pl.col(\"sectionID\").alias(\"segmentTraversed\"), \n",
    "    pl.col(\"direction\"),\n",
    "    pl.col(\"serviceSectionID\"),\n",
    "    pl.col(\"hasS&C\").alias(\"segmentTraversedHasS&C\"), \n",
    "    pl.col(\"curvature\").alias(\"segmentTraversedCurvature\"), \n",
    "    pl.col(\"derailmentSegmentDistanceFromServiceSectionStart\").alias(\"segmentTraversedDistanceFromServiceSectionStart\")\n",
    "    ), how=\"inner\", on= [\"serviceSectionID\", \"direction\"]  \n",
    ").with_columns(\n",
    "    # By subtracting the location of the derailment segment from the location of the traversed segment we can identify which segments are \n",
    "    # actually traversed (a negative value indicates that the traversed segment comes before the derailment segment, and hence cannot be \n",
    "    # traversed AFTER the derailment). This excludes all segments that came BEFORE the derailment occured. \n",
    "    (pl.col(\"segmentTraversedDistanceFromServiceSectionStart\") - \n",
    "     pl.col(\"derailmentSegmentDistanceFromServiceSectionStart\")\n",
    "     ).alias(\"distanceBetweenTwoSegments\")\n",
    ").filter(pl.col(\"distanceBetweenTwoSegments\") >= 0\n",
    ").with_columns(\n",
    "    # Then by subtracting the distance between the two segments from the derailmentDistance we can identify which segments are \"too far\" for \n",
    "    # the derailed train to reach. This excludes all of the segments that come after the derailed train would have come to a stop. \n",
    "    (pl.col(\"derailmentDistance\") - \n",
    "     pl.col(\"distanceBetweenTwoSegments\") \n",
    "     ).alias(\"distanceFromEndPoint\")\n",
    ").filter(pl.col(\"distanceFromEndPoint\") >= 0\n",
    ").select(\n",
    "    pl.col(\"trainSectionDerailmentPeriodDirectionID\"),\n",
    "    pl.col(\"sectionID\").alias(\"derailmentSectionID\"),\n",
    "    pl.col(\"length(m)\"),\n",
    "    pl.col(\"direction\"),\n",
    "    pl.col(\"periodID\"), \n",
    "    pl.col(\"trainGroupID\"),\n",
    "    pl.col(\"derailmentTypeID\"),\n",
    "    pl.col(\"hasS&C\").alias(\"derailmentSegmentHasS&C\"),\n",
    "    pl.col(\"curvature\").alias(\"derailmentSegmentCurvature\"),\n",
    "    pl.col(\"derailment_speed_m/s\").alias(\"derailmentSpeed(m/s)\"),\n",
    "    pl.col(\"decelerationRate(m/s^2)\").alias(\"decelerationRate(m/s^2)\"),\n",
    "    pl.col(\"derailmentDistance\"),\n",
    "    pl.col(\"derailmentSegmentDistanceFromServiceSectionStart\"),\n",
    "    pl.col(\"segmentTraversed\"),\n",
    "    pl.col(\"segmentTraversedHasS&C\").cast(pl.Int8), #This is important to the next step\n",
    "    pl.col(\"segmentTraversedCurvature\"),\n",
    "    pl.col(\"segmentTraversedDistanceFromServiceSectionStart\"),\n",
    "    pl.col(\"distanceBetweenTwoSegments\"),\n",
    "    pl.col(\"distanceFromEndPoint\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# streaming=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76ed8dc-f117-4310-af53-bdb018785857",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Change in derailment type\n",
    "\n",
    "In the original algorithm, encountering S&C during the derailment process changed the derailment type into \"T1\".\n",
    "\n",
    "This also comes with a number of changes including deceleration rate (which by extention changes the derailmentDistance) and the initial lateral displacement. \n",
    "\n",
    "Polars' parallelization is row based - similar to simultaneous computation of batches. This means that we cannot know if a derailed train will meet an S&C down the line unless we compute it before hand. We do this by getting the cumulative max value for our \"segmentHasTraversedS&C\" field partitioned by the unique scenario ID. This is why rather than a boolean value we used an integer in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fc9b19a4-f36a-43b8-acb6-0b769a58457a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Every time we call a cumulative function we need to pass the key as in the \"down\" direction the sections appear the wrong way around (last\n",
    "# first)\n",
    "traversedPoints = segmentsCovered.with_columns(\n",
    "    # The flag indicates that from that point forward the train has been through an S&C and hence the derailment type, deceleration rate, and\n",
    "    # lateral displacement have all changed. The intiger is used as a gate in calculations. \n",
    "    pl.col(\"segmentTraversedHasS&C\").cum_max().over([\"trainSectionDerailmentPeriodDirectionID\", \"direction\"], \n",
    "                                                    order_by = pl.when(pl.col(\"direction\") == \"up\"\n",
    "                                                                       ).then(pl.col(\"segmentTraversed\")\n",
    "                                                                              ).otherwise(pl.col(\"segmentTraversed\").reverse())\n",
    "                                                                       ).alias(\"beenThroughS&C\")\n",
    ").with_columns(\n",
    "        # The distance to the first \"point\" is a measure that is used in a number of cone calcultions. Here we calculate the distanceSinceS&C\n",
    "        # as a surrogate measure because performing calculations across rows is strictly speaking impossible. \n",
    "        # We use it to infer the distance to the first S&C as we know their relative positions at all times. \n",
    "        pl.when(pl.col(\"beenThroughS&C\") == 1\n",
    "                    ).then(pl.col(\"length(m)\").cum_sum().over([\"trainSectionDerailmentPeriodDirectionID\", \"direction\", \"beenThroughS&C\"], \n",
    "                                                              order_by = pl.when(pl.col(\"direction\") == \"up\"\n",
    "                                                                       ).then(pl.col(\"segmentTraversed\")\n",
    "                                                                              ).otherwise(pl.col(\"segmentTraversed\").reverse()))\n",
    "                           ).otherwise(0.0\n",
    "                                ).alias(\"distanceSinceS&C\")\n",
    ").collect()\n",
    "\n",
    "distanceToFirstPoints = traversedPoints.filter((pl.col(\"beenThroughS&C\") == 1)\n",
    "    ).group_by(\"trainSectionDerailmentPeriodDirectionID\"\n",
    "    ).agg(pl.col(\"distanceBetweenTwoSegments\").min().alias(\"distanceToFirstPoints\"))\n",
    "\n",
    "# streaming = False - the cumulative operations force us out of streaming mode. This table is likely to become very large; we might need to \n",
    "# batch this operation in subsequent versions of the algorithm (partition by service section).\n",
    "\n",
    "\n",
    "# Using the \"segmentTraversedHasS&C\" flag we can reset the lateral displacement value and the deceleration rate to reflect the change in \n",
    "# derailment type. The subsequentPointsInitLatDisplac represents an additional value added during the displacement calculation in the \n",
    "# next step. \n",
    "lazyUpdatedDerailments = pl.LazyFrame(traversedPoints.with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"beenThroughS&C\") == 1 #Polars doesn't do truthy statements (i.e. in Polars 1 != True)\n",
    "        ).then(\n",
    "            subsequentPointsInitialLateralDisplacement\n",
    "        ).otherwise(0.0\n",
    "            ).alias(\"subsequentPointsInitLatDisplac\"),\n",
    "    # The deceleration rate only changes when the train goes through an S&C if its current deceleration rate is lower than T1s decel rate\n",
    "    pl.when(\n",
    "        pl.col(\"beenThroughS&C\") == 1\n",
    "        ).then(\n",
    "            pl.max_horizontal(derailmentType.filter(pl.col(\"derailmentTypeID\") == \"T1\").select(\"decelerationRate(m/s^2)\").item(), pl.col(\"decelerationRate(m/s^2)\"))\n",
    "        ).otherwise(pl.col(\"decelerationRate(m/s^2)\")\n",
    "            ).alias(\"secondDecelerationRate(m/s^2)\")\n",
    ").join(distanceToFirstPoints,\n",
    "    on=\"trainSectionDerailmentPeriodDirectionID\", how=\"left\", coalesce=True\n",
    ").fill_null(0\n",
    ").with_columns(\n",
    "    (np.sqrt((pl.col(\"derailmentSpeed(m/s)\")**2) - (2* pl.col(\"distanceToFirstPoints\") * pl.col(\"decelerationRate(m/s^2)\")))\n",
    "     ).alias(\"speedAtFirstPoints\")\n",
    ").with_columns(\n",
    "    (pl.col(\"distanceToFirstPoints\") + ((pl.col(\"speedAtFirstPoints\")**2)/(2*pl.col(\"secondDecelerationRate(m/s^2)\")))\n",
    "     ).alias(\"secondDerailmentDistance\")\n",
    ").filter(pl.col(\"secondDerailmentDistance\") >= pl.col(\"distanceBetweenTwoSegments\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "512f6819-4b61-4993-ac46-09a0624c97e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Cone\n",
    "\n",
    "The derailment cone algorithm is complex, but it basically produces output in the form of **left and right displacement** at each segment traversed during a specific derailment scenario. \n",
    "\n",
    "The **vertical direction** (_left or right_) is determined using a combination of the horizontal direction (_up or down_) and the sign of the curvature (_positive or negative_).\n",
    "\n",
    "The **lateral displacements** are calculated for the _closer_ and _further away_ sides. These are calculated as follows:\n",
    "- **closerSide** = initialLateralDisplacement + lateralDisplacementDueToSubsequentPoints \n",
    "- **furtherAwaySide** = initialLateralDisplacement + lateralDisplacementDueToSubsequentPoints + lateralDisplacementDueToSubsequentCurves\n",
    "\n",
    "In turn each of these values are subject to their own formulas and conditions. These are explained in more detailed in the body of the algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3f1f3ddc-f993-4ea2-a9e6-5035936ae965",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentCones = lazyUpdatedDerailments.join(\n",
    "    lazyDerailmentType.select(\"derailmentTypeID\", \"initialLateralDisplacement\"), \n",
    "    on=\"derailmentTypeID\", how =\"inner\"\n",
    ").join(\n",
    "    lazyMitigationScenarios, \n",
    "    how=\"cross\"\n",
    ").with_columns(\n",
    "    # Subsequent curves only influence the outcome under specific circumstances. Derailments T2 and T7 need curves to happen. Curves also \n",
    "    # contribute in other derailments when they aren't 0. This could be computed directly during the calculation but this added step here\n",
    "    # improves clarity.\n",
    "    pl.when((pl.col(\"derailmentTypeID\") == \"T2\") | \n",
    "            (pl.col(\"derailmentTypeID\") == \"T7\") | \n",
    "            (pl.col(\"segmentTraversedCurvature\") != 0)\n",
    "            ).then(True\n",
    "            ).otherwise(False\n",
    "                        ).alias(\"subsequentCurvesApply\")\n",
    ").with_columns( \n",
    "    # The effect of points is subject to more complicated conditions. The basic idea is that there are two major conditions that\n",
    "    # must be fulfilled at the same time: condition A, consisting of three subconditions any of which would satisfy condition A, \n",
    "    # and condition B. Condition B is simply the train having traversed S&C points before as given by the flag \"segmentTraversedHasS&C\"\n",
    "    # Condition A consists of the following: A1 (derailment type == T4 or T6, A2 (derailment type == T3 and subsequent curves do NOT apply)\n",
    "    # and A3 (derailment type == T5  and subsequent curves do NOT apply).\n",
    "    pl.when(\n",
    "            (\n",
    "            ((pl.col(\"derailmentTypeID\") == \"T4\") | \n",
    "             (pl.col(\"derailmentTypeID\") == \"T6\")) |\n",
    "             ((pl.col(\"derailmentTypeID\") == \"T3\") & (~pl.col(\"subsequentCurvesApply\"))) |\n",
    "             ((pl.col(\"derailmentTypeID\") == \"T5\") & (~pl.col(\"subsequentCurvesApply\")))\n",
    "             ) & (pl.col(\"segmentTraversedHasS&C\") == 1)\n",
    "            ).then(True\n",
    "            ).otherwise(False\n",
    "                        ).alias(\"subsequentPointsApply\")\n",
    ").with_columns(\n",
    "    # Derailment types T1 and T2 need to occur on points and a curve respectively. This condition creates a flag that ensures this is the case\n",
    "    (pl.when(pl.col(\"derailmentTypeID\") == \"T1\"\n",
    "            ).then(pl.when(pl.col(\"derailmentSegmentHasS&C\")\n",
    "                           ).then(True\n",
    "                           ).otherwise(False)\n",
    "            ).otherwise(pl.when(pl.col(\"derailmentTypeID\") == \"T2\"\n",
    "                                ).then(pl.when(pl.col(\"derailmentSegmentCurvature\") > 0\n",
    "                                               ).then(True\n",
    "                                               ).otherwise(False)\n",
    "                                ).otherwise(True)\n",
    "            )\n",
    "        ).alias(\"scenarioApplies\"), \n",
    "    (pl.when(\n",
    "    # The direction of the curve is used in the lateralisation of the displacement. The curvature is positive if the track is curving to the \n",
    "    # left hand side of the travelling direction. The original algorithm used the measure of \"worst side\" to conceptualize this; the worst side\n",
    "    # is the side of the direction of the curve, as the train has the greatest potential displacement on that side. This measure is NOT \n",
    "    # brought over to the Python algorithm as it is not needed.  \n",
    "        ((np.sign(pl.col(\"segmentTraversedCurvature\")) == 1) & (pl.col(\"direction\") == \"down\")) |\n",
    "        ((np.sign(pl.col(\"segmentTraversedCurvature\")) == -1) & (pl.col(\"direction\") == \"up\")) |\n",
    "        ((np.sign(pl.col(\"segmentTraversedCurvature\")) == 0) & (pl.col(\"direction\") == \"up\"))\n",
    "            ).then(pl.lit(\"Right\")\n",
    "            ).otherwise(pl.lit(\"Left\"))\n",
    "        ).alias(\"curveDirection\")\n",
    ").with_columns(\n",
    "    # Checking that encountering subsequent curves affects lateral displacement\n",
    "    (pl.when(pl.col(\"subsequentCurvesApply\")\n",
    "    # The absolute value of the calculation is important because of the way that the total lateral displacement is calculated\n",
    "    # The total lateral displacement is the minimum between the max lateral displacement possible (15m) and the sum of all contributing\n",
    "    # factors. The curvature values we are working with are very high (1000s). As such a very high negative value would indicate that \n",
    "    # displacement would be thousands of meters to the opposite direction of the curve. This doesn't conceptually make sense. \n",
    "            ).then(np.abs(pl.col(\"segmentTraversedCurvature\") - \n",
    "                   (np.sqrt(np.power(pl.col(\"segmentTraversedCurvature\"), 2) - (np.power(pl.col(\"segmentTraversedCurvature\"), 2) / 4))))\n",
    "                   ).otherwise(0.0\n",
    "                               )\n",
    "                ).alias(\"lateralDisplacementCurve\"), \n",
    "    (pl.when(pl.col(\"subsequentPointsApply\")\n",
    "             ).then(pl.col(\"beenThroughS&C\") * (pl.col(\"distanceSinceS&C\") * lateralDisplacementConstant + pl.col(\"subsequentPointsInitLatDisplac\"))\n",
    "                    ).otherwise(0.0)\n",
    "             ).alias(\"lateralDisplacementPoints\")\n",
    ").with_columns(\n",
    "    # scenarioApplies is our most important flag - if it is set to False then the scenario is impossible (e.g. T1 derailment not happening\n",
    "    # on an S&C) and hence the lateral displacement for this scenario should be 0. Subsequent filtering removes all segments belonging\n",
    "    # to these derailments (except the derailmentSegment) as they do not contribute anything of value. \n",
    "    (pl.when(pl.col(\"scenarioApplies\")\n",
    "            ).then(pl.min_horizontal(\n",
    "                pl.sum_horizontal(\"initialLateralDisplacement\", \"lateralDisplacementCurve\", \"lateralDisplacementPoints\"),\n",
    "                 maxLateralDeviation)\n",
    "                   ).otherwise(0.0)\n",
    "            ).alias(\"totalLateralDisplacementFurtherAwaySide\"),\n",
    "    (pl.when(pl.col(\"scenarioApplies\")\n",
    "             ).then(pl.min_horizontal(\n",
    "                pl.sum_horizontal(\"initialLateralDisplacement\", \"lateralDisplacementPoints\"),\n",
    "                 maxLateralDeviation)\n",
    "                   ).otherwise(0.0)\n",
    "            ).alias(\"totalLateralDisplacementCloserSide\")\n",
    ").with_columns(\n",
    "    (pl.when(pl.col(\"curveDirection\") == \"Left\"\n",
    "            ).then(pl.col(\"totalLateralDisplacementCloserSide\")\n",
    "                   ).otherwise(\"totalLateralDisplacementFurtherAwaySide\")\n",
    "            ).alias(\"Total Left Displacement\"),\n",
    "    (pl.when(pl.col(\"curveDirection\") == \"Right\"\n",
    "            ).then(pl.col(\"totalLateralDisplacementCloserSide\")\n",
    "                   ).otherwise(\"totalLateralDisplacementFurtherAwaySide\")\n",
    "            ).alias(\"Total Right Displacement\")    \n",
    ").filter(\n",
    "    (pl.col(\"scenarioApplies\") == True) | \n",
    "    ((pl.col(\"scenarioApplies\") == False) & (pl.col(\"derailmentSectionID\") == pl.col(\"segmentTraversed\")))\n",
    "    # We are filtering out all instances where the scenario does NOT apply, except for instances where the derailment Section ID equals the\n",
    "    # segment traversed ID. This effectively only keeps the first segment of derailment scenarios that cannot occur, showing that they \n",
    "    # have been calculated, and that they do not result in displacement. \n",
    ").with_columns(\n",
    "    pl.concat_str(pl.col(\"trainSectionDerailmentPeriodDirectionID\").cast(pl.String), pl.col(\"scenarioID\").cast(pl.String), separator = \"_\").alias(\"coneID\").cast(pl.Categorical)\n",
    ")\n",
    "\n",
    "#streaming=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b80562c-6e02-4004-a2b1-0c6430abb77d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Consolidating the categorical values we will need further on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d046c28c-0430-4ae5-8ccc-ab85fc1d694c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentCones = pl.LazyFrame(lazyDerailmentCones.collect(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc906a42-dab3-4f38-82e2-8d8c833b5314",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Cone Lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ec6e251b-333f-4daf-bd55-f0750ee182a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentConeSegments = pl.LazyFrame(lazyDerailmentCones.group_by(\"coneID\").agg(pl.col(\"segmentTraversed\").count().alias(\"coneLength(Sections)\")).collect())\n",
    "\n",
    "# Here because we have manifested the coneID field once, it has been successfully encoded \n",
    "# We can confirm this by assigning two calls of lazyDerailmentConeLengths to two variables and testing to see if they are equal\n",
    "lazyDerailmentConeLengths = lazyDerailmentCones.join(\n",
    "  lazyDerailmentConeSegments, \n",
    "  on = \"coneID\", how = \"inner\"\n",
    ").select(\n",
    "  pl.col(\"coneID\"),\n",
    "  pl.col(\"trainSectionDerailmentPeriodDirectionID\"), \n",
    "  pl.col(\"scenarioID\"), \n",
    "  pl.col(\"secondDerailmentDistance\").alias(\"coneLength(m)\"),\n",
    "  pl.col(\"coneLength(Sections)\")\n",
    ")\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b9bdc10-7882-4dca-910d-3a2f76553240",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Assets in Cone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "39d503b4-129a-4f8e-97d8-587896940716",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyAssetInCone = lazyDerailmentCones.join(lazyAssetInSection,\n",
    "    left_on=\"segmentTraversed\", right_on=\"sectionID\", how = \"inner\", suffix=\"Asset\"\n",
    ").with_columns(\n",
    "    # In lazyAssetInSection the assets are always on the left hand side of the track and hence are described as being either in the \"up\" or \n",
    "    # \"down\" direction. Here we reconcile this difference. \n",
    "    pl.when(pl.col(\"directionAsset\") == pl.col(\"direction\")\n",
    "            ).then(pl.lit(\"Left\")\n",
    "            ).otherwise(pl.lit(\"Right\")\n",
    "                         ).alias(\"leftOrRight\")\n",
    ").with_columns(\n",
    "    # Assets further away from the track than the displacement of the train at this specific segment are defined as outside the cone\n",
    "    (pl.when((pl.col(\"leftOrRight\") == \"Left\") & \n",
    "             ((pl.col(\"distance_from_section_route\")) <= pl.col(\"Total Left Displacement\"))\n",
    "             ).then(pl.lit(True)\n",
    "                    ).otherwise(pl.lit(False)) | \n",
    "             (pl.when((pl.col(\"leftOrRight\") == \"Right\") & \n",
    "                      (pl.col(\"distance_from_section_route\") <= pl.col(\"Total Right Displacement\"))\n",
    "                      ).then(pl.lit(True)\n",
    "                             ).otherwise(pl.lit(False)))\n",
    "             ).alias(\"inCone\")\n",
    "  )\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4942919d-6709-4546-9058-9655c8cdf364",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Section In Cone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ea7b6d24-a1b1-4dda-9246-6e12cca00234",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazySectionInCone = lazyDerailmentCones.with_columns(\n",
    "    pl.concat_str(pl.col(\"coneID\").cast(pl.String), pl.col(\"segmentTraversed\").cast(pl.String)).alias(\"sectionInConeID\").cast(pl.Categorical)\n",
    "  ).select(\n",
    "      pl.col(\"sectionInConeID\"),\n",
    "      pl.col(\"coneID\"), \n",
    "      pl.col(\"segmentTraversed\"),\n",
    "      pl.col(\"Total Left Displacement\"), \n",
    "      pl.col(\"Total Right Displacement\")       \n",
    "  )\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9053ccbc-5b8a-4e73-8801-42e37aa7e933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29d206c-1ebc-4d48-b2a7-9287c6cc5cb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Calculated Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5345c752-cf14-4430-b3e8-d5dd02a7413a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Train derailment on a section in a direction by precursor per Period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a3995f84-35bc-4ee2-ac1b-975d22dcefe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This is essentially a conversion of km to section segments. As this is spread out over the network we take the mean section length \n",
    "section_length_km = sectionSegments.select(\"length(m)\").mean().item()/1000 \n",
    "\n",
    "lazyTrainDerailments = lazyDerailmentSpeed.select(\n",
    "         \"trainSectionDerailmentPeriodDirectionID\", \n",
    "         \"sectionID\", \n",
    "         \"direction\", \n",
    "         \"trainGroupID\", \n",
    "         \"periodID\", \n",
    "         \"derailmentTypeID\", \n",
    ")\n",
    "# By joining the lazyTrainSectionDirectionPeriod lazyframe to the lazyLevelCrossing lazyframe with a left join we can identify the  \n",
    "# derailments starting on a LX. This is a prerequisite for certain precursors.\n",
    "lazyTrainGroupLXSectionDirectionPeriod = lazyTrainDerailments.join(\n",
    "    lazyTrainGroup.select(\n",
    "        \"trainGroupID\", \"trainType\", \"vehicleLength\", \"frequencyUp\", \"frequencyDown\"), \n",
    "    on = \"trainGroupID\", how = \"inner\"\n",
    ").join(lazyLevelCrossings.select(\n",
    "        \"sectionID\", pl.col(\"levelCrossingType\").alias(\"levelCrossingTypePresent\")), \n",
    "       on = \"sectionID\", how = \"left\", coalesce = True\n",
    ").with_columns(\n",
    "    (pl.when(pl.col(\"direction\") == \"up\"\n",
    "             ).then(pl.col(\"frequencyUp\")\n",
    "                    ).otherwise(pl.col(\"frequencyDown\"))\n",
    "             ).alias(\"frequency\")\n",
    ")\n",
    "\n",
    "# streaming = True\n",
    "\n",
    "# The derailment precursors are split into two groups - one for passenger trains and one for freight trains as they are liable to different \n",
    "# derailment precursors. Then each derailment scenario is associated with all the possible derailment precursors, and their national frequency\n",
    "# This means that each derailment scenario has a one-to-many relationship with its possible derailment types, which in turn have a one-to-many\n",
    "# relationship with their precursors.\n",
    "lazyPassengerDerailmentPrecursors = lazyTrainGroupLXSectionDirectionPeriod.filter(\n",
    "    pl.col(\"trainType\") == \"Passenger\"\n",
    ").join(lazyPrecursorDerailmentMap.filter(\n",
    "    # We need to cast to String as the .str methods are not available for Categorical data\n",
    "    (pl.col(\"precursorID\").cast(pl.String).str.ends_with(\"_P\")) | \n",
    "    (pl.col(\"precursorID\").cast(pl.String).str.starts_with(\"LX_\")) \n",
    "    ), how = \"cross\"\n",
    ").join(lazyPrecursor.select(\n",
    "        \"precursorID\", pl.col(\"nationalFrequency\").alias(\"precursorNationalFrequency\")), \n",
    "       on = \"precursorID\", how = \"inner\"\n",
    ")\n",
    "\n",
    "# streaming = True\n",
    "\n",
    "lazyFreightDerailmentPrecursors = lazyTrainGroupLXSectionDirectionPeriod.filter(\n",
    "    pl.col(\"trainType\") == \"Freight\"\n",
    ").join(lazyPrecursorDerailmentMap.filter(\n",
    "    (pl.col(\"precursorID\").cast(pl.String).str.ends_with(\"F\")) |\n",
    "    (pl.col(\"precursorID\").cast(pl.String).str.starts_with(\"LX_\"))), \n",
    "       how = \"cross\"\n",
    ").join(lazyPrecursor.select(\n",
    "        \"precursorID\", pl.col(\"nationalFrequency\").alias(\"precursorNationalFrequency\")), \n",
    "       on = \"precursorID\", how = \"inner\"\n",
    ")\n",
    "\n",
    "# streaming = True\n",
    "\n",
    "# Depending on the lazyPrecursor the excel is using a different normalization formula. These formulas can be grouped\n",
    "# and we use the flags in \"lazyPrecursor\" which indicate what sort of normalization it should undergo.\n",
    "# Here we calculate all of the normalizations for all the precursors but in the absence of a \"TRUE\" flag they are set \n",
    "# to zero. This is (surprisingly) faster than implementing extensive conditional logic. \n",
    "# Some of the expressions evaluate into boolean logic which also serve as gates to ensure that a non-zero value only\n",
    "# under specific conditions. These expressions are multiplied by 1 prior to multiplying them with the remainder of the \n",
    "# expression. This is done to force their conversion into an integer as polars doesn't support boolean multiplication.  \n",
    "lazyTrainSectionDirectionPeriodPrecursor = pl.concat(\n",
    "    [lazyPassengerDerailmentPrecursors, lazyFreightDerailmentPrecursors], \n",
    "           how=\"vertical\"\n",
    "    ).join(lazyLevelCrossingNormalizers, left_on= \"levelCrossingTypePresent\", right_on = \"levelCrossingType\", how = \"left\", coalesce = True\n",
    "    ).join(lazyLevelCrossings, on = \"sectionID\", how = \"left\", coalesce = True\n",
    "    ).join(lazyPeriod, on = \"periodID\", how = \"inner\"\n",
    "    ).join(lazyPrecursor, on = \"precursorID\", how = \"inner\"\n",
    "    ).join(lazySectionSegments.select([\"sectionID\", \"inTunnel\", \"curvature\"]), on = [\"sectionID\"], how = \"inner\"\n",
    "    ).join(lazyAssetInSection.select([\"sectionID\", \"direction\", \"assetTypeID\"]), left_on = [\"sectionID\", \"direction\"], right_on = [\"sectionID\", \"direction\"], how = \"left\", coalesce = True\n",
    "    ).join(lazyAssetDependentNormalizers.select(\n",
    "        [pl.col(\"trainType\"), \n",
    "         pl.col(\"precursorGroupID\"), \n",
    "         pl.col(\"trainKm\").alias(\"nationalAssetKm\"), \n",
    "         pl.col(\"assetTypeID\").alias(\"necessaryAssetPresent\")]), \n",
    "        on = [\"precursorGroupID\", \"trainType\"], how = \"left\", coalesce= True\n",
    "    ).with_columns(\n",
    "        ((pl.when(\n",
    "            pl.col(\"trainType\") == \"Passenger\"\n",
    "        )).then(\n",
    "            pl.max_horizontal(\n",
    "                (pl.max_horizontal(pl.col(\"tunnelIndependent\") * 1, \n",
    "                                  (pl.col(\"tunnelIndependent\") != pl.col(\"inTunnel\")) * 1)) * \n",
    "                pl.col(\"vehicleKmNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                vehicleKmPerYearPassenger * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\") * \n",
    "                pl.col(\"vehicleLength\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.max_horizontal(pl.col(\"tunnelIndependent\") * 1, \n",
    "                                   (pl.col(\"tunnelIndependent\") != pl.col(\"inTunnel\")) * 1)) * \n",
    "                pl.col(\"trainKmNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                trainKmPerYearPassenger * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"assetDependentNormalization\") * \n",
    "                ((pl.col(\"assetTypeID\") == pl.col(\"necessaryAssetPresent\")) * 1) * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                pl.col(\"nationalAssetKm\") * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"assetDependentSpecialNormalization\") * \n",
    "                ((pl.col(\"assetTypeID\") == pl.col(\"necessaryAssetPresent\")) * 1) * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/ \n",
    "                pl.col(\"nationalAssetKm\") * \n",
    "                pl.col(\"vehicleLength\") * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\")), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"levelCrossingDependentNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                ((pl.col(\"levelCrossingTypePresent\") == pl.col(\"levelCrossingType\")) *  1) * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                pl.col(\"totalLevelCrossingDerailmentRisk\") * \n",
    "                pl.col(\"levelCrossingDerailmentRisk\")), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"overspeedingNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                (((np.abs(pl.col(\"curvature\")) < 1000) & (pl.col(\"curvature\") != 0)) * 1) * \n",
    "                pl.col(\"precursorNationalFrequency\") / \n",
    "                pl.col(\"nationalAssetKm\") * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\")), \n",
    "                            0)\n",
    "        ).otherwise(\n",
    "            pl.max_horizontal(\n",
    "                pl.max_horizontal(\n",
    "                    pl.col(\"tunnelIndependent\") * 1, \n",
    "                    (pl.col(\"tunnelIndependent\") != pl.col(\"inTunnel\")) * 1) * \n",
    "                pl.col(\"vehicleKmNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                (pl.col(\"precursorNationalFrequency\")/\n",
    "                vehicleKmPerYearFreight * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\")) * \n",
    "                pl.col(\"vehicleLength\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                pl.max_horizontal(\n",
    "                    pl.col(\"tunnelIndependent\") * 1, \n",
    "                    (pl.col(\"tunnelIndependent\") != pl.col(\"inTunnel\")) * 1) * \n",
    "                pl.col(\"trainKmNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                trainKmPerYearFreight * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                pl.col(\"assetDependentNormalization\") * \n",
    "                ((pl.col(\"assetTypeID\") == pl.col(\"necessaryAssetPresent\")) * 1) * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                pl.col(\"nationalAssetKm\") * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\"), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"assetDependentSpecialNormalization\") * \n",
    "                ((pl.col(\"assetTypeID\") == pl.col(\"necessaryAssetPresent\")) * 1) * \n",
    "                 pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                 pl.col(\"precursorNationalFrequency\")/ \n",
    "                 pl.col(\"nationalAssetKm\") * \n",
    "                 pl.col(\"vehicleLength\") * \n",
    "                 section_length_km * \n",
    "                 pl.col(\"frequency\") * \n",
    "                 pl.col(\"lengthHours\") * \n",
    "                 pl.col(\"numPerYear\")), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"levelCrossingDependentNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                ((pl.col(\"levelCrossingTypePresent\") == pl.col(\"levelCrossingType\")) * 1) * \n",
    "                pl.col(\"precursorNationalFrequency\")/\n",
    "                pl.col(\"totalLevelCrossingDerailmentRisk\") * \n",
    "                pl.col(\"levelCrossingDerailmentRisk\")), \n",
    "                            0) +\n",
    "\n",
    "            pl.max_horizontal(\n",
    "                (pl.col(\"overspeedingNormalization\") * \n",
    "                pl.col(\"proportionOfPrecursorToDerailment\") * \n",
    "                (((np.abs(pl.col(\"curvature\")) < 1000) & (pl.col(\"curvature\") != 0)) * 1) * \n",
    "                pl.col(\"precursorNationalFrequency\") / \n",
    "                pl.col(\"nationalAssetKm\") * \n",
    "                section_length_km * \n",
    "                pl.col(\"frequency\") * \n",
    "                pl.col(\"lengthHours\") * \n",
    "                pl.col(\"numPerYear\")), \n",
    "                            0)\n",
    "        ).alias(\"derailmentFrequency\")\n",
    "    )\n",
    ")\n",
    "\n",
    "#collect(streaming=True)\n",
    "# streaming = True\n",
    "\n",
    "# Here our ID column \"derailmentScenarioWithPrecursor\" doensn't need to be manifested because it is not used for any joins\n",
    "lazyDerailmentFrequencyTrainSectionDirectionPeriodPrecursor = lazyTrainSectionDirectionPeriodPrecursor.with_columns(\n",
    "    pl.concat_str(\n",
    "        [\"trainGroupID\", \"sectionID\", \"direction\", pl.col(\"periodID\").cast(pl.String), \"mappingID\"], separator = \"_\"\n",
    "        ).alias(\"derailmentScenarioWithPrecursor\").cast(pl.Categorical)\n",
    "    ).select(\n",
    "        \"derailmentScenarioWithPrecursor\", \n",
    "        \"trainInSectionInDirectionID\", \n",
    "        \"mappingID\", \n",
    "        \"derailmentFrequency\")\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b333c06d-b284-4d2d-9d74-5f50959c8ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Train derailment on a section in a direction per period "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a5e2092d-a3f9-4825-91c1-a8f9cf9ec5d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lazyDerailmentFreuqencies is essentially an end DataFrame where we aggregate a result\n",
    "lazyDerailmentFrequencies = pl.LazyFrame(lazyTrainSectionDirectionPeriodPrecursor.group_by(\n",
    "    \"trainGroupID\", \"sectionID\", \"direction\",\"periodID\", \"derailmentTypeID\"\n",
    ").agg(pl.col(\"derailmentFrequency\").sum()\n",
    ").collect())\n",
    "\n",
    "# This is essentially \"lazyDerailmentFrequencyTrainSectionDirectionPeriodPrecursor\" but with an extra level of aggregation. \n",
    "# This table gives the normalized frequency of each derailment scenario\n",
    "lazyTrainDerailmentSectionDirectionPeriod = lazyTrainDerailments.join(\n",
    "  lazyDerailmentFrequencies, \n",
    "  on = [\"sectionID\", \"trainGroupID\", \"direction\", \"periodID\", \"derailmentTypeID\"], how = \"inner\"\n",
    ")\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d88be5f-fb91-4874-b027-bdb42d5de83b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Potential Train Collision \n",
    "For each train in a section in a direction finding the possible trains that they could collide with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8c7bafc5-4652-40c4-8c4b-6cf49120103e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailedTrains = lazyTrainSectionDirectionPeriod.join(\n",
    "   lazySectionSegments.select(\n",
    "        [\n",
    "            \"sectionID\", \"serviceSectionID\"\n",
    "        ]\n",
    "    ), on = \"sectionID\", how = \"inner\"\n",
    ").join(lazyTrainGroup.select(\n",
    "    [\n",
    "        \"trainGroupID\", \"serviceID\"\n",
    "    ]\n",
    "), on = \"trainGroupID\", how = \"inner\"\n",
    ").select(\n",
    "    [\n",
    "        pl.col(\"trainInSectionInDirectionID\").alias(\"derailedTrainSectionDirectionPeriodID\"),\n",
    "        pl.col(\"sectionID\").alias(\"derailmentSection\"), \n",
    "        pl.col(\"serviceID\").alias(\"derailedServiceID\"), \n",
    "        pl.col(\"direction\").alias(\"derailedTrainDirection\"),\n",
    "        pl.col(\"serviceSectionID\").alias(\"derailedTrainServiceSectionID\"), \n",
    "        pl.col(\"frequency\").alias(\"derailedTrainFrequency\"), \n",
    "        pl.col(\"trainGroupID\").alias(\"derailedTrainGroupID\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "lazyCollidingTrains = lazyTrainSectionDirectionPeriod.join(\n",
    "   lazySectionSegments.select(\n",
    "        [\n",
    "            \"sectionID\", \"serviceSectionID\"\n",
    "        ]\n",
    "    ), on = \"sectionID\", how = \"inner\"\n",
    ").join(lazyTrainGroup.select(\n",
    "    [\n",
    "        \"trainGroupID\", \"serviceID\"\n",
    "    ]\n",
    "), on = \"trainGroupID\", how = \"inner\"\n",
    ").select(\n",
    "    [\n",
    "        pl.col(\"trainInSectionInDirectionID\").alias(\"collidingTrainSectionDirectionPeriodID\"),\n",
    "        pl.col(\"sectionID\").alias(\"collisionSection\"), \n",
    "        pl.col(\"serviceID\").alias(\"collidingServiceID\"), \n",
    "        pl.col(\"direction\").alias(\"collidingTrainDirection\"),\n",
    "        pl.col(\"serviceSectionID\").alias(\"collidingTrainServiceSectionID\"), \n",
    "        pl.col(\"frequency\").alias(\"collidingTrainFrequency\"), \n",
    "        pl.col(\"expectedSpeedMPH\").alias(\"collidingTrainSpeedMPH\"),  \n",
    "        pl.col(\"trainGroupID\").alias(\"collidingTrainGroupID\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "lazyPotentialCollisions = lazyDerailedTrains.join(\n",
    "    lazyCollidingTrains, how = \"inner\", left_on=\"derailmentSection\", right_on=\"collisionSection\"\n",
    "    # the consecutive .filter() calls are used because \"&\" filtering ends streaming \n",
    ").filter( \n",
    "    (pl.col(\"derailedTrainDirection\") != pl.col(\"collidingTrainDirection\")))\n",
    "\n",
    "lazyTotalCollisionFrequency = pl.LazyFrame(lazyPotentialCollisions.group_by(\"derailedTrainSectionDirectionPeriodID\").agg(pl.col(\"collidingTrainFrequency\").sum().alias(\"totalCollidingTrainFrequency\")).collect())\n",
    "\n",
    "lazyPotentialCollisionFrequencies = pl.LazyFrame(lazyPotentialCollisions.join(\n",
    "    lazyTotalCollisionFrequency, on = \"derailedTrainSectionDirectionPeriodID\", how = \"inner\"\n",
    "    ).with_columns(\n",
    "        [pl.concat_str([\"derailedTrainSectionDirectionPeriodID\", \n",
    "                        \"collidingTrainSectionDirectionPeriodID\"], separator = \"_\").cast(pl.Categorical).alias(\"potentialCollisionID\"), \n",
    "         (pl.col(\"collidingTrainFrequency\")/pl.col(\"totalCollidingTrainFrequency\")).alias(\"probCollisionWithSpecificTrain\")]\n",
    "    ).select(\n",
    "            [\"potentialCollisionID\", \n",
    "             \"derailedTrainSectionDirectionPeriodID\", \n",
    "             \"collidingTrainSectionDirectionPeriodID\",\n",
    "             \"derailedTrainGroupID\", \n",
    "             \"collidingTrainGroupID\",  \n",
    "             \"collidingTrainFrequency\", \n",
    "             \"totalCollidingTrainFrequency\", \n",
    "             \"probCollisionWithSpecificTrain\", \n",
    "             \"collidingTrainSpeedMPH\"]\n",
    "    ).collect(streaming=True)\n",
    ")\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd20749-3d14-4120-baea-e72e4a6752fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Secondary Collision Probability \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "62281f2c-453f-485c-903d-7fc0af4e1f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating a numpy array using the columns necessary to calculate the secondary collision probability \n",
    "array = lazyPotentialCollisionFrequencies.select(\n",
    "  pl.col(\"potentialCollisionID\"),\n",
    "  pl.col(\"collidingTrainSpeedMPH\"), \n",
    "  pl.lit(9).alias(\"dummy_braking_rate\"), \n",
    "  pl.col(\"collidingTrainFrequency\")\n",
    "  ).collect().to_numpy()\n",
    "\n",
    "#We transform the data so that they can be used to make predictions using the model  \n",
    "transformation = (array[:,0], poly.fit_transform(array[:,1:]))\n",
    "coefficients = model.coef_\n",
    "\n",
    "lazyTransformedArray = pl.LazyFrame(\n",
    "  data = {\n",
    "    \"potential_collision_ID_str\" : transformation[0],\n",
    "    \"transformed_values\" : transformation[1]\n",
    "  }\n",
    ")\n",
    "\n",
    "lazyCoefficients = pl.LazyFrame(\n",
    "  data = {\n",
    "    \"coefficients\" : coefficients \n",
    "  }\n",
    ")\n",
    "\n",
    "lazyTransformedArrayWithCoeff = lazyTransformedArray.join(lazyCoefficients, how = \"cross\")\n",
    "\n",
    "lazySecondaryCollisions = lazyPotentialCollisionFrequencies.join(\n",
    "  lazyTransformedArrayWithCoeff, left_on = pl.col(\"potentialCollisionID\").cast(pl.String), right_on = \"potential_collision_ID_str\", how = \"inner\"\n",
    "  ).with_columns(\n",
    "    (pl.col(\"transformed_values\") * pl.col(\"coefficients\")).alias(\"values_times_coefficients\")\n",
    "  ).with_columns(\n",
    "    (pl.col(\"values_times_coefficients\").arr.sum()).alias(\"probability\")\n",
    "  ).select(\n",
    "    \"potentialCollisionID\",\n",
    "    \"derailedTrainSectionDirectionPeriodID\",\n",
    "    \"collidingTrainSectionDirectionPeriodID\",\n",
    "    \"derailedTrainGroupID\", \n",
    "    \"collidingTrainGroupID\",\n",
    "    \"collidingTrainSpeedMPH\",\n",
    "    \"probability\"\n",
    "  )\n",
    "\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6039d2c4-a032-42db-bb17-83820051137e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Asset type in Cone \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "faf8d74b-aa77-4e29-a9fe-056a3344ca7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assetTypeInCone = lazyAssetInCone.filter(\n",
    "    pl.col(\"inCone\") == True\n",
    ").group_by([\"coneID\", \"assetTypeID\"]\n",
    ").agg(pl.col(\"segmentTraversed\").count().alias(\"segmentsWithAssetInCone\")).collect()\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb11320d-5903-4119-b3be-6d90ec9a9701",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Cone with potential Collision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "79f0c1b5-997b-4c74-b7c7-47b3b39f8822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentConePotentialCollision = lazyDerailmentCones.filter(pl.col(\"derailmentSectionID\") == pl.col(\"segmentTraversed\")\n",
    ").select(\n",
    "    \"coneID\",\"derailmentTypeID\", \"derailmentSectionID\", \"derailmentSpeed(m/s)\", \"direction\", \"periodID\", \"trainGroupID\", \"trainSectionDerailmentPeriodDirectionID\"\n",
    ").join(lazyTrainSectionDirectionPeriod, \n",
    "left_on = [\"derailmentSectionID\", \"direction\", \"periodID\", \"trainGroupID\"], right_on = [\"sectionID\", \"direction\", \"periodID\", \"trainGroupID\"], how = \"inner\"\n",
    ").join(\n",
    "    lazyPotentialCollisionFrequencies, \n",
    "left_on = \"trainInSectionInDirectionID\", right_on = \"derailedTrainSectionDirectionPeriodID\", how = \"inner\"\n",
    ").with_columns(\n",
    "    pl.concat_str(pl.col(\"coneID\"), pl.col(\"potentialCollisionID\"), separator = \"_\").alias(\"derailmentConePotentialCollisionID\").cast(pl.Categorical)\n",
    ").select(\n",
    "    pl.col(\"derailmentConePotentialCollisionID\"),\n",
    "    pl.col(\"trainSectionDerailmentPeriodDirectionID\"),\n",
    "    pl.col(\"derailmentTypeID\"),\n",
    "    (pl.col(\"derailmentSpeed(m/s)\")/speedConversionConstant).alias(\"derailmentSpeedMPH\"),\n",
    "    pl.col(\"derailmentSectionID\").alias(\"sectionID\"),\n",
    "    pl.col(\"coneID\"), \n",
    "    pl.col(\"potentialCollisionID\")\n",
    ")\n",
    "# collect(streaming=True) (26/09/2024)\n",
    "# streaming = True (26/09/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e47feb9d-cab5-4456-b644-ccd261718f31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerailmentConePotentialCollision = pl.LazyFrame(lazyDerailmentConePotentialCollision.collect(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e31663c-2918-4e3c-bee9-05165e8eef3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Derailment Cone Cutset with Potential Collision\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55c2bd40-74b9-4b6e-8ca4-e9164e2aa52d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Escalation Cutsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bdc9c23-40fd-4bb3-892c-9edfed34f7b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Asset types encountered \n",
    "This LazyFrame contains two boolean flags, one for significant structures and one for small structures, as well as a list field that contains all the stucture IDs that are found **_WITHIN_** the derailment cone for each derailment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b7722005-659f-45c2-9b4e-03309c399f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Constructing the lazy_asset_types_encountered LazyFrame which is used to run the calculations natively on the API\n",
    "#We at first create columns \"significant_structure_present\" and \"small_structure_present\" that have a \"1\" and \"0\" in them depending on \n",
    "#the presence of a significant structure/ small structure in the section of the cone \n",
    "#Then we aggregate by derailment cone. \n",
    "lazyAssetTypesEncountered = pl.LazyFrame(assetTypeInCone.with_columns(\n",
    "    pl.when(pl.col(\"assetTypeID\").is_in(assetType.filter(pl.col(\"significant_structure\") == True).select(\"assetTypeID\").to_series())\n",
    "            ).then(True\n",
    "                   ).otherwise(False\n",
    "    ).alias(\"significant_structure_present\"), \n",
    "    pl.when(pl.col(\"assetTypeID\").is_in(assetType.filter(pl.col(\"small_structure\") == True).select(\"assetTypeID\").to_series())\n",
    "            ).then(True\n",
    "                   ).otherwise(False\n",
    "    ).alias(\"small_structure_present\")\n",
    "    ).group_by(\"coneID\").agg(\n",
    "        pl.col(\"assetTypeID\").alias(\"asset_type_IDs_encountered\"), \n",
    "        pl.col(\"significant_structure_present\").max(), \n",
    "        pl.col(\"small_structure_present\").max())\n",
    ")\n",
    "\n",
    "# collect(streaming=True) (26/09/2024)\n",
    "# streaming = True (26/09/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e81d8fd5-01ab-481b-8634-0ca5d32021c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Converting previous DataFrames into LazyFrames so that they can be used to run calculations natively\n",
    "#lazy_all_derailment_cones is used to calculate the derailment speed for each derailment and lazy_potential_train_collision...\n",
    "#is used to extract data regarding the possible train collisions. \n",
    "lazyConeID = lazyDerailmentCones.filter(pl.col(\"derailmentSectionID\") == pl.col(\"segmentTraversed\")\n",
    ").select([\"coneID\", \"trainSectionDerailmentPeriodDirectionID\"])\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming=True\n",
    "\n",
    "lazyDerailmentswithConeID = lazyDerailmentConeLengths.join(lazyConeID, on = \"coneID\", how = \"inner\")\n",
    "\n",
    "# collect(streaming=True) (26/09/2024)\n",
    "# streaming=True (26/09/2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "137cd132-cf9f-491e-a6c5-c78645ab009b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Finally we divide the value derived by the function by the conversion rate of mph_to_m/s as calculating the probability of a secondary \n",
    "#collision requires the value in mph. \n",
    "lazyDerailmentConesAndSpeeds = lazyDerailmentCones.filter(pl.col(\"derailmentSectionID\") == pl.col(\"segmentTraversed\")\n",
    ").select(\n",
    "    \"coneID\", \"trainSectionDerailmentPeriodDirectionID\"\n",
    ").join(\n",
    "    lazyDerailmentSpeed,\n",
    "    on = \"trainSectionDerailmentPeriodDirectionID\", how = \"inner\"\n",
    ").with_columns(\n",
    "    (pl.col(\"derailment_speed_m/s\")/ speedConversionConstant).alias(\"derailmentSpeedMPH\")\n",
    ").select(\n",
    "    \"coneID\", \"trainSectionDerailmentPeriodDirectionID\", \"derailmentSpeedMPH\", \"derailmentTypeID\", \"sectionID\"\n",
    ")\n",
    "\n",
    "# collect(streaming=True) (26/09/2024)\n",
    "# streaming=True (26/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f1b5a86-1f1a-41e0-92c5-5f7e3832d44b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Calculation of escalation probabilities\n",
    "The probabilities of individual escalations depend entirely on the context of the derailment and subsequent collision (i.e. train type, derailment type etc). The gates only determine which escalations are applicable in each scenario. \n",
    "By calculating the probability for each escalation before involving the cutsets we reduce the memory burden of the algorithm substantially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fcc0396f-0598-4b3b-8710-7ac207dad177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Joining all the LazyFrames created prior to the calculation step\n",
    "#Note that two seperate fill_null statements were necessary. This is because the \"asset_type_IDs_encountered\" field contains a Struct\n",
    "#object which is necessary for calculations. \n",
    "#Therefore we first fill null values (i.e. cones that do not have assets within them) with [0] as 0 is not a valid asset type ID,\n",
    "#and then we fill the significant_structure/small_structure_present fields with False to indicate they do not encounter any such assets. \n",
    "#This works because Polars only fills out fields of the same data type - it infers [0] as a Struct, and False as a Boolean.\n",
    "\n",
    "escalationProbabilities = lazyDerailmentConePotentialCollision.join(lazyAssetTypesEncountered, on = \"coneID\", how = \"left\", coalesce = True \n",
    ").join(lazySecondaryCollisions, on = \"potentialCollisionID\", how = \"inner\"\n",
    ").join(lazySectionSegments.select(\"sectionID\", \"lineSpeedMPH\"), on=\"sectionID\", how=\"inner\"\n",
    ").join(lazyEmbankmentHeights, on = \"sectionID\", how = \"inner\"\n",
    ").join(lazyTrainGroup.select(\n",
    "        [pl.col(\"trainGroupID\").alias(\"derailedTrainGroupID\"), \n",
    "         pl.col(\"trainType\").alias(\"derailedTrainType\"),\n",
    "         pl.col(\"power\").cast(pl.Categorical).alias(\"derailed_train_power\"), \n",
    "         pl.col(\"carryingHazGoods\").alias(\"derailedTrainHazGoods\"), \n",
    "         pl.col(\"carryingFlamGoods\").alias(\"derailedTrainFlamGoods\"), \n",
    "         pl.col(\"crashworthiness\").alias(\"derailedTrainCrashworthiness\"),\n",
    "         pl.col(\"loading\").alias(\"derailedTrainLoading\"),\n",
    "         pl.col(\"vehicleLength\").alias(\"derailedTrainLength\")]), on = \"derailedTrainGroupID\", how = \"inner\"\n",
    ").join(lazyTrainGroup.select(\n",
    "        [pl.col(\"trainGroupID\").alias(\"collidingTrainGroupID\"), \n",
    "         pl.col(\"trainType\").alias(\"collidingTrainType\"),\n",
    "         pl.col(\"power\").cast(pl.Categorical).alias(\"colliding_train_power\"), \n",
    "         pl.col(\"crashworthiness\").alias(\"collidingTrainCrashworthiness\"),\n",
    "         pl.col(\"carryingHazGoods\").alias(\"collidingTrainHasGoods\"), \n",
    "         pl.col(\"loading\").alias(\"collidingTrainLoading\"),\n",
    "         pl.col(\"carryingFlamGoods\").alias(\"collidingTrainFlamGoods\")]), on = \"collidingTrainGroupID\", how = \"inner\"\n",
    ").fill_null([0]\n",
    ").fill_null(False\n",
    ").with_columns(\n",
    "  (pl.when(pl.col(\"significant_structure_present\") \n",
    "           ).then(probSignStructCollisionP\n",
    "                  ).otherwise(probSignStructCollisionN)\n",
    "    ).cast(pl.Float32\n",
    "          ).alias(\"significant_structure_collision_Y\"),\n",
    "    \n",
    "  ((pl.when(pl.col(\"significant_structure_present\")\n",
    "            ).then(probSignStructCollisionN\n",
    "                   ).otherwise(\n",
    "      1 - ((collisionForce * timeElapsed)**2)/(pl.min_horizontal(maxNumberOfVehicles, pl.col(\"derailedTrainLength\")) * vehicleMass * pl.col(\"derailmentSpeedMPH\") * (speedConversionConstant))**2))\n",
    "   ).cast(pl.Float32\n",
    "          ).alias(\"significant_structure_collapse_Y\"),\n",
    "\n",
    "  (pl.when(pl.col(\"small_structure_present\")\n",
    "           ).then(probSmallStructCollisionP\n",
    "                  ).otherwise(probSmallStructCollisionN)\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"small_structure_collision_Y\"),\n",
    "\n",
    "  (pl.when(\n",
    "    (pl.col(\"asset_type_IDs_encountered\").list.contains(\"viaduct\")) | \n",
    "    (pl.col(\"asset_type_IDs_encountered\").list.contains(\"underbridge\")) | \n",
    "    (pl.col(\"asset_type_IDs_encountered\").list.contains(\"retaining_walls_land\"))\n",
    "      ).then(probFallFromHeightP\n",
    "             ).otherwise(probFallFromHeightN)\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"fall_from_height_Y\"),\n",
    "\n",
    "  (pl.when(pl.col(\"asset_type_IDs_encountered\").list.contains(\"embankment\")\n",
    "           ).then(probFallFromEmbankmentP \n",
    "                  ).otherwise(probFallFromEmbankmentN)\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"fall_from_embankment_Y\"),\n",
    "\n",
    "  (pl.when(pl.col(\"asset_type_IDs_encountered\").list.contains(\"embankment\")\n",
    "           ).then(probFallInWaterP\n",
    "                  ).otherwise(probFallInWaterN)\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"fall_into_water_Y\"),\n",
    "\n",
    "  (pl.when((pl.col(\"derailmentTypeID\") == \"T7\") | \n",
    "           (pl.col(\"derailmentTypeID\") == \"T8\")\n",
    "           ).then(probFallOnSideP\n",
    "                  ).otherwise(P0 + ((P125 - P0)/( 1 + np.power((np.abs(np.power((pl.col(\"lineSpeedMPH\")/constantA),((np.log(2))/(np.log(V50/constantA)))) - 1)), K))))\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"fall_on_side_Y\"),\n",
    "  \n",
    "  (pl.when(pl.col(\"probability\") < 0\n",
    "           ).then(0.001\n",
    "                  ).otherwise(pl.col(\"probability\"))\n",
    "             ).cast(pl.Float32\n",
    "                     ).alias(\"secondary_collision_Y\"),\n",
    "\n",
    "  (((pl.when(pl.col(\"derailedTrainFlamGoods\")\n",
    "             ).then(probFlamGoodsReleaseP\n",
    "                    ).otherwise(\n",
    "                      pl.when(pl.col(\"derailed_train_power\") == \"Diesel\"\n",
    "                              ).then(1/(1+(np.exp(-1*(constantB + constantC * pl.col(\"lineSpeedMPH\")))))\n",
    "                                     ).otherwise(probFlamGoodsReleaseN)) + \n",
    "   pl.when(pl.col(\"collidingTrainFlamGoods\")\n",
    "           ).then(probFlamGoodsReleaseP \n",
    "                  ).otherwise(\n",
    "                    pl.when(pl.col(\"colliding_train_power\") == \"Diesel\"\n",
    "                            ).then(1/(1+(np.exp(-1*(constantB + constantC * pl.col(\"collidingTrainSpeedMPH\")))))\n",
    "                                   ).otherwise(probFlamGoodsReleaseN))) - \n",
    "   (pl.when(pl.col(\"derailedTrainFlamGoods\")\n",
    "            ).then(probFlamGoodsReleaseP \n",
    "                   ).otherwise(pl.when(pl.col(\"derailed_train_power\") == \"Diesel\"\n",
    "                                       ).then(1/(1+(np.exp(-1*(constantB + constantC * pl.col(\"lineSpeedMPH\")))))\n",
    "                                              ).otherwise(probFlamGoodsReleaseN)) * \n",
    "   pl.when(pl.col(\"collidingTrainFlamGoods\")\n",
    "           ).then(probFlamGoodsReleaseP \n",
    "              ).otherwise(pl.when(pl.col(\"colliding_train_power\") == \"Diesel\"\n",
    "                     ).then(1/(1+(np.exp(-1*(constantB + constantC * pl.col(\"collidingTrainSpeedMPH\")))))\n",
    "                            ).otherwise(probFlamGoodsReleaseN))))\n",
    "   ).cast(pl.Float32\n",
    "           ).alias(\"flam_goods_release(collision)_Y\"),\n",
    "  \n",
    "  (pl.when(pl.col(\"derailedTrainFlamGoods\")\n",
    "           ).then(probFlamGoodsReleaseP\n",
    "                  ).otherwise(\n",
    "                    pl.when(pl.col(\"derailed_train_power\") == \"Diesel\"\n",
    "                            ).then(1/(1+(np.exp(-1*(constantB + constantC * pl.col(\"lineSpeedMPH\")))))\n",
    "                                   ).otherwise(probFlamGoodsReleaseN))\n",
    "    ).cast(pl.Float32\n",
    "           ).alias(\"flam_goods_release(no_collision)_Y\"),\n",
    "\n",
    "  (((pl.when(pl.col(\"derailedTrainHazGoods\")\n",
    "             ).then(probHazGoodsReleaseP\n",
    "                    ).otherwise(probHazGoodsReleaseN)) + \n",
    "    (pl.when(pl.col(\"collidingTrainHasGoods\")\n",
    "             ).then(probHazGoodsReleaseP\n",
    "                    ).otherwise(probHazGoodsReleaseN))) - \n",
    "   ((pl.when(pl.col(\"derailedTrainHazGoods\")\n",
    "             ).then(probHazGoodsReleaseP\n",
    "                    ).otherwise(probHazGoodsReleaseN)) * \n",
    "    (pl.when(pl.col(\"collidingTrainHasGoods\")\n",
    "             ).then(probHazGoodsReleaseP\n",
    "                    ).otherwise(probHazGoodsReleaseN)))\n",
    "   ).cast(pl.Float32\n",
    "           ).alias(\"haz_goods_release(collision)_Y\"),\n",
    "\n",
    "  ((pl.when(pl.col(\"derailedTrainHazGoods\")\n",
    "            ).then(probHazGoodsReleaseP\n",
    "                   ).otherwise(probHazGoodsReleaseN))\n",
    "   ).cast(pl.Float32\n",
    "           ).alias(\"haz_goods_release(no_collision)_Y\"),\n",
    "\n",
    "  (pl.lit(probFireP)).cast(pl.Float32\n",
    "           ).alias(\"fire(flam_goods)_Y\"),\n",
    "  \n",
    "  (pl.lit(probFireN)).cast(pl.Float32\n",
    "           ).alias(\"fire(no_flam_goods)_Y\")\n",
    "  )\n",
    "  \n",
    "# collecting(streaming=True) (30/09/2024)\n",
    "# streaming=True (26/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a261a087-7d96-4f4a-b540-b22115f482e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Applying the escalation gates by scenario\n",
    "The escalation gates can be calculated using only the probability of the escalation occuring and calculating the probability of the escalation not occuring on the spot. The saves us having to call each function twice and saves us memory space by needing only one probability column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2909f792-c15f-480f-8130-06c9234e2e9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#We start by excluding all fields that were used in the calculation as they are no longer needed. \n",
    "# There is somewhere a square root with a negative value\n",
    "cutsetProbabilities = escalationProbabilities.join(\n",
    "    lazyCutsetMatrixC, how = \"cross\"\n",
    ").with_columns(\n",
    "   ( pl.when(\n",
    "        (pl.col(\"1Y\") * pl.col(\"significant_structure_collision_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"1Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"1Y\") * pl.col(\"significant_structure_collision_Y\")\n",
    "                           )).alias(\"significant_structure_collision_Y\"),\n",
    "               \n",
    "    (pl.when(\n",
    "        (pl.col(\"1N\") * (1 - pl.col(\"significant_structure_collision_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"1N\").cast(pl.Int8)\n",
    "                ).otherwise(pl.col(\"1N\") * (1 - pl.col(\"significant_structure_collision_Y\"))\n",
    "                            )).alias(\"significant_structure_collision_N\"),\n",
    "            \n",
    "    (pl.when(\n",
    "        (pl.col(\"2Y\") * pl.col(\"significant_structure_collapse_Y\")) == 0\n",
    "            ).then(1 - pl.col(\"2Y\").cast(pl.Int8)\n",
    "                   ).otherwise(pl.col(\"2Y\") * pl.col(\"significant_structure_collapse_Y\")\n",
    "                               )).alias(\"significant_structure_collapse_Y\"),\n",
    "                   \n",
    "   (pl.when(\n",
    "        (pl.col(\"2N\") * (1 - pl.col(\"significant_structure_collapse_Y\"))) == 0\n",
    "            ).then(1 - pl.col(\"2N\").cast(pl.Int8)\n",
    "                   ).otherwise(pl.col(\"2N\") * (1 - pl.col(\"significant_structure_collapse_Y\"))\n",
    "                               )).alias(\"significant_structure_collapse_N\"),\n",
    "   \n",
    "    (pl.when(\n",
    "        (pl.col(\"3Y\") * pl.col(\"small_structure_collision_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"3Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"3Y\") * pl.col(\"small_structure_collision_Y\")\n",
    "                           )).alias(\"small_structure_collision_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"3N\") * (1 - pl.col(\"small_structure_collision_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"3N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"3N\") * (1 - pl.col(\"small_structure_collision_Y\"))\n",
    "                           )).alias(\"small_structure_collision_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"4Y\") * pl.col(\"fall_from_height_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"4Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"4Y\") * pl.col(\"fall_from_height_Y\")\n",
    "                           )).alias(\"fall_from_height_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"4N\") * (1 - pl.col(\"fall_from_height_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"4N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"4N\") * (1 - pl.col(\"fall_from_height_Y\"))\n",
    "                           )).alias(\"fall_from_height_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"5Y\") * pl.col(\"fall_from_embankment_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"5Y\").cast(pl.Int8)\n",
    "               ).otherwise((pl.col(\"5Y\") * pl.col(\"fall_from_embankment_Y\"))\n",
    "                           )).alias(\"fall_from_embankment_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"5N\") * (1 - pl.col(\"fall_from_embankment_Y\"))) == 0 \n",
    "        ).then(1 - pl.col(\"5N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"5N\") * (1 - pl.col(\"fall_from_embankment_Y\"))\n",
    "                           )).alias(\"fall_from_embankment_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"6Y\") * pl.col(\"fall_into_water_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"6Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"6Y\") * pl.col(\"fall_into_water_Y\")\n",
    "                           )).alias(\"fall_into_water_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"6N\") * (1 - pl.col(\"fall_into_water_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"6N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"6N\") * (1 - pl.col(\"fall_into_water_Y\"))\n",
    "                           )).alias(\"fall_into_water_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"7Y\") * pl.col(\"fall_on_side_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"7Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"7Y\") * pl.col(\"fall_on_side_Y\")\n",
    "                           )).alias(\"fall_on_side_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"7N\") * (1 - pl.col(\"fall_on_side_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"7N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"7N\") * (1 - pl.col(\"fall_on_side_Y\"))\n",
    "                           )).alias(\"fall_on_side_N\"),\n",
    "  \n",
    "    (pl.when(\n",
    "        (pl.col(\"8Y\") * pl.col(\"secondary_collision_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"8Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"8Y\") * pl.col(\"secondary_collision_Y\")\n",
    "                           )).alias(\"secondary_collision_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"8N\") * (1 - pl.col(\"secondary_collision_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"8N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"8N\") * (1 - pl.col(\"secondary_collision_Y\"))\n",
    "                           )).alias(\"secondary_collision_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"9Y\") * pl.col(\"flam_goods_release(collision)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"9Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"9Y\") * pl.col(\"flam_goods_release(collision)_Y\")\n",
    "                           )).alias(\"flam_goods_release(collision)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"9N\") * (1 - pl.col(\"flam_goods_release(collision)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"9N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"9N\") * (1 - pl.col(\"flam_goods_release(collision)_Y\"))\n",
    "                           )).alias(\"flam_goods_release(collision)_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"10Y\") * pl.col(\"flam_goods_release(no_collision)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"10Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"10Y\") * pl.col(\"flam_goods_release(no_collision)_Y\")\n",
    "                           )).alias(\"flam_goods_release(no_collision)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"10N\") * (1 - pl.col(\"flam_goods_release(no_collision)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"10N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"10N\") * (1 - pl.col(\"flam_goods_release(no_collision)_Y\"))\n",
    "                           )).alias(\"flam_goods_release(no_collision)_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"11Y\") * pl.col(\"haz_goods_release(collision)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"11Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"11Y\") * pl.col(\"haz_goods_release(collision)_Y\")\n",
    "                           )).alias(\"haz_goods_release(collision)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"11N\") * (1 - pl.col(\"haz_goods_release(collision)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"11N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"11N\") * (1 - pl.col(\"haz_goods_release(collision)_Y\"))\n",
    "                           )).alias(\"haz_goods_release(collision)_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"12Y\") * pl.col(\"haz_goods_release(no_collision)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"12Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"12Y\") * pl.col(\"haz_goods_release(no_collision)_Y\")\n",
    "                           )).alias(\"haz_goods_release(no_collision)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"12N\") * (1 - pl.col(\"haz_goods_release(no_collision)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"12N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"12N\") * (1 - pl.col(\"haz_goods_release(no_collision)_Y\"))\n",
    "                           )).alias(\"haz_goods_release(no_collision)_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"13Y\") * pl.col(\"fire(flam_goods)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"13Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"13Y\") * pl.col(\"fire(flam_goods)_Y\")\n",
    "                           )).alias(\"fire(flam_goods)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"13N\") * (1 - pl.col(\"fire(flam_goods)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"13N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"13N\") * (1 - pl.col(\"fire(flam_goods)_Y\"))\n",
    "                           )).alias(\"fire(flam_goods)_N\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"14Y\") * pl.col(\"fire(no_flam_goods)_Y\")) == 0\n",
    "        ).then(1 - pl.col(\"14Y\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"14Y\") * pl.col(\"fire(no_flam_goods)_Y\")\n",
    "                           )).alias(\"fire(no_flam_goods)_Y\"),\n",
    "    \n",
    "    (pl.when(\n",
    "        (pl.col(\"14N\") * (1 - pl.col(\"fire(no_flam_goods)_Y\"))) == 0\n",
    "        ).then(1 - pl.col(\"14N\").cast(pl.Int8)\n",
    "               ).otherwise(pl.col(\"14N\") * (1 - pl.col(\"fire(no_flam_goods)_Y\"))\n",
    "                           )).alias(\"fire(no_flam_goods)_N\")\n",
    ").with_columns((pl.col(\"significant_structure_collision_Y\") * pl.col(\"significant_structure_collision_N\") * pl.col(\"significant_structure_collapse_Y\") * pl.col(\"significant_structure_collapse_N\") * pl.col(\"small_structure_collision_Y\") * pl.col(\"small_structure_collision_N\") * pl.col(\"fall_from_height_Y\") * pl.col(\"fall_from_height_N\") * pl.col(\"fall_from_embankment_Y\") * pl.col(\"fall_from_embankment_N\") * pl.col(\"fall_into_water_Y\") * pl.col(\"fall_into_water_N\") * pl.col(\"fall_on_side_Y\") * pl.col(\"fall_on_side_N\") * pl.col(\"secondary_collision_Y\") * pl.col(\"secondary_collision_N\") * pl.col(\"flam_goods_release(collision)_Y\") * pl.col(\"flam_goods_release(collision)_N\") * pl.col(\"flam_goods_release(no_collision)_Y\") * pl.col(\"flam_goods_release(no_collision)_N\") * pl.col(\"haz_goods_release(collision)_Y\") * pl.col(\"haz_goods_release(collision)_N\") * pl.col(\"haz_goods_release(no_collision)_Y\") * pl.col(\"haz_goods_release(no_collision)_N\") * pl.col(\"fire(flam_goods)_Y\") * pl.col(\"fire(flam_goods)_N\") * pl.col(\"fire(no_flam_goods)_Y\") * pl.col(\"fire(no_flam_goods)_N\")).alias(\"cutset_probability\")\n",
    ").filter(pl.col(\"cutset_probability\") > 0.0\n",
    ").select(\"derailmentConePotentialCollisionID\", \n",
    "         \"trainSectionDerailmentPeriodDirectionID\",\n",
    "         \"coneID\",\n",
    "         \"sectionID\", \n",
    "         \"potentialCollisionID\", \n",
    "         \"cutsetID\", \n",
    "         \"derailmentSpeedMPH\", \n",
    "         \"cutset_probability\",\n",
    "         \"collidingTrainSpeedMPH\",\n",
    "         \"derailedTrainType\",\n",
    "         \"derailed_train_power\",\n",
    "         \"derailedTrainLoading\",\n",
    "         \"collidingTrainType\",\n",
    "         \"colliding_train_power\",\n",
    "         \"collidingTrainLoading\", \n",
    "         \"derailedTrainCrashworthiness\",\n",
    "         \"collidingTrainCrashworthiness\", \n",
    "         \"derailedTrainGroupID\",\n",
    "         \"collidingTrainGroupID\", \n",
    "         \"embankmentHeight(m)\",\n",
    "         \"bridgeViaductHeight\",\n",
    "         pl.col(\"1Y\").alias(\"significantStructureCollision\"),\n",
    "         pl.col(\"2Y\").alias(\"significantStructureCollapse\"),\n",
    "         pl.col(\"3Y\").alias(\"smallStructureCollision\"),\n",
    "         pl.col(\"4Y\").alias(\"vehicleFallFromHeight\"),\n",
    "         pl.col(\"5Y\").alias(\"vehicleFallFromEmbankment\"),\n",
    "         pl.col(\"6Y\").alias(\"vehicleFallIntoWater\"),\n",
    "         pl.col(\"7Y\").alias(\"vehicleFallOnSide\"),\n",
    "         pl.col(\"8Y\").alias(\"secondaryCollision\"),\n",
    "         pl.col(\"9Y\").alias(\"toxicGoodRelease\"),\n",
    "         pl.col(\"10Y\").alias(\"toxicGoodRelease(noCollision)\"),\n",
    "         pl.col(\"11Y\").alias(\"flamGoodRelease\"),\n",
    "         pl.col(\"12Y\").alias(\"flamGoodRelease(noCollision)\"),\n",
    "         pl.col(\"13Y\").alias(\"fire(flamGoods)\"),\n",
    "         pl.col(\"14Y\").alias(\"fire(noFlamGoods)\")\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1db1762-0790-46d6-88a9-02952c0ebbbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Cutset Materialization\n",
    "This step has two aims: \n",
    "1) Reduces run time for everything downstream \n",
    "2) Stabilizes the lazyframe - because secondary collision is calculated using a regression model, we get variation in our zero values every time we call the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4ca63446-99b8-454a-abf8-e686ae139936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cutsetProbabilities = pl.LazyFrame(cutsetProbabilities.collect(streaming=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3488c6ef-9ec9-4750-ba33-25a956dc5916",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba7513d3-a52e-4d47-874c-370e5dffbcd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Injury Atoms\n",
    "Injury atoms are calculated in different ways depending on the group that they involve and the IA itself. They can however be grouped by some similarities:\n",
    "- **_Group 1_**: **derailmentIA** (passenger and workforce), **structureCollisionIA** (passenger and workforce), **structureCollapseIA** (passenger and workforce), and **fallOnSideIA** (passenger and workforce) are all calculated using the exact same methodology but with different constants\n",
    "- **smallStructureCollisionIA** calculated as structureCollisionIA * smallStructureConstant\n",
    "- **_Group 2_**:**secondaryCollision** (passenger and workforce for each train) and **Fire** (passenger and workforce for each train) are calculated using a lookup table \n",
    "- **_Group 3_**: **Haz** and **Flam** goods are set values \n",
    "- **_Group 4_**: **bridgeFall** and **embankmentFall** are calculated in the same way using the slightly modified function of Group 1 and simply using different heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecbf1f4f-36f5-4414-b681-d4f095ceae6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Constants\n",
    "A number of constants are used in the calculations of the injury atoms. These are initialized here and follow the naming convention of \n",
    "\"escalationGroup\". The fields are \"Value\", followed by the group specific injury ranks.\n",
    "\"Value\" represents the type of probability, with the corresponding value indicating how likely this injury is to occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "965391f9-4658-4ba7-af33-3d318348d6ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Constants for injury Atom calculations\n",
    "To calculate the injury atom of some escalations unique constants are used. These are compiled here and retrieved during calculation, so that if any changes to the constants are necessary they can be easily accessed and changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "05b8f805-6346-4004-ab75-d99b1e36822c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "derPassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.0, 0.0000142857139664037, 0.0000142857139664037, 20.0, 4.0, 0.9, 1.02, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.0, 0.00141428572790963, 0.00141428572790963, 20.0, 4.0, 0.9, 1.02, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.00142857142857143, 0.00285714285714286, 0.00285714285714286, 20.0, 4.0, 0.9, 1.02, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 20.0, 4.0, 0.9, 1.02, 1.0])\n",
    "    }\n",
    ")\n",
    "derPassenger.name = \"derPassenger\"\n",
    "\n",
    "derWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.0, 0.0, 0.0, 20.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Specified\": pl.Series([0.0, 0.0, 0.0, 20.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Sev7\": pl.Series([0.01, 0.1, 0.45, 60.0, 2.5, 0.9, 1.05, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.09, 0.2, 0.05, 45.0, 2.0, 0.9, 1.05, 1.0]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.0, 0.05, 45.0, 2.0, 0.9, 1.05, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.134297520661157, 0.1, 40.0, 2.0, 0.9, 1.035, 1.0])\n",
    "    }\n",
    ")\n",
    "derWorkforce.name = \"derWorkforce\"\n",
    "\n",
    "structureCollisionPassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.000205780167210667, 0.000718928675219401, 0.00161451408055514, 55.0, 1.75, 0.8, 1.1, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.00185202142823692, 0.00518464350161897, 0.0132449118160091, 60.0, 1.75, 0.8, 1.1, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.00142857142857143, 0.00571428571428572, 0.00571428571428572, 45.0, 1.75, 0.8, 1.05, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 45.0, 1.75, 0.8, 1.05, 1.0])\n",
    "    }\n",
    ")\n",
    "structureCollisionPassenger.name = \"structureCollisionPassenger\"\n",
    "\n",
    "structureCollisionWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.0, 0.150000005960465, 0.150000005960465, 25.0, 4.0, 0.8, 1.02, 1.0]),\n",
    "        \"Specified\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 25.0, 4.0, 0.95, 1.02, 1.0]),\n",
    "        \"Sev7\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 25.0, 4.0, 0.95, 1.02, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 25.0, 4.0, 0.95, 1.02, 1.0]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.2, 0.3, 30.0, 2.25, 0.9, 1.02, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.2, 0.1, 20.0, 4.0, 0.9, 1.02, 1.0])\n",
    "    }\n",
    ")\n",
    "structureCollisionWorkforce.name = \"structureCollisionWorkforce\"\n",
    "\n",
    "smallStructureCollisionPassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.000205780167210667, 0.000718928675219401, 0.00161451408055514, 55.0, 1.75, 0.8, 1.1, 0.5]),\n",
    "        \"SevHosp\": pl.Series([0.00185202142823692, 0.00518464350161897, 0.0132449118160091, 60.0, 1.75, 0.8, 1.1, 0.5]),\n",
    "        \"NonSevere\": pl.Series([0.00142857142857143, 0.00571428571428572, 0.00571428571428572, 45.0, 1.75, 0.8, 1.05, 0.5]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 45.0, 1.75, 0.8, 1.05, 0.5])\n",
    "    }\n",
    ")\n",
    "smallStructureCollisionPassenger.name = \"smallStructureCollisionPassenger\"\n",
    "\n",
    "smallStructureCollisionWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.0, 0.150000005960465, 0.150000005960465, 25.0, 4.0, 0.8, 1.02, 0.5]),\n",
    "        \"Specified\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 25.0, 4.0, 0.95, 1.02, 0.5]),\n",
    "        \"Sev7\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 25.0, 4.0, 0.95, 1.02, 0.5]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 25.0, 4.0, 0.95, 1.02, 0.5]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.2, 0.3, 30.0, 2.25, 0.9, 1.02, 0.5]),\n",
    "        \"Shock\": pl.Series([0.0, 0.2, 0.1, 20.0, 4.0, 0.9, 1.02, 0.5])\n",
    "    }\n",
    ")\n",
    "smallStructureCollisionWorkforce.name = \"smallStructureCollisionWorkforce\"\n",
    "\n",
    "structureCollapsePassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.0508231206535108, 0.127932857502114, 0.131515199056731, 20.0, 4.0, 0.9, 1.01, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.0491768793924846, 0.122067142661772, 0.118484801307334, 20.0, 4.0, 0.9, 1.01, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0114285714285714, 0.0342857142857143, 0.0342857142857143, 20.0, 4.0, 0.9, 1.005, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 20.0, 4.0, 0.9, 1.005, 1.0])\n",
    "    }\n",
    ")\n",
    "structureCollapsePassenger.name = \"structureCollapsePassenger\"\n",
    "\n",
    "structureCollapseWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.1, 0.1, 0.1, 20.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Specified\": pl.Series([0.0749999955296518, 0.0749999955296518, 0.0749999955296518, 20.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Sev7\": pl.Series([0.0749999955296518, 0.12499999254942, 0.164999990165234, 40.0, 2.5, 0.98, 1.02, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0499999970197677, 0.00999999940395354, 20.0, 3.0, 0.95, 1.005, 1.0]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.4, 0.5, 30.0, 3.0, 0.9, 1.03, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 30.0, 3.0, 0.9, 1.03, 1.0])\n",
    "    }\n",
    ")\n",
    "structureCollapseWorkforce.name = \"structureCollapseWorkforce\"\n",
    "\n",
    "fallPassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"midpointHeight\", \"heightPowerFactor\", \"maxLossAtHeight\", \"maxLoss\",\"P0Constant\", \"P125Constant\"]),\n",
    "        \"Fatal\": pl.Series([0.025127715224731, 0.0314096440309137, 0.0471144660463706, 60.0, 1.5, 5.0, 1.35, 30.0, 0.6, 0.96, 1.08]),\n",
    "        \"SevHosp\": pl.Series([0.0832922841660118, 0.104115355207515, 0.156173032811272, 60.0, 1.5, 5.0, 1.35, 30.0, 0.6, 0.96, 1.08]),\n",
    "        \"NonSevere\": pl.Series([0.019265306122449, 0.0240816326530612, 0.0361224489795918, 60.0, 1.5, 5.0, 1.35, 30.0, 0.6, 0.96, 1.06]),\n",
    "        \"Shock\": pl.Series([0.272314694486808, 0.34039336810851, 0.360590052162765, 50.0, 1.5, 5.0, 1.35, 30.0, 0.60, 0.97, 1.06])\n",
    "    }\n",
    ")\n",
    "fallPassenger.name = \"fallPassenger\"\n",
    "\n",
    "fallPublic = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"midpointHeight\", \"heightPowerFactor\", \"maxLossAtHeight\", \"maxLoss\", \"P0Constant\", \"P125Constant\"]),\n",
    "        \"Fatal\": pl.Series([0.2, 0.2, 0.2, 60.0, 1.0, 5.0, 0.0, 30.0, 0.6, 1.0, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0])\n",
    "    }\n",
    ")\n",
    "fallPublic.name = \"fallPublic\"\n",
    "\n",
    "fallWorkForce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"midpointHeight\", \"heightPowerFactor\", \"maxLossAtHeight\", \"maxLoss\", \"P0Constant\", \"P125Constant\"]),\n",
    "        \"Fatal\": pl.Series([0.5, 0.503140964403091, 0.51099337541082, 60.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.0015]),\n",
    "        \"Specified\": pl.Series([0.0, 0.0104115355207515, 0.0364403743226302, 60.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.0015]),\n",
    "        \"Sev7\": pl.Series([0.0, 0.00240816326530612, 0.00842857142857143, 60.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.005]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.034039336810851, 0.0441376788379786, 40.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.01]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.2, 0.3, 60.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.0015]),\n",
    "        \"Shock\": pl.Series([0.0, 0.2, 0.1, 60.0, 2.0, 5.0, 1.35, 30.0, 0.8, 1.0, 1.0015])\n",
    "    }\n",
    ")   \n",
    "fallWorkForce.name = \"fallWorkForce\"\n",
    "\n",
    "sidePassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.00154335129240954, 0.0106247533789642, 0.0228071437643043, 50.0, 1.75, 0.65, 1.05, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.00531598751240057, 0.0352312914910405, 0.0771928562223911, 50.0, 1.75, 0.65, 1.05, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0128571428571429, 0.0257142857142857, 0.0257142857142857, 45.0, 1.75, 0.75, 1.05, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 45.0, 1.75, 0.75, 1.05, 1.0])\n",
    "    }\n",
    ")\n",
    "sidePassenger.name = \"sidePassenger\"\n",
    "\n",
    "sideWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.050000000745058, 0.050000000745058, 0.050000000745058, 45.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Specified\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 45.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Sev7\": pl.Series([0.100000001490116, 0.100000001490116, 0.100000001490116, 45.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 45.0, 1.0, 1.0, 1.0, 1.0]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.2, 0.3, 35.0, 2.0, 0.92, 1.05, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.2, 0.1, 35.0, 4.0, 1.0, 1.0, 1.0])\n",
    "    }\n",
    ")\n",
    "sideWorkforce.name = \"sideWorkforce\"\n",
    "\n",
    "fallWaterPassenger = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\", \"smallCollisionModifier\"]),\n",
    "        \"Fatal\": pl.Series([0.2, 0.4, 0.6, 45.0, 1.75, 1.0, 1.05, 1.0]),\n",
    "        \"SevHosp\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0])\n",
    "    }\n",
    ")\n",
    "fallWaterPassenger.name = \"fallWaterPassenger\"\n",
    "\n",
    "fallWaterWorkforce = pl.DataFrame(\n",
    "    data = {\n",
    "        \"Value\": pl.Series([\"probabilitySlow\", \"probabilityMedium\", \"probabilityFast\", \"midpointSpeed\", \"K\", \"P0Constant\", \"P125Constant\"]),\n",
    "        \"Fatal\": pl.Series([0.6, 0.7, 0.8, 45.0, 2.0, 1.0, 1.01]),\n",
    "        \"Specified\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]),\n",
    "        \"Sev7\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]),\n",
    "        \"Shock7\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0])\n",
    "    }\n",
    ")\n",
    "fallWaterWorkforce.name = \"fallWaterWorkforce\"\n",
    "#Technically for the ECS and Freight trains it does not make a difference whether the fire is inside or whether the power type is electric/diesel, and for freights whether they are loaded. \n",
    "#However the way the selection process works (by first checking whether the train is a freight and then whether it is loaded) these cells will never be accessed, and Boolean dtypes are efficient to work with. \n",
    "fireWorkForce = pl.LazyFrame(\n",
    "    data = {\n",
    "        \"trainType\" : pl.Series([\"Passenger\", \"Passenger\", \"Passenger\", \"Passenger\", \"Passenger\", \"Freight\", \"Freight\"]),\n",
    "        \"loaded\" : pl.Series([True, True, True, False, False, False, False]),\n",
    "        \"fireInside\" : pl.Series([True, False, False, False, False, False, False]),\n",
    "        \"power\" : pl.Series([None, \"Diesel\", \"Electric\", \"Diesel\", \"Electric\", \"Diesel\", \"Electric\"]),\n",
    "        \"Fatal\" : pl.Series([0.00000595, 0.0000584, 0.0000326, 0.0, 0.0, 0.00000135, 0.00000135]),\n",
    "        \"Specified\" : pl.Series([0.0000125, 0.00292, 0.000033, 0.0, 0.0, 0.00001950, 0.00001950]),\n",
    "        \"Sev7\" : pl.Series([0.00235, 0.00158, 0.00195, 0.00205, 0.00205, 0.00125, 0.00125]),\n",
    "        \"NonSevere\" : pl.Series([0.0235, 0.0158, 0.0195, 0.0205, 0.0205, 0.0125, 0.0125]),\n",
    "        \"Shock7\" : pl.Series([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "        \"Shock\" : pl.Series([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    }\n",
    ")\n",
    "fireWorkForce.name = \"fireWorkForce\"\n",
    "\n",
    "fireNonWorkForce = pl.LazyFrame(\n",
    "    data = {\n",
    "        \"trainType\" : pl.Series([\"Passenger\", \"Passenger\", \"Passenger\", \"Passenger\", \"Passenger\", \"Freight\", \"Freight\"]),\n",
    "        \"loaded\" : pl.Series([True, True, True, False, False, False, False]),\n",
    "        \"fireInside\" : pl.Series([True, False, False, False, False, False, False]),\n",
    "        \"power\" : pl.Series([None, \"Diesel\", \"Electric\", \"Diesel\", \"Electric\", \"Diesel\", \"Electric\"]),\n",
    "        \"Fatal\": pl.Series([0.00000155, 0.0000019, 0.00000088, 0.0, 0.0, 0.00000019, 0.00000019]),\n",
    "        \"SevHosp\": pl.Series([0.0000488, 0.000048, 0.0000421, 0.0, 0.0, 0.0000017, 0.0000017]),\n",
    "        \"NonSevere\": pl.Series([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]),\n",
    "        \"Shock\": pl.Series([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "    }\n",
    ")\n",
    "fireNonWorkForce.name = \"fireNonWorkForce\"\n",
    "\n",
    "#Constructing the dataframe directly caused issues with the orientation of the matrix \n",
    "passengerStructure = np.array([[\"Fatal\", \"a\",\"c\",\"c\",\"c\",\"c\"], \n",
    "                                [\"SevHosp\", \"b\",\"a\",\"c\",\"c\",\"c\"], \n",
    "                                [\"NonSevere\", \"b\",\"b\",\"a\",\"c\",\"c\"],\n",
    "                                [\"Shock\", \"b\",\"b\",\"b\",\"a\",\"c\"],\n",
    "                                [\"NotInjured\", \"b\",\"b\",\"b\",\"b\",\"b\"]])\n",
    "passengerInjuryAtomStructure = pl.from_numpy(passengerStructure).rename(\n",
    "    {\n",
    "        \"column_0\": \"Injury\",\n",
    "        \"column_1\": \"Fatal\",\n",
    "        \"column_2\": \"SevHosp\",\n",
    "        \"column_3\": \"NonSevere\",\n",
    "        \"column_4\": \"Shock\",\n",
    "        \"column_5\": \"NotInjured\"\n",
    "    }\n",
    ")\n",
    "lazyPassengerInjuryAtomStructure = pl.LazyFrame(passengerInjuryAtomStructure)\n",
    "\n",
    "workforceStructure =  np.array([[\"Fatal\", \"a\", \"c\", \"c\", \"c\", \"c\", \"c\", \"c\"], \n",
    "                                [\"Specified\", \"b\", \"a\", \"c\", \"c\", \"c\", \"c\", \"c\"],\n",
    "                                [\"Sev7\", \"b\", \"b\", \"a\", \"c\", \"c\", \"c\", \"c\"], \n",
    "                                [\"NonSevere\", \"b\", \"b\", \"b\", \"a\", \"c\", \"c\", \"c\"],\n",
    "                                [\"Shock7\", \"b\", \"b\", \"b\", \"b\", \"a\", \"c\", \"c\"],\n",
    "                                [\"Shock\", \"b\", \"b\", \"b\", \"b\", \"b\", \"a\", \"c\"],\n",
    "                                [\"NotInjured\", \"b\",\"b\",\"b\",\"b\",\"b\", \"b\", \"b\"]])\n",
    "workforceInjuryAtomStructure = pl.from_numpy(workforceStructure).rename(\n",
    "    {\n",
    "        \"column_0\": \"Injury\",\n",
    "        \"column_1\": \"Fatal\",\n",
    "        \"column_2\": \"Specified\",\n",
    "        \"column_3\": \"Sev7\",\n",
    "        \"column_4\": \"NonSevere\",\n",
    "        \"column_5\": \"Shock7\",\n",
    "        \"column_6\": \"Shock\",\n",
    "        \"column_7\": \"NotInjured\"\n",
    "    }\n",
    ")\n",
    "lazyWorkforceInjuryAtomStructure = pl.LazyFrame(workforceInjuryAtomStructure)\n",
    "\n",
    "headOnCollisionProbability = 0.05\n",
    "sideOnCollisionProbability = 0.95\n",
    "\n",
    "headOnCollisionDerailmentSpeedCoefficient = 0.5\n",
    "sideOnCollisionDerailmentSpeedCoefficient = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7b02b0f-766b-4706-94b9-442fa486ed54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Gate Effect functions \n",
    "If a \"gate\" for a given escalation is negative, then the injury atom (regardless of value) doesn't apply to the given scenario. \n",
    "These functions are called following injury atom calculation and turn the values to 0 if the \"gate\" field is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "492f69ca-c62f-4603-95a2-0c36cd229112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to apply the effect of the gate to the probabilities of injury \n",
    "def gate_effect_passenger(lazyframe): \n",
    "    appliedEffect = lazyframe.with_columns(\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Fatal\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Fatal\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"SevHosp\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"SevHosp\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"NonSevere\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"NonSevere\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Shock\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Shock\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"NotInjured\"\n",
    "                       ).otherwise(1.0\n",
    "                              ).alias(\"NotInjured\")\n",
    "    )\n",
    "    \n",
    "    return appliedEffect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "37e367b9-dfa6-45c6-9028-e522784092e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to apply the effect of the gate to the probabilities of injury \n",
    "def gate_effect_workforce(lazyframe): \n",
    "    appliedEffect = lazyframe.with_columns(\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Fatal\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Fatal\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Specified\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Specified\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Sev7\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Sev7\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"NonSevere\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"NonSevere\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Shock7\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Shock7\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"Shock\"\n",
    "                       ).otherwise(0.0\n",
    "                              ).alias(\"Shock\"),\n",
    "        pl.when(pl.col(\"gate\")\n",
    "                ).then(\"NotInjured\"\n",
    "                       ).otherwise(1.0\n",
    "                              ).alias(\"NotInjured\")\n",
    "    )\n",
    "    \n",
    "    return appliedEffect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe998512-7bf9-4548-ae67-beab8d039ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Secondary Collision pre-processing\n",
    "Secondary collision is calculated differently to the other injury atoms using a lookup table and an older format (workforce subdivided into driver and guard).\n",
    "To maintain a coherent structure we are preprocessing the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2bcbc8c3-f43b-41ef-a533-063296a3e92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The total number is approximately lazyDerailmentConePotentialCollision * 2 * 1.7 as each derailment-collision has crashworthiness\n",
    "#combinations appearing more than once. This is because while the derailments are different (for example due to different derailment types)\n",
    "#this isn't evaluated here, meaning that \n",
    "baseInjuryAtomsSecondaryCollision = cutsetProbabilities.select(\n",
    "    [\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        \"derailmentSpeedMPH\",\n",
    "        \"collidingTrainSpeedMPH\",\n",
    "        \"derailedTrainCrashworthiness\", \n",
    "        \"collidingTrainCrashworthiness\",\n",
    "        \"secondaryCollision\"\n",
    "    ]\n",
    ").with_columns( #Casting into Int64 is necessary for the join to work\n",
    "    pl.min_horizontal((pl.col(\"derailmentSpeedMPH\") * headOnCollisionDerailmentSpeedCoefficient + pl.col(\"collidingTrainSpeedMPH\")), 120).round(0).cast(pl.Int64).alias(\"headOnCollisionSpeed\"),\n",
    "    pl.min_horizontal((pl.col(\"derailmentSpeedMPH\") * sideOnCollisionDerailmentSpeedCoefficient + pl.col(\"collidingTrainSpeedMPH\")), 120).round(0).cast(pl.Int64).alias(\"sideOnCollisionSpeed\")\n",
    ").join(lazySecondaryCollisionIA.filter(pl.col(\"collisionType\") == \"Head-on\"), left_on = [\"derailedTrainCrashworthiness\", \"collidingTrainCrashworthiness\", \"headOnCollisionSpeed\"], right_on = [\"trainType1\", \"trainType2\", \"collisionSpeedmph\"], how = \"inner\"\n",
    ").join(lazySecondaryCollisionIA.filter(pl.col(\"collisionType\") == \"Side-on\"), left_on = [\"derailedTrainCrashworthiness\", \"collidingTrainCrashworthiness\", \"sideOnCollisionSpeed\"], right_on = [\"trainType1\", \"trainType2\", \"collisionSpeedmph\"], how = \"inner\", suffix = \"side\"\n",
    ").with_columns(\n",
    "    (pl.col(\"passengerFatal1\") * headOnCollisionProbability + pl.col(\"passengerFatal1side\") * sideOnCollisionProbability).alias(\"passengerFatal1\"), \n",
    "    (pl.col(\"passengerSevHosp1\") * headOnCollisionProbability + pl.col(\"passengerSevHosp1side\") * sideOnCollisionProbability).alias(\"passengerSevHosp1\"),\n",
    "    (pl.col(\"passengerNonSevere1\") * headOnCollisionProbability + pl.col(\"passengerNonSevere1side\") * sideOnCollisionProbability).alias(\"passengerNonSevere1\"),\n",
    "    (pl.col(\"passengerShock1\") * headOnCollisionProbability + pl.col(\"passengerShock1side\") * sideOnCollisionProbability).alias(\"passengerShock1\"),\n",
    "    (pl.col(\"passengerFatal2\") * headOnCollisionProbability + pl.col(\"passengerFatal2side\") * sideOnCollisionProbability).alias(\"passengerFatal2\"), \n",
    "    (pl.col(\"passengerSevHosp2\") * headOnCollisionProbability + pl.col(\"passengerSevHosp2side\") * sideOnCollisionProbability).alias(\"passengerSevHosp2\"),\n",
    "    (pl.col(\"passengerNonSevere2\") * headOnCollisionProbability + pl.col(\"passengerNonSevere2side\") * sideOnCollisionProbability).alias(\"passengerNonSevere2\"),\n",
    "    (pl.col(\"passengerShock2\") * headOnCollisionProbability + pl.col(\"passengerShock2side\") * sideOnCollisionProbability).alias(\"passengerShock2\"), \n",
    "    (pl.col(\"workforceFatal1\") * headOnCollisionProbability + pl.col(\"workforceFatal1side\") * sideOnCollisionProbability).alias(\"workforceFatal1\"),\n",
    "    (pl.col(\"workforceSpecified1\") * headOnCollisionProbability + pl.col(\"workforceSpecified1side\") * sideOnCollisionProbability).alias(\"workforceSpecified1\"),\n",
    "    (pl.col(\"workforceSev71\") * headOnCollisionProbability + pl.col(\"workforceSev71side\") * sideOnCollisionProbability).alias(\"workforceSev71\"),\n",
    "    (pl.col(\"workforceNonSevere1\") * headOnCollisionProbability + pl.col(\"workforceNonSevere1side\") * sideOnCollisionProbability).alias(\"workforceNonSevere1\"),\n",
    "    (pl.col(\"workforceFatal2\") * headOnCollisionProbability + pl.col(\"workforceFatal2side\") * sideOnCollisionProbability).alias(\"workforceFatal2\"),\n",
    "    (pl.col(\"workforceSpecified2\") * headOnCollisionProbability + pl.col(\"workforceSpecified2side\") * sideOnCollisionProbability).alias(\"workforceSpecified2\"),\n",
    "    (pl.col(\"workforceSev72\") * headOnCollisionProbability + pl.col(\"workforceSev72side\") * sideOnCollisionProbability).alias(\"workforceSev72\"),\n",
    "    (pl.col(\"workforceNonSevere2\") * headOnCollisionProbability + pl.col(\"workforceNonSevere2side\") * sideOnCollisionProbability).alias(\"workforceNonSevere2\"),\n",
    "    (pl.col('workforceShock71') * headOnCollisionProbability + pl.col(\"workforceShock71side\") * sideOnCollisionProbability).alias(\"workforceShock71\"),\n",
    "    (pl.col('workforceShock1') * headOnCollisionProbability + pl.col(\"workforceShock1side\") * sideOnCollisionProbability).alias(\"workforceShock1\"),\n",
    "    (pl.col('workforceShock72') * headOnCollisionProbability + pl.col(\"workforceShock72side\") * sideOnCollisionProbability).alias(\"workforceShock72\"),\n",
    "    (pl.col('workforceShock2')* headOnCollisionProbability + pl.col(\"workforceShock2side\") * sideOnCollisionProbability).alias(\"workforceShock2\")\n",
    ").group_by(\"derailmentConePotentialCollisionID\", \"cutsetID\"\n",
    ").agg(pl.col(\"cutset_probability\").mean(),\n",
    "      pl.col(\"passengerFatal1\").mean(),\n",
    "      pl.col(\"passengerSevHosp1\").mean(),\n",
    "      pl.col('passengerNonSevere1').mean(),\n",
    "      pl.col('passengerFatal2').mean(),\n",
    "      pl.col(\"passengerSevHosp2\").mean(),\n",
    "      pl.col('passengerNonSevere2').mean(),\n",
    "      pl.col(\"workforceFatal1\").mean(),\n",
    "      pl.col(\"workforceSpecified1\").mean(),\n",
    "      pl.col(\"workforceSev71\").mean(),\n",
    "      pl.col(\"workforceNonSevere1\").mean(),\n",
    "      pl.col(\"workforceFatal2\").mean(),\n",
    "      pl.col(\"workforceSpecified2\").mean(),\n",
    "      pl.col(\"workforceSev72\").mean(),\n",
    "      pl.col(\"workforceNonSevere2\").mean(),\n",
    "      pl.col(\"passengerShock1\").mean(), \n",
    "      pl.col(\"passengerShock2\").mean(),\n",
    "      pl.col('workforceShock71').mean(),\n",
    "      pl.col('workforceShock1').mean(),\n",
    "      pl.col('workforceShock72').mean(),\n",
    "      pl.col('workforceShock2').mean(),\n",
    "      pl.col(\"secondaryCollision\").min()\n",
    ").collect()\n",
    "\n",
    "secondaryCollisionPassengerTrain1 = baseInjuryAtomsSecondaryCollision.select(\n",
    "    [\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        pl.col(\"passengerFatal1\").alias(\"passengerFatal\"),\n",
    "        pl.col(\"passengerSevHosp1\").alias(\"passengerSevHosp\"),\n",
    "        pl.col(\"passengerNonSevere1\").alias(\"passengerNonSevere\"), \n",
    "        pl.col(\"passengerShock1\").alias(\"passengerShock\"),\n",
    "        \"secondaryCollision\"\n",
    "    ]\n",
    ")\n",
    "lazySecondaryCollisionPassengerTrain1 = pl.LazyFrame(secondaryCollisionPassengerTrain1)\n",
    "lazySecondaryCollisionPassengerTrain1.name = \"secondaryCollisionPassengerTrain1\"\n",
    "\n",
    "secondaryCollisionPassengerTrain2 = baseInjuryAtomsSecondaryCollision.select(\n",
    "    [\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        pl.col(\"passengerFatal2\").alias(\"passengerFatal\"),\n",
    "        pl.col(\"passengerSevHosp2\").alias(\"passengerSevHosp\"),\n",
    "        pl.col(\"passengerNonSevere2\").alias(\"passengerNonSevere\"), \n",
    "        pl.col(\"passengerShock2\").alias(\"passengerShock\"),\n",
    "        \"secondaryCollision\"\n",
    "    ]\n",
    ")\n",
    "lazySecondaryCollisionPassengerTrain2 = pl.LazyFrame(secondaryCollisionPassengerTrain2)\n",
    "lazySecondaryCollisionPassengerTrain2.name = \"secondaryCollisionPassengerTrain2\"\n",
    "\n",
    "secondaryCollisionWorkforceTrain1 = baseInjuryAtomsSecondaryCollision.select(\n",
    "    [\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        pl.col(\"workforceFatal1\").alias(\"workforceFatal\"),\n",
    "        pl.col(\"workforceSpecified1\").alias(\"workforceSpecified\"),\n",
    "        pl.col(\"workforceSev71\").alias(\"workforceSev7\"),\n",
    "        pl.col(\"workforceNonSevere1\").alias(\"workforceNonSevere\"),\n",
    "        pl.col(\"workforceShock71\").alias(\"workforceShock7\"), \n",
    "        pl.col(\"workforceShock1\").alias(\"workforceShock\"),\n",
    "        \"secondaryCollision\"\n",
    "    ]\n",
    ")\n",
    "lazySecondaryCollisionWorkforceTrain1 = pl.LazyFrame(secondaryCollisionWorkforceTrain1)\n",
    "lazySecondaryCollisionWorkforceTrain1.name = \"secondaryCollisionWorkforceTrain1\"\n",
    "\n",
    "secondaryCollisionWorkforceTrain2 = baseInjuryAtomsSecondaryCollision.select(\n",
    "    [\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        pl.col(\"workforceFatal2\").alias(\"workforceFatal\"),\n",
    "        pl.col(\"workforceSpecified2\").alias(\"workforceSpecified\"),\n",
    "        pl.col(\"workforceSev72\").alias(\"workforceSev7\"),\n",
    "        pl.col(\"workforceNonSevere2\").alias(\"workforceNonSevere\"),\n",
    "        pl.col(\"workforceShock72\").alias(\"workforceShock7\"), \n",
    "        pl.col(\"workforceShock2\").alias(\"workforceShock\"),\n",
    "        \"secondaryCollision\"\n",
    "    ]\n",
    ")\n",
    "lazySecondaryCollisionWorkforceTrain2 = pl.LazyFrame(secondaryCollisionWorkforceTrain2)\n",
    "lazySecondaryCollisionWorkforceTrain2.name = \"secondaryCollisionWorkforceTrain2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ce17b9-8344-4684-96fc-fe8443823f88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3136301-2054-42d1-bf19-9e4bf168d73e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Group 1\n",
    "Rather than repeat significantly lengthy code here we pass the API native calculations into a function which we parallelize \n",
    "This allows us to calculate all of the IA in the first group at the same time  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ada69da8-feff-4148-bbd7-f7b40cd25c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Functions\n",
    "Simplified functions return only the probability of a person receiving a specified injury from being uninjured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0d26250d-d8ad-4dfe-b0c2-0ebe868017ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def groupOnePassengerIASimple(dataframe, name):\n",
    "# Calling the function returns a LazyFrame \n",
    "# The left join is because of a bug - as of 27/09/2024 using an inner join return an empty dataframe when streaming = True. It is unclear what is causing this but it might have to do \n",
    "# with how the parallelization works in conjunction with the forming of categorical data.\n",
    "  maxSpeedMPH = 125\n",
    "  injuryAtoms = cutsetProbabilities.with_columns(\n",
    "      ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item()) + \n",
    "      ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(\"Fatal\").item() * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Fatal\").item()) - (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Fatal\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Fatal\").item()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      ).alias(\"{}CumFatal\".format(name)),\n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"SevHosp\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"SevHosp\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "         dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"SevHosp\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"SevHosp\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"SevHosp\").item()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      ).alias(\"{}CumSevHosp\".format(name)),\n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"NonSevere\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"NonSevere\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"NonSevere\").item()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      ).alias(\"{}CumNonSevere\".format(name)),\n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock\").item()\n",
    "            )\n",
    "          )\n",
    "        )\n",
    "      ).alias(\"{}CumShock\".format(name))\n",
    "  ).with_columns(\n",
    "    pl.col(\"{}CumFatal\".format(name)),\n",
    "    (pl.col(\"{}CumSevHosp\".format(name)) - pl.col(\"{}CumFatal\".format(name))).alias(\"{}SevHospUC\".format(name)),\n",
    "    (pl.col(\"{}CumNonSevere\".format(name)) - pl.col(\"{}CumSevHosp\".format(name))).alias(\"{}NonSevereUC\".format(name)),\n",
    "    (pl.col(\"{}CumShock\".format(name)) - pl.col(\"{}CumNonSevere\".format(name))).alias(\"{}ShockUC\".format(name))\n",
    "  ).with_columns( \n",
    "    # The consecutive with_columns() statements are necessary as the result of the previous one is used in calculating the next one \n",
    "    # This doesn't significantly affect the efficiency of the algorithm \n",
    "\n",
    "    # The smallCollisionModifier applies only to the Passenger IAs and is 0 for IAs other than smallStructureCollision\n",
    "    (pl.col(\"{}CumFatal\".format(name)) * \n",
    "     dataframe.filter(pl.col(\"Value\") == \"smallCollisionModifier\").select(\"Fatal\").item()\n",
    "     ).alias(\"Fatal\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(pl.col(\"{}SevHospUC\".format(name)), \n",
    "                                        1 - pl.col(\"Fatal\")), 0) * \n",
    "     dataframe.filter(pl.col(\"Value\") == \"smallCollisionModifier\").select(\"SevHosp\").item()\n",
    "     ).alias(\"SevHosp\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(pl.col(\"{}NonSevereUC\".format(name)), \n",
    "                        1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\")), 0) * \n",
    "     dataframe.filter(pl.col(\"Value\") == \"smallCollisionModifier\").select(\"NonSevere\").item()\n",
    "     ).alias(\"NonSevere\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(\n",
    "        pl.col(\"{}ShockUC\".format(name)), \n",
    "        1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")), 0) * \n",
    "     dataframe.filter(pl.col(\"Value\") == \"smallCollisionModifier\").select(\"Shock\").item()\n",
    "     ).alias(\"Shock\")\n",
    "  ).with_columns(\n",
    "    (1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).alias(\"NotInjured\")\n",
    "  ).select(\"derailmentConePotentialCollisionID\", \n",
    "            \"cutsetID\",\n",
    "            \"cutset_probability\",\n",
    "            \"Fatal\", \n",
    "            \"SevHosp\", \n",
    "            \"NonSevere\", \n",
    "            \"Shock\", \n",
    "            \"NotInjured\",\n",
    "            \"significantStructureCollision\",\n",
    "            \"significantStructureCollapse\",\n",
    "            \"vehicleFallOnSide\",\n",
    "            \"smallStructureCollision\",\n",
    "            \"vehicleFallIntoWater\"\n",
    "  )\n",
    "\n",
    "  \n",
    "  return injuryAtoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e9036625-1fab-45f3-b264-0c062ca89fa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# derailment IA for the Workforce \n",
    "def groupOneWorkforceIASimple(dataframe, name):\n",
    "  maxSpeedMPH = 125\n",
    "  injuryAtoms = cutsetProbabilities.with_columns(\n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(\"Fatal\").item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Fatal\").item()) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          (np.power(\n",
    "              (pl.col(\"derailmentSpeedMPH\")/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Fatal\").item() / maxSpeedMPH))\n",
    "                  ) - 1), dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Fatal\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumFatal\".format(name)),\n",
    "\n",
    "\n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Specified\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Specified\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Specified\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Specified\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Specified\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumSpecified\".format(name)),\n",
    "\n",
    "\n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Sev7\").item()) + \n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Sev7\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Sev7\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Sev7\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Sev7\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumSev7\".format(name)),\n",
    "\n",
    "\n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() *  dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() * (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"NonSevere\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"NonSevere\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"NonSevere\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumNonSevere\".format(name)),\n",
    "\n",
    "\n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock7\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock7\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock7\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock7\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock7\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumShock7\".format(name)),\n",
    "\n",
    "\n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "         np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock\").item()\n",
    "          )\n",
    "      )\n",
    "    )\n",
    "  ).alias(\"{}CumShock\".format(name))\n",
    "  ).with_columns(\n",
    "  pl.col(\"{}CumFatal\".format(name)),\n",
    "  (pl.col(\"{}CumSpecified\".format(name)) - pl.col(\"{}CumFatal\".format(name))).alias(\"{}SpecifiedUC\".format(name)),\n",
    "  (pl.col(\"{}CumSev7\".format(name)) - pl.col(\"{}CumSpecified\".format(name))).alias(\"{}Sev7UC\".format(name)),\n",
    "  (pl.col(\"{}CumNonSevere\".format(name)) - pl.col(\"{}CumSev7\".format(name))).alias(\"{}NonSevereUC\".format(name)),\n",
    "  (pl.col(\"{}CumShock7\".format(name)) - pl.col(\"{}CumNonSevere\".format(name))).alias(\"{}Shock7UC\".format(name)),\n",
    "  (pl.col(\"{}CumShock\".format(name)) - pl.col(\"{}CumShock7\".format(name))).alias(\"{}ShockUC\".format(name))\n",
    "  ).with_columns(\n",
    "    (pl.col(\"{}CumFatal\".format(name))\n",
    "     ).alias(\"Fatal\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}SpecifiedUC\".format(name)), 1 - pl.col(\"Fatal\")), 0) \n",
    "     ).alias(\"Specified\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}Sev7UC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\")), 0)\n",
    "     ).alias(\"Sev7\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}NonSevereUC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")), 0)\n",
    "     ).alias(\"NonSevere\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}Shock7UC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")), 0)\n",
    "     ).alias(\"Shock7\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}ShockUC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")), 0)\n",
    "     ).alias(\"Shock\")\n",
    "  ).with_columns(\n",
    "    (1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\", \"Shock\")).alias(\"NotInjured\")\n",
    "  ).select(\"derailmentConePotentialCollisionID\", \n",
    "            \"cutsetID\",\n",
    "            \"cutset_probability\",\n",
    "            \"Fatal\", \n",
    "            \"Specified\", \n",
    "            \"Sev7\", \n",
    "            \"NonSevere\",\n",
    "            \"Shock7\",\n",
    "            \"Shock\", \n",
    "            \"NotInjured\",\n",
    "            \"significantStructureCollision\",\n",
    "            \"significantStructureCollapse\",\n",
    "            \"vehicleFallOnSide\",\n",
    "            \"smallStructureCollision\",\n",
    "            \"vehicleFallIntoWater\"\n",
    "  )\n",
    "  \n",
    "  return injuryAtoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e7a21d32-8dff-4e0c-be08-901a6a673182",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyDerPassengerIA = derPassenger.pipe(groupOnePassengerIASimple, derPassenger.name)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "lazyDerWorkforceIA = derWorkforce.pipe(groupOneWorkforceIASimple, derWorkforce.name)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "lazySTRColPassengerIA = groupOnePassengerIASimple(structureCollisionPassenger, structureCollisionPassenger.name)\n",
    "lazySTRColWorkforceIA = groupOneWorkforceIASimple(structureCollisionWorkforce, structureCollisionWorkforce.name)\n",
    "lazySTRCollapsePassengerIA = groupOnePassengerIASimple(structureCollapsePassenger, structureCollapsePassenger.name)\n",
    "lazySTRCollapseWorkforceIA = groupOneWorkforceIASimple(structureCollapseWorkforce, structureCollapseWorkforce.name)\n",
    "lazySidePassengerIA = groupOnePassengerIASimple(sidePassenger, sidePassenger.name)\n",
    "lazySideWorkforceIA = groupOneWorkforceIASimple(sideWorkforce, sideWorkforce.name)\n",
    "lazySmallSTRPassengerIA = groupOnePassengerIASimple(smallStructureCollisionPassenger, smallStructureCollisionPassenger.name)\n",
    "lazySmallSTRWorkforceIA = groupOneWorkforceIASimple(smallStructureCollisionWorkforce, smallStructureCollisionWorkforce.name)\n",
    "lazyFallWaterPassengerIA = groupOnePassengerIASimple(fallWaterPassenger, fallWaterPassenger.name)\n",
    "lazyFallWaterWorkforceIA = groupOneWorkforceIASimple(fallWaterWorkforce, fallWaterWorkforce.name)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66709104-19d8-439a-ad65-2d13ffbc9798",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b1e50a1-003d-49d4-8912-a8960d2adc50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Group 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f7c0e12-85e9-489d-9b50-8719259a7676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Functions\n",
    "Simplified functions return only the probability of a person receiving a specified injury from being uninjured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fa850371-578d-491a-b41d-9266b61c08a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def groupTwoPassengerIASimple(lazyframe):\n",
    "    lazyframe = lazyframe.with_columns(\n",
    "    pl.col(\"passengerFatal\").alias(\"Fatal\")\n",
    "    ).with_columns(\n",
    "    pl.max_horizontal(\n",
    "        pl.min_horizontal(pl.col(\"passengerSevHosp\"), 1 - pl.col(\"Fatal\")), \n",
    "        0\n",
    "    ).alias(\"SevHosp\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"passengerNonSevere\"), 1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\")), \n",
    "            0\n",
    "        ).alias(\"NonSevere\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"passengerShock\"), 1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")), \n",
    "            0\n",
    "        ).alias(\"Shock\")\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        \"Fatal\", \n",
    "        \"SevHosp\", \n",
    "        \"NonSevere\", \n",
    "        \"Shock\", \n",
    "        \"NotInjured\", \n",
    "        \"secondaryCollision\"\n",
    "    )\n",
    "\n",
    "    return lazyframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cd4876ca-70d1-426d-8031-0e1c33fc70ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def groupTwoWorkForceIASimple(lazyframe):\n",
    "    lazyframe = lazyframe.with_columns(\n",
    "    pl.col(\"workforceFatal\").alias(\"Fatal\")\n",
    "    ).with_columns(\n",
    "    pl.max_horizontal(\n",
    "        pl.min_horizontal(pl.col(\"workforceSpecified\"), 1 - pl.col(\"Fatal\")), \n",
    "        0\n",
    "    ).alias(\"Specified\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"workforceSev7\"), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\")), \n",
    "            0\n",
    "        ).alias(\"Sev7\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"workforceNonSevere\"), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")), \n",
    "            0\n",
    "        ).alias(\"NonSevere\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"workforceShock7\"), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")), \n",
    "            0\n",
    "        ).alias(\"Shock7\")\n",
    "    ).with_columns(\n",
    "        pl.max_horizontal(\n",
    "            pl.min_horizontal(pl.col(\"workforceShock\"), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\")), \n",
    "            0\n",
    "        ).alias(\"Shock\")\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\",\"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\", \n",
    "        \"cutsetID\",\n",
    "        \"cutset_probability\",\n",
    "        \"Fatal\", \n",
    "        \"Specified\", \n",
    "        \"Sev7\", \n",
    "        \"NonSevere\", \n",
    "        \"Shock7\", \n",
    "        \"Shock\", \n",
    "        \"NotInjured\",\n",
    "        \"secondaryCollision\"\n",
    "    )\n",
    "\n",
    "    return lazyframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9f491d08-f21e-4a5f-9550-970098c0cf95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "secondaryCollisionPassengerTrain1IA = groupTwoPassengerIASimple(lazySecondaryCollisionPassengerTrain1)\n",
    "secondaryCollisionPassengerTrain2IA = groupTwoPassengerIASimple(lazySecondaryCollisionPassengerTrain2)\n",
    "secondaryCollisionWorkforceTrain1IA = groupTwoWorkForceIASimple(lazySecondaryCollisionWorkforceTrain1)\n",
    "secondaryCollisionWorkforceTrain2IA = groupTwoWorkForceIASimple(lazySecondaryCollisionWorkforceTrain2)\n",
    "\n",
    "# collect(streaming=True)\n",
    "# streaming = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5490b708-aa17-4341-a406-cb85d768e228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Group 3\n",
    "The Injury atoms for toxic and flammable goods are hardcoded as they have set values derived from historic events \n",
    "\n",
    "For each LazyFrame only the final row (\"Not Injured\") is accurate as it is the only row we will be using in the calculations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d592503c-a39b-4c47-9403-a6ba5452d4f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hazGoodsPassengerIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1, 0, 0, 0, 0.1285714], dtype=pl.Float32),\n",
    "             \"SevHosp\":  pl.Series([0.1285714, 0.871428571, 0, 0,0.085714286], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.1285714, 0.085714286, 0.785714286, 0, 0], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([0.1285714, 0.085714286, 0, 0.785714286, 0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.1285714, 0.085714286, 0, 0, 0.785714286], dtype=pl.Float32)})\n",
    "\n",
    "hazGoodsPublicIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1, 0, 0, 0, 0.142857143], dtype=pl.Float32),\n",
    "             \"SevHosp\":  pl.Series([ 0.142857143, 0.857142857, 0, 0, 0.285714286], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.142857143, 0.285714286, 0.571428571, 0,  0.571428571], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([ 0.142857143, 0.285714286, 0.571428571, 0.0, 0.0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.142857143, 0.285714286, 0.571428571, 0, 0.0], dtype=pl.Float32)})\n",
    "\n",
    "\n",
    "hazGoodsWorkforceIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\",\"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1,0,0,0,0,0,0.128571429], dtype=pl.Float32),\n",
    "             \"Specified\":  pl.Series([ 0.128571429, 0.871428571,0,0,0,0,0.042857143], dtype=pl.Float32),\n",
    "             \"Sev7\" : pl.Series([0.128571429, 0.042857143, 0.828571429,0,0,0,0.042857143], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.128571429, 0.042857143, 0.042857143, 0.785714286,0,0,0], dtype=pl.Float32),\n",
    "             \"Shock7\":  pl.Series([  0.128571429, 0.042857143, 0.042857143, 0, 0.785714286,0,0], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([  0.128571429, 0.042857143, 0.042857143, 0, 0, 0.785714286,0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.128571429,0.042857143,0.042857143,0,0, 0, 0.785714286], dtype=pl.Float32)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f916d0d6-d463-462d-80bb-5b102bbc9783",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "flamGoodsPassengerIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1, 0, 0, 0, 0.071428571], dtype=pl.Float32),\n",
    "             \"SevHosp\":  pl.Series([0.071428571, 0.928571429, 0, 0,  0.071428571], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.071428571, 0.071428571, 0.857142857, 0, 0], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([0.071428571, 0.071428571, 0,0.857142857, 0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.071428571, 0.071428571, 0, 0, 0.857142857], dtype=pl.Float32)})\n",
    "\n",
    "\n",
    "\n",
    "flamGoodsPublicIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1, 0, 0, 0, 0], dtype=pl.Float32),\n",
    "             \"SevHosp\":  pl.Series([ 0.0, 1, 0, 0, 0.5], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.0, 0.5, 0.5, 0, 0.5], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([0.0, 0.5, 0.5, 0.0, 0.0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.0, 0.5, 0.5, 0, 0.0], dtype=pl.Float32)}) \n",
    "\n",
    "\n",
    "\n",
    "flamGoodsWorkforceIA = pl.LazyFrame(\n",
    "    data = {\"Injury\": pl.Series([\"Fatal\",\"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\", \"Shock\", \"NotInjured\"], dtype = pl.Categorical),\n",
    "             \"Fatal\": pl.Series([1,0,0,0,0,0,0.071428571], dtype=pl.Float32),\n",
    "             \"Specified\":  pl.Series([ 0.071428571, 0.928571429,0,0,0,0,0.035714286], dtype=pl.Float32),\n",
    "             \"Sev7\" : pl.Series([0.071428571, 0.035714286, 0.892857143,0,0,0,0.035714286], dtype=pl.Float32),\n",
    "             \"NonSevere\":  pl.Series([0.071428571, 0.035714286, 0.035714286, 0.857142857,0,0,0], dtype=pl.Float32),\n",
    "             \"Shock7\":  pl.Series([  0.071428571, 0.035714286, 0.035714286, 0, 0.857142857,0,0], dtype=pl.Float32),\n",
    "             \"Shock\":  pl.Series([   0.071428571, 0.035714286, 0.035714286, 0, 0, 0.857142857,0], dtype=pl.Float32),\n",
    "             \"NotInjured\":  pl.Series([0.071428571,0.035714286,0.035714286,0,0, 0, 0.857142857], dtype=pl.Float32)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5dd95fd5-51f2-4d25-9261-5d66e2ed399e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The fire injury atoms make a distinction depending on the train power type so the power type needs to be included in the calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9d8f3850-66f4-4335-8c5a-2808d72f9810",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "derailedTrainGroups = cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \n",
    "    \"cutsetID\", \n",
    "    \"cutset_probability\", \n",
    "    \"potentialCollisionID\", \n",
    "    pl.col(\"derailedTrainType\").alias(\"trainType\"),\n",
    "    pl.col(\"derailed_train_power\").alias(\"power\"),\n",
    "    \"derailedTrainLoading\", \n",
    "    \"toxicGoodRelease(noCollision)\",\n",
    "    \"toxicGoodRelease\",\n",
    "    \"flamGoodRelease(noCollision)\",\n",
    "    \"flamGoodRelease\",\n",
    "    \"fire(noFlamGoods)\",\n",
    "    \"fire(flamGoods)\"\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col(\"derailedTrainLoading\") > 0 \n",
    "                ).then(True\n",
    "                       ).otherwise(False\n",
    "                                   ).alias(\"loaded\")\n",
    "    )\n",
    "\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "\n",
    "collidingTrainGroups = cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \n",
    "    \"cutsetID\", \n",
    "    \"cutset_probability\",\n",
    "    \"potentialCollisionID\", \n",
    "    pl.col(\"collidingTrainType\").alias(\"trainType\"),\n",
    "    pl.col(\"colliding_train_power\").alias(\"power\"),\n",
    "    \"collidingTrainLoading\",\n",
    "    \"toxicGoodRelease(noCollision)\",\n",
    "    \"toxicGoodRelease\",\n",
    "    \"flamGoodRelease(noCollision)\",\n",
    "    \"flamGoodRelease\",\n",
    "    \"fire(noFlamGoods)\",\n",
    "    \"fire(flamGoods)\"\n",
    "    ).with_columns(\n",
    "        pl.when(pl.col(\"collidingTrainLoading\") > 0 \n",
    "                ).then(True\n",
    "                       ).otherwise(False\n",
    "                                   ).alias(\"loaded\")\n",
    "    )\n",
    "\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c999a1-1ec8-495f-a8c3-ce0ad9c6f7cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c21effbc-11b3-42a4-a7e0-ff0e30e4ddc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def non_workforce_fire_flam_goods(dataframe, table):\n",
    "    output = dataframe.cast(\n",
    "        {\"trainType\":pl.String, \"loaded\": pl.Boolean, \"power\":pl.String}\n",
    "    ).join(table, on = [\"trainType\", \"loaded\", \"power\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\"derailmentConePotentialCollisionID\",\n",
    "             \"cutsetID\",\n",
    "             \"Fatal\",\n",
    "             \"SevHosp\", \n",
    "             \"NonSevere\", \n",
    "             \"Shock\", \n",
    "             \"NotInjured\", \n",
    "             pl.col(\"fire(flamGoods)\").alias(\"gate\")\n",
    "    )\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c52f64ec-e27d-4baa-8eea-9c201ef3f4ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def non_workforce_fire_no_flam_goods(dataframe, table):\n",
    "    output = dataframe.cast({\"trainType\":pl.String, \"loaded\": pl.Boolean, \"power\":pl.String}).join(table, on = [\"trainType\", \"loaded\", \"power\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\"derailmentConePotentialCollisionID\",\n",
    "             \"cutsetID\",\n",
    "             \"Fatal\",\n",
    "             \"SevHosp\", \n",
    "             \"NonSevere\", \n",
    "             \"Shock\", \n",
    "             \"NotInjured\",\n",
    "             pl.col(\"fire(noFlamGoods)\").alias(\"gate\")\n",
    "    )\n",
    "\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e3ddb5ba-2af5-4613-bb8b-44c6560e9c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def workforce_fire_flam_goods(dataframe, table):\n",
    "    output = dataframe.cast({\"trainType\":pl.String, \"loaded\": pl.Boolean, \"power\":pl.String}).join(table, on = [\"trainType\", \"loaded\", \"power\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\",\"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\"derailmentConePotentialCollisionID\",\n",
    "             \"cutsetID\",\n",
    "             \"Fatal\",\n",
    "             \"Specified\", \n",
    "             \"Sev7\", \n",
    "             \"NonSevere\", \n",
    "             \"Shock7\", \n",
    "             \"Shock\",\n",
    "             \"NotInjured\", \n",
    "             pl.col(\"fire(flamGoods)\").alias(\"gate\")\n",
    "    )\n",
    "\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1ceab2dd-0a93-4d36-aabc-cbc16a0b8eb8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def workforce_fire_no_flam_goods(dataframe, table):\n",
    "    output = dataframe.cast({\"trainType\":pl.String, \"loaded\": pl.Boolean, \"power\":pl.String}).join(table, on = [\"trainType\", \"loaded\", \"power\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (1 - pl.sum_horizontal(\"Fatal\",\"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).alias(\"NotInjured\")\n",
    "    ).select(\"derailmentConePotentialCollisionID\",\n",
    "             \"cutsetID\",\n",
    "             \"Fatal\",\n",
    "             \"Specified\", \n",
    "             \"Sev7\", \n",
    "             \"NonSevere\", \n",
    "             \"Shock7\", \n",
    "             \"Shock\",\n",
    "             \"NotInjured\",\n",
    "             pl.col(\"fire(noFlamGoods)\").alias(\"gate\")\n",
    "    )\n",
    "\n",
    "    return output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f867e0a-47c3-4c49-9e37-8b38cb60c6e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Group 4\n",
    "We prepare the LazyFrames for the calculation outside of the function environment, as the height parameter will change depending on what we are trying to calculate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b3dbee90-833f-43e4-9ea6-eac735e81994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lazyDerailmentsWithEmbankmentHeights = cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\",\n",
    "    \"cutsetID\",\n",
    "    \"cutset_probability\",\n",
    "    \"potentialCollisionID\",\n",
    "    \"derailmentSpeedMPH\",\n",
    "    \"embankmentHeight(m)\",\n",
    "    pl.col(\"vehicleFallFromEmbankment\").alias(\"gate\")\n",
    ").rename(\n",
    "    {\n",
    "        \"embankmentHeight(m)\": \"height(m)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "\n",
    "lazyDerailmentsWithBridgeHeights =  cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\",\n",
    "    \"cutsetID\",\n",
    "    \"cutset_probability\",\n",
    "    \"potentialCollisionID\",\n",
    "    \"derailmentSpeedMPH\",\n",
    "    \"bridgeViaductHeight\",\n",
    "    pl.col(\"vehicleFallFromHeight\").alias(\"gate\")\n",
    ").rename(\n",
    "    {\n",
    "        \"bridgeViaductHeight\": \"height(m)\"\n",
    "    }\n",
    ").cast(\n",
    "    {\n",
    "        \"height(m)\" : pl.Float32\n",
    "    }\n",
    ")\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "936d804c-73db-4d19-b9d5-74372f77ccfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b7117f20-9da9-46e3-ae13-fedbbb09553f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def groupFourPassengerIASimple(lazyframe, dataframe, name):\n",
    "#Calling the function returns a LazyFrame \n",
    "  maxSpeedMPH = 125\n",
    "  injuryAtoms = lazyframe.with_columns(\n",
    "      #Cumulative probability for Fatal injuries\n",
    "      pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item()) + \n",
    "      ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(\"Fatal\").item() * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Fatal\").item()) - (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Fatal\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Fatal\").item()\n",
    "            )\n",
    "          )\n",
    "        ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Fatal\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Fatal\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Fatal\").item())\n",
    "      ), \n",
    "             dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Fatal\").item()\n",
    "             ).alias(\"{}CumFatal\".format(name)),\n",
    "      #Cumulative probability for severe hospitalisations\n",
    "      pl.min_horizontal((((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"SevHosp\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"SevHosp\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\")).item()) * \n",
    "         dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"SevHosp\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"SevHosp\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"SevHosp\").item()\n",
    "            )\n",
    "          )\n",
    "        ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"SevHosp\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"SevHosp\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"SevHosp\").item()),\n",
    "        dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"SevHosp\").item())\n",
    "      ).alias(\"{}CumSevHosp\".format(name)),\n",
    "      #Cumulative probability for non severe injuries \n",
    "      pl.min_horizontal((((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * \n",
    "        dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"NonSevere\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"NonSevere\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"NonSevere\").item()\n",
    "            )\n",
    "          )\n",
    "        )  * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"NonSevere\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"NonSevere\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"NonSevere\").item()),\n",
    "        dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"NonSevere\").item())\n",
    "      ).alias(\"{}CumNonSevere\".format(name)),\n",
    "      #Cumulative probability for shock and trauma\n",
    "      pl.min_horizontal((((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item()) + \n",
    "      (((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock\").item()) - \n",
    "        ((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).item()) * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item())) * \n",
    "      (1 / (1 + \n",
    "        np.power(\n",
    "            np.power(\n",
    "                (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "                (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock\").item() / maxSpeedMPH))\n",
    "                      ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock\").item()\n",
    "            )\n",
    "          )\n",
    "        ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Shock\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Shock\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Shock\").item()),\n",
    "        dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Shock\").item())\n",
    "      ).alias(\"{}CumShock\".format(name))\n",
    "  ).with_columns(\n",
    "    pl.col(\"{}CumFatal\".format(name)),\n",
    "    (pl.col(\"{}CumSevHosp\".format(name)) - pl.col(\"{}CumFatal\".format(name))).alias(\"{}SevHospUC\".format(name)),\n",
    "    (pl.col(\"{}CumNonSevere\".format(name)) - pl.col(\"{}CumSevHosp\".format(name))).alias(\"{}NonSevereUC\".format(name)),\n",
    "    (pl.col(\"{}CumShock\".format(name)) - pl.col(\"{}CumNonSevere\".format(name))).alias(\"{}ShockUC\".format(name))\n",
    "  ).with_columns( \n",
    "    #The consecutive with_columns() statements are necessary as the result of the previous one is used in calculating the next one \n",
    "    #This doesn't significantly affect the efficiency of the algorithm \n",
    "    (pl.col(\"{}CumFatal\".format(name))\n",
    "     ).alias(\"Fatal\")\n",
    "  ).with_columns(\n",
    "    #The smallCollisionModifier applies only to the Passenger IAs\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(pl.col(\"{}SevHospUC\".format(name)), \n",
    "                                        1 - pl.col(\"Fatal\")), 0)\n",
    "     ).alias(\"SevHosp\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(pl.col(\"{}NonSevereUC\".format(name)), \n",
    "                        1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\")), 0)\n",
    "     ).alias(\"NonSevere\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(\n",
    "      pl.min_horizontal(\n",
    "        pl.col(\"{}ShockUC\".format(name)), \n",
    "        1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\")), 0)\n",
    "     ).alias(\"Shock\")\n",
    "  ).with_columns(\n",
    "    (1 - pl.sum_horizontal(\"Fatal\", \"SevHosp\", \"NonSevere\", \"Shock\")).alias(\"NotInjured\")\n",
    "  ).select([\"derailmentConePotentialCollisionID\", \n",
    "            \"cutsetID\",\n",
    "            \"cutset_probability\",\n",
    "            pl.col(\"Fatal\").cast(pl.Float64), \n",
    "            pl.col(\"SevHosp\").cast(pl.Float64), \n",
    "            pl.col(\"NonSevere\").cast(pl.Float64), \n",
    "            pl.col(\"Shock\").cast(pl.Float64), \n",
    "            pl.col(\"NotInjured\").cast(pl.Float64),\n",
    "            \"gate\"]\n",
    "  )\n",
    "  \n",
    "  return injuryAtoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f0e06420-c281-46f4-b545-ea366f2a6f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def groupFourWorkforceIASimple(lazyframe, dataframe, name):\n",
    "  maxSpeedMPH = 125\n",
    "  injuryAtoms = lazyframe.with_columns(\n",
    "  #Cumulative probability of fatal injuries \n",
    "  pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(\"Fatal\").item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Fatal\").item()) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(\"Fatal\").item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Fatal\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Fatal\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Fatal\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Fatal\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Fatal\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Fatal\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Fatal\").item())\n",
    "  ).alias(\"{}CumFatal\".format(name)),\n",
    "\n",
    "#Cumulative probability of specified injuries \n",
    "    pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Specified\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Specified\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Specified\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Specified\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Specified\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Specified\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Specified\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Specified\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Specified\").item())\n",
    "  ).alias(\"{}CumSpecified\".format(name)),\n",
    "\n",
    "#Cumulative probability of Severe Injuries\n",
    "  pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Sev7\").item()) + \n",
    "  ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Sev7\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Sev7\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Sev7\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Sev7\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Sev7\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Sev7\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Sev7\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Sev7\").item())\n",
    "  ).alias(\"{}CumSev7\".format(name)),\n",
    "\n",
    "#Cumulative Probability of Non Severe injuries \n",
    "  pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() *  dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() * (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"NonSevere\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")).item() * dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"NonSevere\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"NonSevere\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"NonSevere\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"NonSevere\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"NonSevere\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"NonSevere\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"NonSevere\").item())\n",
    "  ).alias(\"{}CumNonSevere\".format(name)),\n",
    "\n",
    "#Cumulative probability of Shock7-type injuries\n",
    "  pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock7\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock7\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock7\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock7\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock7\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Shock7\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Shock7\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Shock7\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Shock7\").item())\n",
    "  ).alias(\"{}CumShock7\".format(name)),\n",
    "\n",
    "#Cumulative probability of shock injuries \n",
    "  pl.min_horizontal(((dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "    dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item()) + \n",
    "    ((dataframe.filter(pl.col(\"Value\") == \"probabilityFast\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"P125Constant\").select(\"Shock\").item())) - \n",
    "    (dataframe.filter(pl.col(\"Value\") == \"probabilitySlow\").select(pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\", \"Shock\")).item() * \n",
    "      dataframe.filter(pl.col(\"Value\") == \"P0Constant\").select(\"Shock\").item())) * \n",
    "    (1 / (1 + \n",
    "      np.power(\n",
    "          np.power(\n",
    "              (pl.min_horizontal(pl.col(\"derailmentSpeedMPH\"), maxSpeedMPH)/maxSpeedMPH), \n",
    "              (np.log(2)/np.log(dataframe.filter(pl.col(\"Value\") == \"midpointSpeed\").select(\"Shock\").item() / maxSpeedMPH))\n",
    "                  ) - 1, dataframe.filter(pl.col(\"Value\") == \"K\").select(\"Shock\").item()\n",
    "          )\n",
    "      )\n",
    "    ) * np.power((pl.min_horizontal(pl.col(\"height(m)\"), dataframe.filter(pl.col(\"Value\") == \"maxLossAtHeight\").select(\"Shock\").item())/\n",
    "             dataframe.filter(pl.col(\"Value\") == \"midpointHeight\").select(\"Shock\").item()), \n",
    "                     dataframe.filter(pl.col(\"Value\") == \"heightPowerFactor\").select(\"Shock\").item()),\n",
    "    dataframe.filter(pl.col(\"Value\") == \"maxLoss\").select(\"Shock\").item())\n",
    "  ).alias(\"{}CumShock\".format(name))\n",
    "  ).with_columns(\n",
    "  pl.col(\"{}CumFatal\".format(name)),\n",
    "  (pl.col(\"{}CumSpecified\".format(name)) - pl.col(\"{}CumFatal\".format(name))).alias(\"{}SpecifiedUC\".format(name)),\n",
    "  (pl.col(\"{}CumSev7\".format(name)) - pl.col(\"{}CumSpecified\".format(name))).alias(\"{}Sev7UC\".format(name)),\n",
    "  (pl.col(\"{}CumNonSevere\".format(name)) - pl.col(\"{}CumSev7\".format(name))).alias(\"{}NonSevereUC\".format(name)),\n",
    "  (pl.col(\"{}CumShock7\".format(name)) - pl.col(\"{}CumNonSevere\".format(name))).alias(\"{}Shock7UC\".format(name)),\n",
    "  (pl.col(\"{}CumShock\".format(name)) - pl.col(\"{}CumShock7\".format(name))).alias(\"{}ShockUC\".format(name))\n",
    "  ).with_columns(\n",
    "    (pl.col(\"{}CumFatal\".format(name))\n",
    "     ).alias(\"Fatal\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}SpecifiedUC\".format(name)), 1 - pl.col(\"Fatal\")), 0) \n",
    "     ).alias(\"Specified\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}Sev7UC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\")), 0)\n",
    "     ).alias(\"Sev7\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}NonSevereUC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\")), 0)\n",
    "     ).alias(\"NonSevere\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}Shock7UC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\")), 0)\n",
    "     ).alias(\"Shock7\")\n",
    "  ).with_columns(\n",
    "    (pl.max_horizontal(pl.min_horizontal(pl.col(\"{}ShockUC\".format(name)), 1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\", \"Shock7\")), 0)\n",
    "     ).alias(\"Shock\")\n",
    "  ).with_columns(\n",
    "    (1 - pl.sum_horizontal(\"Fatal\", \"Specified\", \"Sev7\", \"NonSevere\",\"Shock7\", \"Shock\")).alias(\"NotInjured\")\n",
    "  ).select([\"derailmentConePotentialCollisionID\", \n",
    "            \"cutsetID\",\n",
    "            \"cutset_probability\",\n",
    "            pl.col(\"Fatal\").cast(pl.Float64), \n",
    "            pl.col(\"Specified\").cast(pl.Float64), \n",
    "            pl.col(\"Sev7\").cast(pl.Float64), \n",
    "            pl.col(\"NonSevere\").cast(pl.Float64),\n",
    "            pl.col(\"Shock7\").cast(pl.Float64), \n",
    "            pl.col(\"Shock\").cast(pl.Float64), \n",
    "            pl.col(\"NotInjured\").cast(pl.Float64),\n",
    "            \"gate\"]\n",
    "  )\n",
    "\n",
    "  return injuryAtoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5962625f-9674-433a-8b90-6058fcd69bc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyFallEmbankmentPassengerIA = groupFourPassengerIASimple(lazyDerailmentsWithEmbankmentHeights, fallPassenger, fallPassenger.name)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "lazyFallEmbankmentWorkforceIA = groupFourWorkforceIASimple(lazyDerailmentsWithEmbankmentHeights, fallWorkForce, fallWorkForce.name)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)\n",
    "lazyFallEmbankmentPublicIA = groupFourPassengerIASimple(lazyDerailmentsWithEmbankmentHeights, fallPublic, fallPublic.name)\n",
    "lazyFallBridgePassengerIA = groupFourPassengerIASimple(lazyDerailmentsWithBridgeHeights, fallPassenger, fallPassenger.name)\n",
    "lazyFallBridgeWorkforceIA = groupFourWorkforceIASimple(lazyDerailmentsWithBridgeHeights,fallWorkForce, fallWorkForce.name)\n",
    "lazyFallBridgePublicIA = groupFourPassengerIASimple(lazyDerailmentsWithBridgeHeights, fallPublic, fallPublic.name)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming = True (27/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce2c873f-f6ab-4335-bb84-d201305333a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f02786a0-a54c-43ce-b30a-00de30d29024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Group 1 Injury Atoms\n",
    "The injury Atoms are calculated after the string caching to allow for the necessary joins to be done efficiently "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e5276cb1-ed02-460f-8590-2b96780fe8cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Here we manually join each injuryAtom with its cutset gate to see whether it would apply to a given scenario. This is because we cannot loop over the changes made to the lazyframes\n",
    "# First we materialize the dataframes before assigning them to a LazyFrame to stream the calculations - a bug with polars causes  \n",
    "# Derailment - notably we don't need to apply the cutset gates\n",
    "lazyDerailmentPassengerIA = lazyDerPassengerIA\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazyDerailmentWorkforceIA = lazyDerWorkforceIA\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "# Significant structure collision\n",
    "lazySTRColPassengerGateIA = lazySTRColPassengerIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"significantStructureCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazySTRColWorkforceGateIA = lazySTRColWorkforceIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"significantStructureCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "\n",
    "# Significant structure collapse\n",
    "lazySTRCollapsePassengerGateIA = lazySTRCollapsePassengerIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"significantStructureCollapse\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "\n",
    "lazySTRCollapseWorkforceGateIA = lazySTRCollapseWorkforceIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"significantStructureCollapse\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "\n",
    "# Fall on side\n",
    "lazySidePassengerGateIA = lazySidePassengerIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"vehicleFallOnSide\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "\n",
    "lazySideWorkforceGateIA = lazySideWorkforceIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"smallStructureCollision\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"vehicleFallOnSide\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "\n",
    "# Small structure collision\n",
    "lazySmallSTRPassengerGateIA = lazySmallSTRPassengerIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"smallStructureCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "\n",
    "lazySmallSTRWorkforceGateIA = lazySmallSTRWorkforceIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"vehicleFallIntoWater\")\n",
    "    ).rename({\"smallStructureCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "\n",
    "# Fall into water\n",
    "lazyFallWaterPassengerGateIA = lazyFallWaterPassengerIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\") \n",
    "    ).rename({\"vehicleFallIntoWater\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "\n",
    "lazyFallWaterWorkforceGateIA = lazyFallWaterWorkforceIA.select(\n",
    "    pl.exclude(\n",
    "    \"significantStructureCollision\", \n",
    "    \"significantStructureCollapse\", \n",
    "    \"vehicleFallOnSide\", \n",
    "    \"smallStructureCollision\") \n",
    "    ).rename({\"vehicleFallIntoWater\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89241eab-df08-40a4-a2d0-2a65434de42a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Group 2 Injury Atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "528abf8a-1f57-404a-96c0-cf8c994b7402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Secondary Collision Passengers\n",
    "lazySecondaryCollisionPassengerTrain1GateIA = secondaryCollisionPassengerTrain1IA.rename(\n",
    "    {\"secondaryCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazySecondaryCollisionPassengerTrain2GateIA = secondaryCollisionPassengerTrain2IA.rename(\n",
    "    {\"secondaryCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "#Secondary Collision Workforce\n",
    "lazySecondaryCollisionWorkforceTrain1GateIA = secondaryCollisionWorkforceTrain1IA.rename(\n",
    "    {\"secondaryCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazySecondaryCollisionWorkforceTrain2GateIA = secondaryCollisionWorkforceTrain2IA.rename(\n",
    "    {\"secondaryCollision\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3b023e0-7779-4b77-8501-07db355f1ca0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Group 3 Injury Atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9000396e-498d-414f-b9c0-524f9fb5de1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The hazardous goods tables are hardcoded so we simply need to make sure that all derailment-collision-cutset combinations have the \n",
    "# bottom row which will be used in the matrix multiplication\n",
    "\n",
    "# Hazardous Goods Passenger\n",
    "# Train 1 is at risk regardless of whether there is a secondary collision, while Train2 is at risk only if there is a secondary collision\n",
    "lazyHazGoodsPassengerTrain1NoCollisionGateIA = hazGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazyHazGoodsPassengerTrain1CollisionGateIA = hazGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "# collect(streaming=True) (27/09/2024)\n",
    "# streaming=True (27/09/2024)\n",
    "\n",
    "lazyHazGoodsPassengerTrain2CollisionGateIA = hazGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# Hazardous Goods Public\n",
    "# The public is at risk from both trains\n",
    "lazyHazGoodsPublicNoCollisionGateIA = hazGoodsPublicIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "lazyHazGoodsPublicCollisionGateIA = hazGoodsPublicIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# Hazardous Goods Workforce\n",
    "lazyHazGoodsWorkforceTrain1NoCollisionGateIA = hazGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "lazyHazGoodsWorkforceTrain1CollisionGateIA = hazGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "lazyHazGoodsWorkforceTrain2CollisionGateIA = hazGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"toxicGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"toxicGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "\n",
    "# Flammable Goods Passenger\n",
    "lazyFlamGoodsPassengerTrain1NoCollisionGateIA = flamGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "lazyFlamGoodsPassengerTrain1CollisionGateIA = flamGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "lazyFlamGoodsPassengerTrain2CollisionGateIA = flamGoodsPassengerIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# Flammable Goods Public\n",
    "# The public is at risk from both trains\n",
    "lazyFlamGoodsPublicNoCollisionGateIA = flamGoodsPublicIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "lazyFlamGoodsPublicCollisionGateIA = flamGoodsPublicIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_passenger)\n",
    "\n",
    "# Flammable Goods Workforce\n",
    "lazyFlamGoodsWorkforceTrain1NoCollisionGateIA = flamGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease(noCollision)\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease(noCollision)\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "lazyFlamGoodsWorkforceTrain1CollisionGateIA = flamGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n",
    "\n",
    "lazyFlamGoodsWorkforceTrain2CollisionGateIA = flamGoodsWorkforceIA.filter(pl.col(\"Injury\") == \"NotInjured\"\n",
    "    ).join(cutsetProbabilities.select(\n",
    "    \"derailmentConePotentialCollisionID\", \"cutsetID\", \"cutset_probability\", \"flamGoodRelease\"), \n",
    "    how=\"cross\"\n",
    "    ).rename({\"flamGoodRelease\": \"gate\"}\n",
    "    ).pipe(gate_effect_workforce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "626c0413-5b7f-4479-8f0a-1e3fe7b60c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fireFlamGoodsPassengerTrain1IA = non_workforce_fire_flam_goods(derailedTrainGroups, fireNonWorkForce)\n",
    "fireNoFlamGoodsPassengerTrain1IA = non_workforce_fire_no_flam_goods(derailedTrainGroups, fireNonWorkForce)\n",
    "fireFlamGoodsWorkforceTrain1IA = workforce_fire_flam_goods(derailedTrainGroups, fireWorkForce)\n",
    "fireNoFlamGoodsWorkforceTrain1IA = workforce_fire_no_flam_goods(derailedTrainGroups, fireWorkForce) \n",
    "fireFlamGoodsPassengersTrain2IA = non_workforce_fire_flam_goods(collidingTrainGroups, fireNonWorkForce)\n",
    "fireNoFlamGoodsPassengersTrain2IA = non_workforce_fire_no_flam_goods(collidingTrainGroups, fireNonWorkForce)\n",
    "fireFlamGoodsWorkforceTrain2IA = workforce_fire_flam_goods(collidingTrainGroups, fireWorkForce)\n",
    "fireNoFlamGoodsWorkforceTrain2IA = workforce_fire_no_flam_goods(collidingTrainGroups, fireWorkForce)\n",
    "\n",
    "lazyFireFlamGoodsPassengerTrain1GateIA = gate_effect_passenger(fireFlamGoodsPassengerTrain1IA)\n",
    "\n",
    "\n",
    "lazyFireNoFlamGoodsPassengerTrain1GateIA = gate_effect_passenger(fireNoFlamGoodsPassengerTrain1IA)\n",
    "\n",
    "lazyFireFlamGoodsPassengerTrain2GateIA = gate_effect_passenger(fireFlamGoodsPassengersTrain2IA)\n",
    "\n",
    "lazyFireNoFlamGoodsPassengerTrain2GateIA = gate_effect_passenger(fireNoFlamGoodsPassengersTrain2IA)\n",
    "\n",
    "lazyFireFlamGoodsWorkforceTrain1GateIA = gate_effect_workforce(fireFlamGoodsWorkforceTrain1IA)\n",
    "\n",
    "lazyFireNoFlamGoodsWorkforceTrain1GateIA = gate_effect_workforce(fireNoFlamGoodsWorkforceTrain1IA)\n",
    "\n",
    "lazyFireFlamGoodsWorkforceTrain2GateIA = gate_effect_workforce(fireFlamGoodsWorkforceTrain2IA)\n",
    "\n",
    "lazyFireNoFlamGoodsWorkforceTrain2GateIA = gate_effect_workforce(fireNoFlamGoodsWorkforceTrain2IA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35f58e36-8424-42fb-a442-fad68fafd2af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Group 4 Injury Atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6bd37c7a-a504-4b02-b3e7-a917292a154e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Fall from embankment\n",
    "lazyFallEmbankmentPassengerGateIA = lazyFallEmbankmentPassengerIA.pipe(gate_effect_passenger)\n",
    "\n",
    "lazyFallEmbankmentWorkforceGateIA = lazyFallEmbankmentWorkforceIA.pipe(gate_effect_workforce)\n",
    "\n",
    "lazyFallEmbankmentPublicGateIA = lazyFallEmbankmentPublicIA.pipe(gate_effect_passenger)\n",
    "# streaming=True (03/10/2024)\n",
    "# collect(streaming=True)\n",
    "\n",
    "#Fall from Height (termed \"FallBridge\" in the IA)\n",
    "lazyFallBridgePassengerGateIA = lazyFallBridgePassengerIA.pipe(gate_effect_passenger)\n",
    "# streaming=True (03/10/2024)\n",
    "# collect(streaming=True)\n",
    "\n",
    "lazyFallBridgeWorkforceGateIA = lazyFallBridgeWorkforceIA.pipe(gate_effect_workforce)\n",
    "\n",
    "lazyFallBridgePublicGateIA = lazyFallBridgePublicIA.pipe(gate_effect_passenger)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95d44060-175b-4180-a352-76c2582c8992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643381ee-8456-456c-a553-6ce287b9fd30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Bottom Row Multiplication Function \n",
    "Originally the IA were in matrix form (5x5 for passenger and public and 7x7 for workforce) and subsequent escalations were multiplied using matrix multiplication. This operation is _**not**_ supported in polars. \n",
    "However it is possible to reconstruct the complete injury atom matrix using only the probability of an uninjured individual sustaining a certain degree of injury, the so-called matrix \"bottom row\". Thus we construct the bottom row of each matrix using only terms found in the bottom row of each matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "705cc4a9-4632-4f90-b612-c1d67ed3c9ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3a3da03e-ba6e-4a1e-971a-21958b90a076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def passenger_injury_atom_multiplication(lazyframe1, lazyframe2):\n",
    "  output = lazyframe1.join(lazyframe2, on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\", suffix = \"_right\"\n",
    "  ).with_columns(\n",
    "      (pl.col(\"Fatal\") + \n",
    "      pl.col(\"SevHosp\") * pl.col(\"Fatal_right\") + \n",
    "      pl.col(\"NonSevere\") * pl.col(\"Fatal_right\") + \n",
    "      pl.col(\"Shock\") * pl.col(\"Fatal_right\") + \n",
    "      pl.col(\"NotInjured\") * pl.col(\"Fatal_right\")\n",
    "      ).alias(\"Fatal_new\"), \n",
    "      \n",
    "      (pl.col(\"SevHosp\") * (1.0 - pl.col(\"Fatal_right\")) + \n",
    "      pl.col(\"NonSevere\") * pl.col(\"SevHosp_right\") + \n",
    "      pl.col(\"Shock\") * pl.col(\"SevHosp_right\") + \n",
    "      pl.col(\"NotInjured\") * pl.col(\"SevHosp_right\")\n",
    "      ).alias(\"SevHosp_new\"),\n",
    "      \n",
    "      (pl.col(\"NonSevere\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"SevHosp_right\")) + \n",
    "      pl.col(\"Shock\") * pl.col(\"NonSevere_right\") + \n",
    "      pl.col(\"NotInjured\") * pl.col(\"NonSevere_right\")\n",
    "      ).alias(\"NonSevere_new\"),\n",
    "      \n",
    "      (pl.col(\"Shock\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"SevHosp_right\", \"NonSevere_right\")) + \n",
    "      pl.col(\"NotInjured\") * pl.col(\"Shock_right\")\n",
    "      ).alias(\"Shock_new\"), \n",
    "\n",
    "      (pl.col(\"NotInjured\") * pl.col(\"NotInjured_right\")\n",
    "      ).alias(\"NotInjured_new\")\n",
    "  ).select(\n",
    "      \"derailmentConePotentialCollisionID\", \n",
    "      \"cutsetID\", \n",
    "      \"cutset_probability\",\n",
    "      pl.col(\"Fatal_new\").alias(\"Fatal\"), \n",
    "      pl.col(\"SevHosp_new\").alias(\"SevHosp\"),\n",
    "      pl.col(\"NonSevere_new\").alias(\"NonSevere\"),\n",
    "      pl.col(\"Shock_new\").alias(\"Shock\"),\n",
    "      pl.col(\"NotInjured_new\").alias(\"NotInjured\"),\n",
    "  )\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2512001a-a82d-4a10-a1e6-1f2e58638d06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: The matrix multiplications can be rewritten in the form of pl.sum_horizontal(x,y,z) * pl.col(injury)\n",
    "# I have kept this as it is for clarity \n",
    "def workforce_injury_atom_multiplication(lazyframe1, lazyframe2):\n",
    "    output = lazyframe1.join(lazyframe2, on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\", suffix = \"_right\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"Fatal\") + \n",
    "        pl.col(\"Specified\") * pl.col(\"Fatal_right\") + \n",
    "        pl.col(\"Sev7\") * pl.col(\"Fatal_right\") + \n",
    "        pl.col(\"NonSevere\") * pl.col(\"Fatal_right\") + \n",
    "        pl.col(\"Shock7\") * pl.col(\"Fatal_right\") + \n",
    "        pl.col(\"Shock\") * pl.col(\"Fatal_right\") + \n",
    "        pl.col(\"NotInjured\") * pl.col(\"Fatal_right\")\n",
    "        ).alias(\"Fatal_new\"), \n",
    "        \n",
    "        (pl.col(\"Specified\") * (1 - pl.col(\"Fatal_right\")) + \n",
    "        pl.col(\"Sev7\") * pl.col(\"Specified_right\") + \n",
    "        pl.col(\"NonSevere\") * pl.col(\"Specified_right\") + \n",
    "        pl.col(\"Shock7\") * pl.col(\"Specified_right\") + \n",
    "        pl.col(\"Shock\") * pl.col(\"Specified_right\") + \n",
    "        pl.col(\"NotInjured\") * pl.col(\"Specified_right\")\n",
    "        ).alias(\"Specified_new\"),\n",
    "        \n",
    "        (pl.col(\"Sev7\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"Specified_right\")) + \n",
    "        pl.col(\"NonSevere\") * pl.col(\"Sev7_right\") + \n",
    "        pl.col(\"Shock7\") * pl.col(\"Sev7_right\") + \n",
    "        pl.col(\"Shock\") * pl.col(\"Sev7_right\") + \n",
    "        pl.col(\"NotInjured\") * pl.col(\"Sev7_right\")\n",
    "        ).alias(\"Sev7_new\"),\n",
    "        \n",
    "        (pl.col(\"NonSevere\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"Specified_right\", \"Sev7_right\")) +\n",
    "        pl.col(\"Shock7\") * pl.col(\"NonSevere_right\") + \n",
    "        pl.col(\"Shock\") * pl.col(\"NonSevere_right\") + \n",
    "        pl.col(\"NotInjured\") * pl.col(\"NonSevere_right\")\n",
    "        ).alias(\"NonSevere_new\"), \n",
    "\n",
    "        (pl.col(\"Shock7\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"Specified_right\", \"Sev7_right\", \"NonSevere_right\")) +\n",
    "        pl.col(\"Shock\") * pl.col(\"Shock7_right\") + \n",
    "        pl.col(\"NotInjured\") * pl.col(\"Shock7_right\")\n",
    "        ).alias(\"Shock7_new\"),\n",
    "        \n",
    "        (pl.col(\"Shock\") * (1 - pl.sum_horizontal(\"Fatal_right\", \"Specified_right\", \"Sev7_right\", \"NonSevere_right\", \"Shock7_right\")) +\n",
    "        pl.col(\"NotInjured\") * pl.col(\"Shock_right\")\n",
    "        ).alias(\"Shock_new\"),\n",
    "        \n",
    "        (pl.col(\"NotInjured\") * pl.col(\"NotInjured_right\")).alias(\"NotInjured_new\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\", \n",
    "        \"cutsetID\", \n",
    "        pl.col(\"Fatal_new\").alias(\"Fatal\"), \n",
    "        pl.col(\"Specified_new\").alias(\"Specified\"),\n",
    "        pl.col(\"Sev7_new\").alias(\"Sev7\"),\n",
    "        pl.col(\"NonSevere_new\").alias(\"NonSevere\"),\n",
    "        pl.col(\"Shock7_new\").alias(\"Shock7\"),\n",
    "        pl.col(\"Shock_new\").alias(\"Shock\"),\n",
    "        pl.col(\"NotInjured_new\").alias(\"NotInjured\"),\n",
    "    )\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4922a54d-b1a1-4eeb-a0c7-0ed0adf47e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Train Loading by Cutset Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "19a0b757-4a79-4d05-835e-d51de4a65499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyTrain1CutsetProbabilityPassengerLoading = derailedTrainGroups.with_columns(\n",
    "    (pl.col(\"cutset_probability\") * pl.col(\"derailedTrainLoading\")\n",
    "     ).alias(\"weightedLoading\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        pl.col(\"derailedTrainLoading\").alias(\"loading\"),\n",
    "        \"weightedLoading\"\n",
    "    )\n",
    "# streaming=True (03/10/2024)\n",
    "# collect(streaming=True)\n",
    " \n",
    "lazyTrain2CutsetProbabilityPassengerLoading =  collidingTrainGroups.with_columns(\n",
    "    (pl.col(\"cutset_probability\") * pl.col(\"collidingTrainLoading\")\n",
    "     ).alias(\"weightedLoading\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        pl.col(\"collidingTrainLoading\").alias(\"loading\"),\n",
    "        \"weightedLoading\"\n",
    "    )\n",
    "\n",
    "lazyTrain1CutsetProbabilityWorkforceLoading = derailedTrainGroups.with_columns(\n",
    "    (pl.col(\"cutset_probability\") * 2\n",
    "     ).alias(\"weightedLoading\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"weightedLoading\"\n",
    "    )\n",
    "\n",
    "lazyTrain2CutsetProbabilityWorkforceLoading = collidingTrainGroups.with_columns(\n",
    "    (pl.col(\"cutset_probability\") * 2\n",
    "     ).alias(\"weightedLoading\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"weightedLoading\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1953fbf3-8e24-4275-9635-77c790d7610f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e06baf58-cb18-4034-8d34-8cc86e247be9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Injury Atom Calculation\n",
    "The injury atoms are calculated by successive operations, where the output of the function is fed again into the function with the next injury atom. \n",
    "This eventually returns the proportion of each injury. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c50ec0c-c2b6-4e56-9551-35ebd58be7b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Passenger Injury Atoms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0877b7aa-1567-460b-87cb-757adf582294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f78fd0be-1a63-41bb-9b12-2e7ee7d0c7a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This step uses a number of large LazyFrames to make calculations. These represent a considerable strain to memory resources. By clearing them\n",
    "# after they have been used in their respective calculations we save up on memory. \n",
    "\n",
    "injuryAtomsPassengerTrain1 = lazyDerailmentPassengerIA.pipe(\n",
    "    passenger_injury_atom_multiplication, lazySTRColPassengerGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazySTRCollapsePassengerGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazySmallSTRPassengerGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFallBridgePassengerGateIA #Unknown introduced\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFallEmbankmentPassengerGateIA #Unknown\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFallWaterPassengerGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazySidePassengerGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazySecondaryCollisionPassengerTrain1GateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyHazGoodsPassengerTrain1NoCollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyHazGoodsPassengerTrain1CollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFireFlamGoodsPassengerTrain1GateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFireNoFlamGoodsPassengerTrain1GateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFlamGoodsPassengerTrain1NoCollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFlamGoodsPassengerTrain1CollisionGateIA\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61967dac-7d58-4b32-888f-51739b1e569d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c95b94b1-f10e-4ad7-8764-ad995f7b0822",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "injuryAtomsPassengerTrain2 = lazySecondaryCollisionPassengerTrain2GateIA.pipe(\n",
    "    passenger_injury_atom_multiplication, lazyHazGoodsPassengerTrain2CollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFireFlamGoodsPassengerTrain2GateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFireNoFlamGoodsPassengerTrain2GateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFlamGoodsPassengerTrain2CollisionGateIA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cfc27e9-0b38-4069-999e-d67c58d7298d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Workforce Injury Atoms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8f44900-5166-4e24-8ab7-60b7052e0274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "03ae2a84-4f1d-4696-8c85-61b4eee41c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "injuryAtomsWorkforceTrain1 = lazyDerailmentWorkforceIA.pipe(\n",
    "    workforce_injury_atom_multiplication, lazySTRColWorkforceGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazySTRCollapseWorkforceGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazySmallSTRWorkforceGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFallBridgeWorkforceGateIA \n",
    ").pipe(workforce_injury_atom_multiplication, lazyFallEmbankmentWorkforceGateIA \n",
    ").pipe(workforce_injury_atom_multiplication, lazyFallWaterWorkforceGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazySideWorkforceGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazySecondaryCollisionWorkforceTrain1GateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyHazGoodsWorkforceTrain1NoCollisionGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyHazGoodsWorkforceTrain1CollisionGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFireFlamGoodsWorkforceTrain1GateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFireNoFlamGoodsWorkforceTrain1GateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFlamGoodsWorkforceTrain1NoCollisionGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFlamGoodsWorkforceTrain1CollisionGateIA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9a37588-a87f-4795-98e6-0e0cbdeb69b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3cdb089f-2b50-42dd-888f-0c3fd4788d71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "injuryAtomsWorkforceTrain2 = lazySecondaryCollisionWorkforceTrain2GateIA.pipe(\n",
    "    workforce_injury_atom_multiplication, lazyHazGoodsWorkforceTrain2CollisionGateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFireFlamGoodsWorkforceTrain2GateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFireNoFlamGoodsWorkforceTrain2GateIA\n",
    ").pipe(workforce_injury_atom_multiplication, lazyFlamGoodsWorkforceTrain2CollisionGateIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c47e50c-2c5f-4d04-bf11-401089ddc4cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Public Injury Atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3b5a4542-e359-47f5-95ff-852e21c3205b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "injuryAtomsPublic = lazyFallEmbankmentPublicGateIA.pipe(\n",
    "    passenger_injury_atom_multiplication, lazyFallBridgePublicGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyHazGoodsPublicNoCollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyHazGoodsPublicCollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFlamGoodsPublicNoCollisionGateIA\n",
    ").pipe(passenger_injury_atom_multiplication, lazyFlamGoodsPublicCollisionGateIA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785a5194-3039-49ce-8045-0fc285ee9908",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Injuries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bca51496-6302-425e-86e8-cd3bdae25bb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Passengers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a71af8b-4aa8-464a-b3cb-234c826e8423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "245afcec-66cf-4a7b-a6f6-b593517edb68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "passengerInjuriesTrain1 = injuryAtomsPassengerTrain1.join(\n",
    "    lazyTrain1CutsetProbabilityPassengerLoading.select(\n",
    "        pl.exclude(\"cutset_probability\")\n",
    "        ), on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"Fatal\") * pl.col(\"loading\")).alias(\"RAWFatal\"),\n",
    "        (pl.col(\"SevHosp\") * pl.col(\"loading\")).alias(\"RAWSevHosp\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"loading\")).alias(\"RAWNonSevere\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"loading\")).alias(\"RAWShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"loading\")).alias(\"RAWNotInjured\"),\n",
    "        (pl.col(\"Fatal\") * pl.col(\"weightedLoading\")).alias(\"weightedFatal\"),\n",
    "        (pl.col(\"SevHosp\") * pl.col(\"weightedLoading\")).alias(\"weightedSevHosp\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"weightedLoading\")).alias(\"weightedNonSevere\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"weightedLoading\")).alias(\"weightedShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"weightedLoading\")).alias(\"weightedNotInjured\")\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f65d0b9-5b19-43d5-b675-56dd82f87161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bdaca8f5-9c71-4c72-b99a-8f79be3cf53b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "passengerInjuriesTrain2 = injuryAtomsPassengerTrain2.join(\n",
    "    lazyTrain1CutsetProbabilityPassengerLoading.select(\n",
    "        pl.exclude(\"cutset_probability\")\n",
    "        ), on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"Fatal\") * pl.col(\"loading\")).alias(\"RAWFatal\"),\n",
    "        (pl.col(\"SevHosp\") * pl.col(\"loading\")).alias(\"RAWSevHosp\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"loading\")).alias(\"RAWNonSevere\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"loading\")).alias(\"RAWShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"loading\")).alias(\"RAWNotInjured\"),\n",
    "        (pl.col(\"Fatal\") * pl.col(\"weightedLoading\")).alias(\"weightedFatal\"),\n",
    "        (pl.col(\"SevHosp\") * pl.col(\"weightedLoading\")).alias(\"weightedSevHosp\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"weightedLoading\")).alias(\"weightedNonSevere\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"weightedLoading\")).alias(\"weightedShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"weightedLoading\")).alias(\"weightedNotInjured\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce87e109-a762-45f2-bc9d-6186c7125111",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Total Expected Passenger Injuries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f44e7d-0b56-49c8-9288-2af69e9f0242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyInjuryWeights = lazyPersonInjury.join(lazyInjuryDegree, on=[\"injuryDegreeID\"], how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d276cf10-bc45-40f8-900e-93a357d7a6be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "totalExpectedPassengerInjuries = passengerInjuriesTrain1.join(\n",
    "    passengerInjuriesTrain2, on=[\"derailmentConePotentialCollisionID\", \"cutsetID\"], how= \"inner\", suffix=\"_right\"\n",
    "    ).with_columns(\n",
    "        pl.sum_horizontal(\"RAWFatal\",\"RAWFatal_right\").alias(\"RAWFatal\"),\n",
    "        pl.sum_horizontal(\"RAWSevHosp\",\"RAWSevHosp_right\").alias(\"RAWSevHosp\"),\n",
    "        pl.sum_horizontal(\"RAWNonSevere\",\"RAWNonSevere_right\").alias(\"RAWNonSevere\"),\n",
    "        pl.sum_horizontal(\"RAWShock\",\"RAWShock_right\").alias(\"RAWShock\"),\n",
    "        pl.sum_horizontal(\"RAWNotInjured\",\"RAWNotInjured_right\").alias(\"RAWNotInjured\"),\n",
    "        pl.sum_horizontal(\"weightedFatal\",\"weightedFatal_right\").alias(\"weightedFatal\"),\n",
    "        pl.sum_horizontal(\"weightedSevHosp\",\"weightedSevHosp_right\").alias(\"weightedSevHosp\"),\n",
    "        pl.sum_horizontal(\"weightedNonSevere\",\"weightedNonSevere_right\").alias(\"weightedNonSevere\"),\n",
    "        pl.sum_horizontal(\"weightedShock\",\"weightedShock_right\").alias(\"weightedShock\"),\n",
    "        pl.sum_horizontal(\"weightedNotInjured\",\"weightedNotInjured_right\").alias(\"weightedNotInjured\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"RAWFatal\", \n",
    "        \"RAWSevHosp\",\n",
    "        \"RAWNonSevere\",\n",
    "        \"RAWShock\",\n",
    "        \"RAWNotInjured\",\n",
    "        \"weightedFatal\", \n",
    "        \"weightedSevHosp\",\n",
    "        \"weightedNonSevere\",\n",
    "        \"weightedShock\",\n",
    "        \"weightedNotInjured\"\n",
    "    ).join(lazyInjuryWeights.filter(pl.col(\"personTypeID\") == \"P\").select([\"injuryDegreeID\", \"personInjuryID\", \"weight\"]), how=\"cross\"\n",
    "    ).with_columns( # This complicated pl.when() statement checks the injuryDegreeID and assigns the correct value to the new field\n",
    "                    # It is designed this way to avoid utilizing a .pivot() or .transpose() method. This is because they are VERY \n",
    "                    # expensive operations and require for us to manifest the entire dataframe. This will not be possible for the entire \n",
    "                    # dataset.\n",
    "        (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"RAWFatal\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"SevHosp\"\n",
    "                            ).then(pl.col(\"RAWSevHosp\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                        ).then(pl.col(\"RAWNonSevere\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                            ).then(pl.col(\"RAWShock\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\"\n",
    "                                                                        ).then(pl.col(\"RAWNotInjured\"))\n",
    "                                                                )\n",
    "                                                    )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"numberOfInjuriesRAW\"),\n",
    "        \n",
    "        (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"weightedFatal\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"SevHosp\"\n",
    "                            ).then(pl.col(\"weightedSevHosp\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                        ).then(pl.col(\"weightedNonSevere\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                            ).then(pl.col(\"weightedShock\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\"\n",
    "                                                                        ).then(pl.col(\"weightedNotInjured\"))\n",
    "                                                                )\n",
    "                                                    )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"expectedNumberOfInjuries\"),\n",
    "        \n",
    "        (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"weightedFatal\") * pl.col(\"weight\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"SevHosp\"\n",
    "                            ).then(pl.col(\"weightedSevHosp\") * pl.col(\"weight\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                        ).then(pl.col(\"weightedNonSevere\") * pl.col(\"weight\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                            ).then(pl.col(\"weightedShock\") * pl.col(\"weight\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\"\n",
    "                                                                        ).then(pl.col(\"weightedNotInjured\") * pl.col(\"weight\"))\n",
    "                                                                )\n",
    "                                                    )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"personInjuryConsequence\")\n",
    "            ).select(\n",
    "                \"derailmentConePotentialCollisionID\",\n",
    "                \"cutsetID\",\n",
    "                \"personInjuryID\",\n",
    "                \"numberOfInjuriesRAW\",\n",
    "                \"expectedNumberOfInjuries\",\n",
    "                \"personInjuryConsequence\"\n",
    "    # streaming= True until this aggregation step\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0344e178-0c26-4aed-8b14-ba45e585a92e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "totalExpectedPassengerInjuriesAgg = totalExpectedPassengerInjuries.group_by(\"derailmentConePotentialCollisionID\", \"personInjuryID\"\n",
    "            ).agg(pl.col(\"numberOfInjuriesRAW\").sum(),\n",
    "                  pl.col(\"expectedNumberOfInjuries\").sum(), \n",
    "                  pl.col(\"personInjuryConsequence\").sum()\n",
    "            ).sort(by = [pl.col(\"derailmentConePotentialCollisionID\").cast(pl.String), pl.col(\"personInjuryID\").cast(pl.String)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdc48410-bddd-45f8-a5ee-96643f05d10c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Workforce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92ebbb54-3f70-412c-b125-6addab184d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5749ecf7-b665-4ed7-a3ee-7102edacb9f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workforceInjuriesTrain1 = injuryAtomsWorkforceTrain1.join(\n",
    "    lazyTrain1CutsetProbabilityWorkforceLoading.select(\n",
    "        pl.exclude(\"cutset_probability\")\n",
    "        ), on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\"\n",
    "    ).with_columns(\n",
    "        (pl.col(\"Fatal\") * 2).alias(\"RAWFatal\"),\n",
    "        (pl.col(\"Specified\") * 2).alias(\"RAWSpecified\"),\n",
    "        (pl.col(\"Sev7\") * 2).alias(\"RAWSev7\"),\n",
    "        (pl.col(\"NonSevere\") * 2).alias(\"RAWNonSevere\"),\n",
    "        (pl.col(\"Shock7\") * 2).alias(\"RAWShock7\"),\n",
    "        (pl.col(\"Shock\") * 2).alias(\"RAWShock\"),\n",
    "        (pl.col(\"NotInjured\") * 2).alias(\"RAWNotInjured\"),\n",
    "        (pl.col(\"Fatal\") * pl.col(\"weightedLoading\")).alias(\"weightedFatal\"),\n",
    "        (pl.col(\"Specified\") * pl.col(\"weightedLoading\")).alias(\"weightedSpecified\"),\n",
    "        (pl.col(\"Sev7\") * pl.col(\"weightedLoading\")).alias(\"weightedSev7\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"weightedLoading\")).alias(\"weightedNonSevere\"),\n",
    "        (pl.col(\"Shock7\") * pl.col(\"weightedLoading\")).alias(\"weightedShock7\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"weightedLoading\")).alias(\"weightedShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"weightedLoading\")).alias(\"weightedNotInjured\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7edaa971-9fdd-40ef-a563-9ddeabe1e231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Train 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a872f72e-6c63-4e9b-8183-74567d66a1d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "workforceInjuriesTrain2 = injuryAtomsWorkforceTrain2.join(\n",
    "    lazyTrain1CutsetProbabilityWorkforceLoading.select(\n",
    "        pl.exclude(\"cutset_probability\")\n",
    "        ), on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"], how = \"inner\"\n",
    "    ).with_columns( #As we do not have values for workforce loading it is assumed that there are only two workers on each train\n",
    "        (pl.col(\"Fatal\") * 2).alias(\"RAWFatal\"),\n",
    "        (pl.col(\"Specified\") * 2).alias(\"RAWSpecified\"),\n",
    "        (pl.col(\"Sev7\") * 2).alias(\"RAWSev7\"),\n",
    "        (pl.col(\"NonSevere\") * 2).alias(\"RAWNonSevere\"),\n",
    "        (pl.col(\"Shock7\") * 2).alias(\"RAWShock7\"),\n",
    "        (pl.col(\"Shock\") * 2).alias(\"RAWShock\"),\n",
    "        (pl.col(\"NotInjured\") * 2).alias(\"RAWNotInjured\"),\n",
    "        (pl.col(\"Fatal\") * pl.col(\"weightedLoading\")).alias(\"weightedFatal\"),\n",
    "        (pl.col(\"Specified\") * pl.col(\"weightedLoading\")).alias(\"weightedSpecified\"),\n",
    "        (pl.col(\"Sev7\") * pl.col(\"weightedLoading\")).alias(\"weightedSev7\"),\n",
    "        (pl.col(\"NonSevere\") * pl.col(\"weightedLoading\")).alias(\"weightedNonSevere\"),\n",
    "        (pl.col(\"Shock7\") * pl.col(\"weightedLoading\")).alias(\"weightedShock7\"),\n",
    "        (pl.col(\"Shock\") * pl.col(\"weightedLoading\")).alias(\"weightedShock\"),\n",
    "        (pl.col(\"NotInjured\") * pl.col(\"weightedLoading\")).alias(\"weightedNotInjured\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ee4a61-71f8-4d2e-9332-1a44f66cf310",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Total Expected Workforce Injuries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "572776ba-0ada-4dbd-9b65-d06492114ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "totalExpectedWorkforceInjuries = workforceInjuriesTrain1.join(\n",
    "    workforceInjuriesTrain2, on=[\"derailmentConePotentialCollisionID\", \"cutsetID\"], how= \"inner\", suffix=\"_right\"\n",
    "    ).with_columns(\n",
    "        pl.sum_horizontal(\"RAWFatal\",\"RAWFatal_right\").alias(\"RAWFatal\"),\n",
    "        pl.sum_horizontal(\"RAWSpecified\",\"RAWSpecified_right\").alias(\"RAWSpecified\"),\n",
    "        pl.sum_horizontal(\"RAWSev7\",\"RAWSev7_right\").alias(\"RAWSev7\"),\n",
    "        pl.sum_horizontal(\"RAWNonSevere\",\"RAWNonSevere_right\").alias(\"RAWNonSevere\"),\n",
    "        pl.sum_horizontal(\"RAWShock7\",\"RAWShock7_right\").alias(\"RAWShock7\"),\n",
    "        pl.sum_horizontal(\"RAWShock\",\"RAWShock_right\").alias(\"RAWShock\"),\n",
    "        pl.sum_horizontal(\"RAWNotInjured\",\"RAWNotInjured_right\").alias(\"RAWNotInjured\"),\n",
    "        pl.sum_horizontal(\"weightedFatal\",\"weightedFatal_right\").alias(\"weightedFatal\"),\n",
    "        pl.sum_horizontal(\"weightedSpecified\",\"weightedSpecified_right\").alias(\"weightedSpecified\"),\n",
    "        pl.sum_horizontal(\"weightedSev7\",\"weightedSev7_right\").alias(\"weightedSev7\"),\n",
    "        pl.sum_horizontal(\"weightedNonSevere\",\"weightedNonSevere_right\").alias(\"weightedNonSevere\"),\n",
    "        pl.sum_horizontal(\"weightedShock7\",\"weightedShock7_right\").alias(\"weightedShock7\"),\n",
    "        pl.sum_horizontal(\"weightedShock\",\"weightedShock_right\").alias(\"weightedShock\"),\n",
    "        pl.sum_horizontal(\"weightedNotInjured\",\"weightedNotInjured_right\").alias(\"weightedNotInjured\")\n",
    "    ).select(\n",
    "        \"derailmentConePotentialCollisionID\",\n",
    "        \"cutsetID\",\n",
    "        \"RAWFatal\", \n",
    "        \"RAWSpecified\",\n",
    "        \"RAWSev7\",\n",
    "        \"RAWNonSevere\",\n",
    "        \"RAWShock7\",\n",
    "        \"RAWShock\",\n",
    "        \"RAWNotInjured\",\n",
    "        \"weightedFatal\",\n",
    "        \"weightedSpecified\",  \n",
    "        \"weightedSev7\",\n",
    "        \"weightedNonSevere\",\n",
    "        \"weightedShock7\",\n",
    "        \"weightedShock\",\n",
    "        \"weightedNotInjured\"\n",
    "    ).join(lazyInjuryWeights.filter(pl.col(\"personTypeID\") == \"W\").select([\"injuryDegreeID\", \"personInjuryID\", \"weight\"]), how=\"cross\"\n",
    "    ).with_columns( # This complicated pl.when() statement checks the injuryDegreeID and assigns the correct value to the new field\n",
    "                    # It is designed this way to avoid utilizing a .pivot() or .transpose() method. This is because they are VERY \n",
    "                    # expensive operations and require for us to manifest the entire dataframe. This will not be possible for the entire \n",
    "                    # dataset.\n",
    "         (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"RAWFatal\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"Specified\"\n",
    "                            ).then(pl.col(\"RAWSpecified\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Sev7\"\n",
    "                                        ).then(pl.col(\"RAWSev7\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                                            ).then(pl.col(\"RAWNonSevere\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock7\"\n",
    "                                                                        ).then(pl.col(\"RAWShock7\")\n",
    "                                                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                                                            ).then(pl.col(\"RAWShock\")\n",
    "                                                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\").then(pl.col(\"RAWNotInjured\"))\n",
    "                                                                                                        )\n",
    "                                                                                            )\n",
    "                                                                        )\n",
    "                                                            )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"numberOfInjuriesRAW\"),\n",
    "        \n",
    "        (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"weightedFatal\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"Specified\"\n",
    "                            ).then(pl.col(\"weightedSpecified\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Sev7\"\n",
    "                                        ).then(pl.col(\"weightedSev7\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                                            ).then(pl.col(\"weightedNonSevere\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock7\"\n",
    "                                                                        ).then(pl.col(\"weightedShock7\")\n",
    "                                                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                                                    ).then(pl.col(\"weightedShock\")\n",
    "                                                                                    ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\"\n",
    "                                                                                                        ).then(pl.col(\"weightedNotInjured\"))\n",
    "                                                                                                )\n",
    "                                                                                    )\n",
    "                                                                        )\n",
    "                                                            )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"expectedNumberOfInjuries\"),\n",
    "        \n",
    "        (pl.when(pl.col(\"injuryDegreeID\") == \"Fatal\"\n",
    "                ).then(pl.col(\"weightedFatal\") * pl.col(\"weight\")\n",
    "                ).otherwise(\n",
    "                    pl.when(pl.col(\"injuryDegreeID\") == \"Specified\"\n",
    "                            ).then(pl.col(\"weightedSpecified\") * pl.col(\"weight\")\n",
    "                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Sev7\"\n",
    "                                        ).then(pl.col(\"weightedSev7\") * pl.col(\"weight\")\n",
    "                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NonSevere\"\n",
    "                                                            ).then(pl.col(\"weightedNonSevere\") * pl.col(\"weight\")\n",
    "                                                            ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock7\"\n",
    "                                                                        ).then(pl.col(\"weightedShock7\") * pl.col(\"weight\")\n",
    "                                                                        ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"Shock\"\n",
    "                                                                                    ).then(pl.col(\"weightedShock\") * pl.col(\"weight\")\n",
    "                                                                                    ).otherwise(pl.when(pl.col(\"injuryDegreeID\") == \"NotInjured\"\n",
    "                                                                                                        ).then(pl.col(\"weightedNotInjured\") * pl.col(\"weight\"))\n",
    "                                                                                                )\n",
    "                                                                                    )\n",
    "                                                                        )\n",
    "                                                            )\n",
    "                                        )\n",
    "                            )\n",
    "                ).alias(\"personInjuryConsequence\")\n",
    "            ).select(\n",
    "                \"derailmentConePotentialCollisionID\",\n",
    "                \"cutsetID\",\n",
    "                \"personInjuryID\",\n",
    "                \"numberOfInjuriesRAW\",\n",
    "                \"expectedNumberOfInjuries\",\n",
    "                \"personInjuryConsequence\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5cf4dc38-2461-45ac-bf3a-4c2c15d6dae6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "totalExpectedWorkforceInjuriesAgg = totalExpectedWorkforceInjuries.group_by(\"derailmentConePotentialCollisionID\", \"personInjuryID\"\n",
    "            ).agg(pl.col(\"numberOfInjuriesRAW\").sum(),\n",
    "                  pl.col(\"expectedNumberOfInjuries\").sum(), \n",
    "                  pl.col(\"personInjuryConsequence\").sum()\n",
    "            ).sort(by = [pl.col(\"derailmentConePotentialCollisionID\").cast(pl.String), pl.col(\"personInjuryID\").cast(pl.String)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cc85e51e-81af-497c-8299-c9078e4d7481",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LazyFrames unfortunately do not have access to the .vstack() method that would have performed this operation seemlessly. \n",
    "# There we need to resort to .merge_sorted() to merge the two LazyFrames. \n",
    "# Notably merge_sorted is NOT a method that can function with streaming which is why the aggregation had to occur beforehand\n",
    "# Also merge_sorted converts the variables into dtype=pl.Categorical prior to the merging, which is why we had to convert them into strings\n",
    "\n",
    "totalExpectedInjuries = pl.concat([totalExpectedPassengerInjuries, totalExpectedWorkforceInjuries], how = \"vertical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bfc2c24-a9c3-4938-abd0-b5b123f2fdc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Person Injuries of a Train Derailment on a Section in a direction per Period by Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4ac6aceb-f0a5-40dd-9cae-002fa0827805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "derailmentFrequencies = cutsetProbabilities.join(\n",
    "    lazyTrainDerailmentSectionDirectionPeriod.select(\n",
    "    \"trainSectionDerailmentPeriodDirectionID\", \"derailmentFrequency\"),\n",
    "    on=\"trainSectionDerailmentPeriodDirectionID\", how=\"inner\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "985738ba-73c8-4154-b96d-5645588684ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lazyTDSDPS = totalExpectedInjuries.join(derailmentFrequencies.select(\"derailmentConePotentialCollisionID\", \"cutsetID\", \"derailmentFrequency\"),\n",
    "                                        on = [\"derailmentConePotentialCollisionID\", \"cutsetID\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "66c8d2f1-ecda-4b3e-ba18-b77e28baeede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output = lazyTDSDPS.group_by(\n",
    "    \"derailmentConePotentialCollisionID\",\"cutsetID\", \"personInjuryID\"\n",
    "    ).agg(\n",
    "        pl.col(\"derailmentFrequency\").sum(), \n",
    "        pl.col(\"personInjuryConsequence\").sum()\n",
    "    ).with_columns(\n",
    "        (pl.col(\"derailmentFrequency\") * pl.col(\"personInjuryConsequence\")).alias(\"Risk\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85bccee3-631a-447e-bbe6-d27cb1f85324",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output.collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f03e05-eeb3-4b44-a2c2-4c10243a0e90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output2 = lazyTDSDPS.select(\"derailmentConePotentialCollisionID\", \"personInjuryID\", \"personInjuryConsequence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43890c82-eeee-40fc-ba35-98129aa60dd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output2.collect(streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70f5b5cb-ef40-4785-a625-44182cee503b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "end = time.perf_counter()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Functions and Calculations - Main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
