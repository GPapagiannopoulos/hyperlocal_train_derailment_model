# hyperlocal_train_derailment_model
 Model calculating the consequence and risk for a given train derailment anywhere on the GB network

This work was undertaken as part of the Hyperlocal Train Derailment Model (or T1316) project by the Rail Safety and Standards Board (RSSB), in an effort to identify high risk areas, as well as areas likely to benefit the most in terms of risk mitigation, should mitigating measures be implemented. In short, it is a tool meant to support a cost-benefit analysis and decision making for RSSB members. 

The model works by breaking down the GB rail network into ~25m segments, and uses data such as train length, speed, and track curvature to estimate the probability and consequence for a derailment. The probability is given in terms of frequency (number of events/year), while the consequence is given in terms of Fatalities and Weighted Injuries (FWIs). Risk is given as the product of frequency * consequence. The functions that indicate the behaviour of the modelled train were created using historical data, as well as simulations ran by the University of Huddersfield. The data was aggregated over a lengthy period of time and through a number of data sources, and constitutes intellectual property of RSSB. As such it is NOT included in this repository.    

This model is built almost entirely on the Polars library. This is done because of hardware limitations, meaning that we frequently have to work with larger than memory datasets. Polars offers us the opportunity to do so while also parallelizing the data transformations necessary using their LazyFrame data structure.

This led to some conditional transformations that can appear convoluted at first, particularly when calculating injury atoms, since these require matrix multiplication (something that Polars is explicitly unable to do). While converting the LazyFrames into numpy matrices would offer a more straight forward and intuitive way to perform these calculations, concerns regarding the overheard of switching between matrices and LazyFrames, maintaining a correct ordering between matrix and matrix id, and having to manually parallelize this process, led to the decision to find workarounds for the computations that cannot be natively run on the API. 

The purpose of this repository is to serve as an example for the capabilities of Polars as a data manipulation tool, as well as showcase a complex, long-form project that required wrangling huge volumes of data. It also serves as a proof-of-concept for the development of future tools to back risk-related decision making processes. 